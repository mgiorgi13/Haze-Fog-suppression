{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mattiadido95/Haze-Fog-suppression/blob/main/pix2pixHD_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-fvIhrKELDf"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pF_YMYXAtxV",
        "outputId": "a503967d-70ff-430a-f5f4-ecb1b6909d8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dominate\n",
            "  Downloading dominate-2.8.0-py2.py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.7.22)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: dominate\n",
            "Successfully installed dominate-2.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install dominate gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DW2OEAxLB1ni"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMC8BzYnB-Mq",
        "outputId": "a43a9151-9ca1-4e19-a9d1-d028f37d2b9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0vFtFOdwCHWs"
      },
      "outputs": [],
      "source": [
        "folder_path = \"drive/MyDrive/Haze-Fog-suppression\"\n",
        "os.chdir(folder_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2F05uey2amY"
      },
      "source": [
        "# Download library for no reference metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgW4xriY17oA",
        "outputId": "424ff3eb-4e2f-4ac7-cc6d-238ae2cfa21e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'NRVQA'...\n",
            "remote: Enumerating objects: 166, done.\u001b[K\n",
            "remote: Counting objects: 100% (166/166), done.\u001b[K\n",
            "remote: Compressing objects: 100% (137/137), done.\u001b[K\n",
            "remote: Total 166 (delta 43), reused 131 (delta 22), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (166/166), 9.97 MiB | 11.47 MiB/s, done.\n",
            "Resolving deltas: 100% (43/43), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/buyizhiyou/NRVQA.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GO4-qJQlpsb"
      },
      "source": [
        "# Install Apex for Automatic Mixed Precision to speed up training (NOT WORKING)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLaTD67wlxW_",
        "outputId": "7321fd9d-5eb9-400f-bb79-a4edf163e797"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/apex\n",
            "Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "Processing /content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/apex\n",
            "  Running command Preparing metadata (pyproject.toml)\n",
            "\n",
            "\n",
            "  torch.__version__  = 2.0.1+cu118\n",
            "\n",
            "\n",
            "  running dist_info\n",
            "  creating /tmp/pip-modern-metadata-k24uqvr5/apex.egg-info\n",
            "  writing /tmp/pip-modern-metadata-k24uqvr5/apex.egg-info/PKG-INFO\n",
            "  writing dependency_links to /tmp/pip-modern-metadata-k24uqvr5/apex.egg-info/dependency_links.txt\n",
            "  writing requirements to /tmp/pip-modern-metadata-k24uqvr5/apex.egg-info/requires.txt\n",
            "  writing top-level names to /tmp/pip-modern-metadata-k24uqvr5/apex.egg-info/top_level.txt\n",
            "  writing manifest file '/tmp/pip-modern-metadata-k24uqvr5/apex.egg-info/SOURCES.txt'\n",
            "  reading manifest file '/tmp/pip-modern-metadata-k24uqvr5/apex.egg-info/SOURCES.txt'\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file '/tmp/pip-modern-metadata-k24uqvr5/apex.egg-info/SOURCES.txt'\n",
            "  creating '/tmp/pip-modern-metadata-k24uqvr5/apex-0.1.dist-info'\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging>20.6 in /usr/local/lib/python3.10/dist-packages (from apex==0.1) (23.1)\n",
            "Building wheels for collected packages: apex\n",
            "  Running command Building wheel for apex (pyproject.toml)\n",
            "\n",
            "\n",
            "  torch.__version__  = 2.0.1+cu118\n",
            "\n",
            "\n",
            "\n",
            "  Compiling cuda extensions with\n",
            "  nvcc: NVIDIA (R) Cuda compiler driver\n",
            "  Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "  Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "  Cuda compilation tools, release 11.8, V11.8.89\n",
            "  Build cuda_11.8.r11.8/compiler.31833905_0\n",
            "  from /usr/local/cuda/bin\n",
            "\n",
            "  running bdist_wheel\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "    warnings.warn(msg.format('we could not find ninja.'))\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib.linux-x86_64-cpython-310\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex\n",
            "  copying apex/__init__.py -> build/lib.linux-x86_64-cpython-310/apex\n",
            "  copying apex/_autocast_utils.py -> build/lib.linux-x86_64-cpython-310/apex\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/RNN\n",
            "  copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-cpython-310/apex/RNN\n",
            "  copying apex/RNN/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/RNN\n",
            "  copying apex/RNN/cells.py -> build/lib.linux-x86_64-cpython-310/apex/RNN\n",
            "  copying apex/RNN/models.py -> build/lib.linux-x86_64-cpython-310/apex/RNN\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/amp\n",
            "  copying apex/amp/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/amp\n",
            "  copying apex/amp/__version__.py -> build/lib.linux-x86_64-cpython-310/apex/amp\n",
            "  copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-cpython-310/apex/amp\n",
            "  copying apex/amp/_initialize.py -> build/lib.linux-x86_64-cpython-310/apex/amp\n",
            "  copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-cpython-310/apex/amp\n",
            "  copying apex/amp/amp.py -> build/lib.linux-x86_64-cpython-310/apex/amp\n",
            "  copying apex/amp/compat.py -> build/lib.linux-x86_64-cpython-310/apex/amp\n",
            "  copying apex/amp/frontend.py -> build/lib.linux-x86_64-cpython-310/apex/amp\n",
            "  copying apex/amp/handle.py -> build/lib.linux-x86_64-cpython-310/apex/amp\n",
            "  copying apex/amp/opt.py -> build/lib.linux-x86_64-cpython-310/apex/amp\n",
            "  copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-cpython-310/apex/amp\n",
            "  copying apex/amp/scaler.py -> build/lib.linux-x86_64-cpython-310/apex/amp\n",
            "  copying apex/amp/utils.py -> build/lib.linux-x86_64-cpython-310/apex/amp\n",
            "  copying apex/amp/wrap.py -> build/lib.linux-x86_64-cpython-310/apex/amp\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/contrib\n",
            "  copying apex/contrib/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/fp16_utils\n",
            "  copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/fp16_utils\n",
            "  copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-cpython-310/apex/fp16_utils\n",
            "  copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-cpython-310/apex/fp16_utils\n",
            "  copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-cpython-310/apex/fp16_utils\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/fused_dense\n",
            "  copying apex/fused_dense/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/fused_dense\n",
            "  copying apex/fused_dense/fused_dense.py -> build/lib.linux-x86_64-cpython-310/apex/fused_dense\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/mlp\n",
            "  copying apex/mlp/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/mlp\n",
            "  copying apex/mlp/mlp.py -> build/lib.linux-x86_64-cpython-310/apex/mlp\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/multi_tensor_apply\n",
            "  copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/multi_tensor_apply\n",
            "  copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-cpython-310/apex/multi_tensor_apply\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/normalization\n",
            "  copying apex/normalization/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/normalization\n",
            "  copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-cpython-310/apex/normalization\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/optimizers\n",
            "  copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/optimizers\n",
            "  copying apex/optimizers/fused_adagrad.py -> build/lib.linux-x86_64-cpython-310/apex/optimizers\n",
            "  copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-cpython-310/apex/optimizers\n",
            "  copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-cpython-310/apex/optimizers\n",
            "  copying apex/optimizers/fused_mixed_precision_lamb.py -> build/lib.linux-x86_64-cpython-310/apex/optimizers\n",
            "  copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-cpython-310/apex/optimizers\n",
            "  copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-cpython-310/apex/optimizers\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/parallel\n",
            "  copying apex/parallel/LARC.py -> build/lib.linux-x86_64-cpython-310/apex/parallel\n",
            "  copying apex/parallel/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/parallel\n",
            "  copying apex/parallel/distributed.py -> build/lib.linux-x86_64-cpython-310/apex/parallel\n",
            "  copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-cpython-310/apex/parallel\n",
            "  copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-cpython-310/apex/parallel\n",
            "  copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-cpython-310/apex/parallel\n",
            "  copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-cpython-310/apex/parallel\n",
            "  copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-cpython-310/apex/parallel\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/transformer\n",
            "  copying apex/transformer/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/transformer\n",
            "  copying apex/transformer/_ucc_util.py -> build/lib.linux-x86_64-cpython-310/apex/transformer\n",
            "  copying apex/transformer/enums.py -> build/lib.linux-x86_64-cpython-310/apex/transformer\n",
            "  copying apex/transformer/log_util.py -> build/lib.linux-x86_64-cpython-310/apex/transformer\n",
            "  copying apex/transformer/microbatches.py -> build/lib.linux-x86_64-cpython-310/apex/transformer\n",
            "  copying apex/transformer/parallel_state.py -> build/lib.linux-x86_64-cpython-310/apex/transformer\n",
            "  copying apex/transformer/utils.py -> build/lib.linux-x86_64-cpython-310/apex/transformer\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/amp/lists\n",
            "  copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/amp/lists\n",
            "  copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-cpython-310/apex/amp/lists\n",
            "  copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-cpython-310/apex/amp/lists\n",
            "  copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-cpython-310/apex/amp/lists\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/contrib/bottleneck\n",
            "  copying apex/contrib/bottleneck/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/bottleneck\n",
            "  copying apex/contrib/bottleneck/bottleneck.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/bottleneck\n",
            "  copying apex/contrib/bottleneck/halo_exchangers.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/bottleneck\n",
            "  copying apex/contrib/bottleneck/test.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/bottleneck\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/contrib/clip_grad\n",
            "  copying apex/contrib/clip_grad/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/clip_grad\n",
            "  copying apex/contrib/clip_grad/clip_grad.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/clip_grad\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/contrib/conv_bias_relu\n",
            "  copying apex/contrib/conv_bias_relu/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/conv_bias_relu\n",
            "  copying apex/contrib/conv_bias_relu/conv_bias_relu.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/conv_bias_relu\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/contrib/cudnn_gbn\n",
            "  copying apex/contrib/cudnn_gbn/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/cudnn_gbn\n",
            "  copying apex/contrib/cudnn_gbn/batch_norm.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/cudnn_gbn\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/contrib/fmha\n",
            "  copying apex/contrib/fmha/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/fmha\n",
            "  copying apex/contrib/fmha/fmha.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/fmha\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/contrib/focal_loss\n",
            "  copying apex/contrib/focal_loss/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/focal_loss\n",
            "  copying apex/contrib/focal_loss/focal_loss.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/focal_loss\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/contrib/group_norm\n",
            "  copying apex/contrib/group_norm/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/group_norm\n",
            "  copying apex/contrib/group_norm/group_norm.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/group_norm\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/contrib/groupbn\n",
            "  copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/groupbn\n",
            "  copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/groupbn\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/contrib/index_mul_2d\n",
            "  copying apex/contrib/index_mul_2d/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/index_mul_2d\n",
            "  copying apex/contrib/index_mul_2d/index_mul_2d.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/index_mul_2d\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/contrib/layer_norm\n",
            "  copying apex/contrib/layer_norm/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/layer_norm\n",
            "  copying apex/contrib/layer_norm/layer_norm.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/layer_norm\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fused_lamb.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fused_sgd.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/optimizers\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/contrib/peer_memory\n",
            "  copying apex/contrib/peer_memory/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/peer_memory\n",
            "  copying apex/contrib/peer_memory/peer_halo_exchanger_1d.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/peer_memory\n",
            "  copying apex/contrib/peer_memory/peer_memory.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/peer_memory\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/asp.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/permutation_lib.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/sparse_masklib.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/contrib/test\n",
            "  copying apex/contrib/test/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/contrib/transducer\n",
            "  copying apex/contrib/transducer/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/transducer\n",
            "  copying apex/contrib/transducer/_transducer_ref.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/transducer\n",
            "  copying apex/contrib/transducer/transducer.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/transducer\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/contrib/xentropy\n",
            "  copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/xentropy\n",
            "  copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/xentropy\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying apex/contrib/sparsity/permutation_search_kernels/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying apex/contrib/sparsity/permutation_search_kernels/channel_swap.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity/permutation_search_kernels\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/contrib/test/bottleneck\n",
            "  copying apex/contrib/test/bottleneck/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/bottleneck\n",
            "  copying apex/contrib/test/bottleneck/test_bottleneck_module.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/bottleneck\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/contrib/test/clip_grad\n",
            "  copying apex/contrib/test/clip_grad/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/clip_grad\n",
            "  copying apex/contrib/test/clip_grad/test_clip_grad.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/clip_grad\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/contrib/test/conv_bias_relu\n",
            "  copying apex/contrib/test/conv_bias_relu/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/conv_bias_relu\n",
            "  copying apex/contrib/test/conv_bias_relu/test_conv_bias_relu.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/conv_bias_relu\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/contrib/test/cudnn_gbn\n",
            "  copying apex/contrib/test/cudnn_gbn/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/cudnn_gbn\n",
            "  copying apex/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/cudnn_gbn\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/contrib/test/fmha\n",
            "  copying apex/contrib/test/fmha/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/fmha\n",
            "  copying apex/contrib/test/fmha/test_fmha.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/fmha\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/contrib/test/focal_loss\n",
            "  copying apex/contrib/test/focal_loss/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/focal_loss\n",
            "  copying apex/contrib/test/focal_loss/test_focal_loss.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/focal_loss\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/contrib/test/group_norm\n",
            "  copying apex/contrib/test/group_norm/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/group_norm\n",
            "  copying apex/contrib/test/group_norm/test_group_norm.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/group_norm\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/contrib/test/index_mul_2d\n",
            "  copying apex/contrib/test/index_mul_2d/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/index_mul_2d\n",
            "  copying apex/contrib/test/index_mul_2d/test_index_mul_2d.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/index_mul_2d\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/contrib/test/layer_norm\n",
            "  copying apex/contrib/test/layer_norm/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/layer_norm\n",
            "  copying apex/contrib/test/layer_norm/test_fast_layer_norm.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/layer_norm\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/contrib/test/multihead_attn\n",
            "  copying apex/contrib/test/multihead_attn/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/multihead_attn\n",
            "  copying apex/contrib/test/multihead_attn/test_encdec_multihead_attn.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/multihead_attn\n",
            "  copying apex/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/multihead_attn\n",
            "  copying apex/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/multihead_attn\n",
            "  copying apex/contrib/test/multihead_attn/test_mha_fused_softmax.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/multihead_attn\n",
            "  copying apex/contrib/test/multihead_attn/test_self_multihead_attn.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/multihead_attn\n",
            "  copying apex/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/multihead_attn\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/contrib/test/optimizers\n",
            "  copying apex/contrib/test/optimizers/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/optimizers\n",
            "  copying apex/contrib/test/optimizers/test_dist_adam.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/optimizers\n",
            "  copying apex/contrib/test/optimizers/test_distributed_fused_lamb.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/optimizers\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/contrib/test/peer_memory\n",
            "  copying apex/contrib/test/peer_memory/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/peer_memory\n",
            "  copying apex/contrib/test/peer_memory/test_peer_halo_exchange_module.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/peer_memory\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/contrib/test/transducer\n",
            "  copying apex/contrib/test/transducer/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/transducer\n",
            "  copying apex/contrib/test/transducer/test_transducer_joint.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/transducer\n",
            "  copying apex/contrib/test/transducer/test_transducer_loss.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/transducer\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/contrib/test/xentropy\n",
            "  copying apex/contrib/test/xentropy/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/xentropy\n",
            "  copying apex/contrib/test/xentropy/test_label_smoothing.py -> build/lib.linux-x86_64-cpython-310/apex/contrib/test/xentropy\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/transformer/_data\n",
            "  copying apex/transformer/_data/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/_data\n",
            "  copying apex/transformer/_data/_batchsampler.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/_data\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/transformer/amp\n",
            "  copying apex/transformer/amp/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/amp\n",
            "  copying apex/transformer/amp/grad_scaler.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/amp\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/transformer/functional\n",
            "  copying apex/transformer/functional/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/functional\n",
            "  copying apex/transformer/functional/fused_softmax.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/functional\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/transformer/layers\n",
            "  copying apex/transformer/layers/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/layers\n",
            "  copying apex/transformer/layers/layer_norm.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/layers\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel\n",
            "  copying apex/transformer/pipeline_parallel/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel\n",
            "  copying apex/transformer/pipeline_parallel/_timers.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel\n",
            "  copying apex/transformer/pipeline_parallel/p2p_communication.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel\n",
            "  copying apex/transformer/pipeline_parallel/utils.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/cross_entropy.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/data.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/layers.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/mappings.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/memory.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/random.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel\n",
            "  copying apex/transformer/tensor_parallel/utils.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/transformer/testing\n",
            "  copying apex/transformer/testing/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/testing\n",
            "  copying apex/transformer/testing/arguments.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/testing\n",
            "  copying apex/transformer/testing/commons.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/testing\n",
            "  copying apex/transformer/testing/distributed_test_base.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/testing\n",
            "  copying apex/transformer/testing/global_vars.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/testing\n",
            "  copying apex/transformer/testing/standalone_bert.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/testing\n",
            "  copying apex/transformer/testing/standalone_gpt.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/testing\n",
            "  copying apex/transformer/testing/standalone_transformer_lm.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/testing\n",
            "  creating build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel/schedules\n",
            "  copying apex/transformer/pipeline_parallel/schedules/__init__.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel/schedules\n",
            "  copying apex/transformer/pipeline_parallel/schedules/common.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel/schedules\n",
            "  copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel/schedules\n",
            "  copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel/schedules\n",
            "  copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py -> build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel/schedules\n",
            "  running build_ext\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:398: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 11.8\n",
            "    warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
            "  building 'apex_C' extension\n",
            "  creating build/temp.linux-x86_64-cpython-310\n",
            "  creating build/temp.linux-x86_64-cpython-310/csrc\n",
            "  x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/include/python3.10 -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-cpython-310/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "  x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/csrc/flatten_unflatten.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-cpython-310/apex_C.cpython-310-x86_64-linux-gnu.so\n",
            "  building 'amp_C' extension\n",
            "  x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-cpython-310/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/multi_tensor_adagrad.cu -o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_adagrad.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n",
            "\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/multi_tensor_adam.cu -o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_adam.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n",
            "\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n",
            "\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/multi_tensor_l2norm_kernel.cu -o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n",
            "\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/multi_tensor_l2norm_kernel_mp.cu -o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_l2norm_kernel_mp.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n",
            "\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/multi_tensor_l2norm_scale_kernel.cu -o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_l2norm_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n",
            "\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/multi_tensor_lamb.cu -o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_lamb.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n",
            "\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/multi_tensor_lamb_mp.cu -o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_lamb_mp.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n",
            "\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/multi_tensor_lamb_stage_1.cu -o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n",
            "\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/multi_tensor_lamb_stage_2.cu -o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n",
            "\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/multi_tensor_novograd.cu -o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_novograd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n",
            "\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n",
            "\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/multi_tensor_sgd_kernel.cu -o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_sgd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n",
            "\n",
            "  x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/csrc/amp_C_frontend.o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_adagrad.o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_adam.o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_axpby_kernel.o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_l2norm_kernel.o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_l2norm_kernel_mp.o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_l2norm_scale_kernel.o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_lamb.o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_lamb_mp.o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_lamb_stage_1.o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_lamb_stage_2.o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_novograd.o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_scale_kernel.o build/temp.linux-x86_64-cpython-310/csrc/multi_tensor_sgd_kernel.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/amp_C.cpython-310-x86_64-linux-gnu.so\n",
            "  building 'syncbn' extension\n",
            "  x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/syncbn.cpp -o build/temp.linux-x86_64-cpython-310/csrc/syncbn.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/welford.cu -o build/temp.linux-x86_64-cpython-310/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n",
            "\n",
            "  x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/csrc/syncbn.o build/temp.linux-x86_64-cpython-310/csrc/welford.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/syncbn.cpython-310-x86_64-linux-gnu.so\n",
            "  building 'fused_layer_norm_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/layer_norm_cuda.cpp -o build/temp.linux-x86_64-cpython-310/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/layer_norm_cuda_kernel.cu -o build/temp.linux-x86_64-cpython-310/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n",
            "\n",
            "  x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/csrc/layer_norm_cuda.o build/temp.linux-x86_64-cpython-310/csrc/layer_norm_cuda_kernel.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/fused_layer_norm_cuda.cpython-310-x86_64-linux-gnu.so\n",
            "  building 'mlp_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/mlp.cpp -o build/temp.linux-x86_64-cpython-310/csrc/mlp.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "  csrc/mlp.cpp: In function std::vector<at::Tensor> mlp_forward(int, int, std::vector<at::Tensor>):\n",
            "  csrc/mlp.cpp:57:21: warning: comparison of integer expressions of different signedness: int and long unsigned int [-Wsign-compare]\n",
            "     57 |   for (int i = 0; i < num_layers; i++) {\n",
            "        |                   ~~^~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:64:76: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     64 |   auto out = at::empty({batch_size, output_features.back()}, inputs[0].type());\n",
            "        |                                                              ~~~~~~~~~~~~~~^~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n",
            "    222 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  csrc/mlp.cpp:65:85: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     65 |   auto reserved_space = at::empty({static_cast<long>(reserved_size)}, inputs[0].type());\n",
            "        |                                                                       ~~~~~~~~~~~~~~^~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n",
            "    222 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  csrc/mlp.cpp:67:58: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     67 |   auto lt_workspace = at::empty({1 << 22}, inputs[0].type());\n",
            "        |                                            ~~~~~~~~~~~~~~^~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n",
            "    222 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/ATen.h:11,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/mlp.cpp:1:\n",
            "  csrc/mlp.cpp: In lambda function:\n",
            "  csrc/mlp.cpp:69:53: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "        |                                       ~~~~~~~~~~~~~~^~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:228:28: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    228 |     const auto& the_type = TYPE;                                            \\\n",
            "        |                            ^~~~\n",
            "  csrc/mlp.cpp:69:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
            "     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n",
            "    222 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/ATen.h:11,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:231:47: warning: c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&) is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "    231 |     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n",
            "        |                          ~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:258:3: note: in expansion of macro AT_DISPATCH_SWITCH\n",
            "    258 |   AT_DISPATCH_SWITCH(                                        \\\n",
            "        |   ^~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:69:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
            "     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:122:23: note: declared here\n",
            "    122 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "        |                       ^~~~~~~~~~~\n",
            "  csrc/mlp.cpp: In lambda function:\n",
            "  csrc/mlp.cpp:72:23: warning: comparison of integer expressions of different signedness: int and long unsigned int [-Wsign-compare]\n",
            "     72 |     for (int i = 0; i < num_layers; i++) {\n",
            "        |                     ~~^~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:253:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    253 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF\n",
            "    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:69:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
            "     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:78:10: warning: unused variable result [-Wunused-variable]\n",
            "     78 |     auto result = mlp_fp<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:253:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    253 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF\n",
            "    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:69:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
            "     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp: In lambda function:\n",
            "  csrc/mlp.cpp:72:23: warning: comparison of integer expressions of different signedness: int and long unsigned int [-Wsign-compare]\n",
            "     72 |     for (int i = 0; i < num_layers; i++) {\n",
            "        |                     ~~^~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:254:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    254 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF\n",
            "    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:69:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
            "     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:78:10: warning: unused variable result [-Wunused-variable]\n",
            "     78 |     auto result = mlp_fp<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:254:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    254 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF\n",
            "    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:69:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
            "     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp: In lambda function:\n",
            "  csrc/mlp.cpp:72:23: warning: comparison of integer expressions of different signedness: int and long unsigned int [-Wsign-compare]\n",
            "     72 |     for (int i = 0; i < num_layers; i++) {\n",
            "        |                     ~~^~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:255:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    255 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF\n",
            "    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:69:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
            "     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:78:10: warning: unused variable result [-Wunused-variable]\n",
            "     78 |     auto result = mlp_fp<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:255:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    255 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF\n",
            "    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:69:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
            "     69 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp: In function std::vector<at::Tensor> mlp_backward(int, int, at::Tensor, std::vector<at::Tensor>, std::vector<at::Tensor>):\n",
            "  csrc/mlp.cpp:115:21: warning: comparison of integer expressions of different signedness: int and long unsigned int [-Wsign-compare]\n",
            "    115 |   for (int i = 0; i < num_layers; i++) {\n",
            "        |                   ~~^~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:120:21: warning: comparison of integer expressions of different signedness: int and std::vector<at::Tensor>::size_type {aka long unsigned int} [-Wsign-compare]\n",
            "    120 |   for (int i = 0; i < inputs.size(); i++) {\n",
            "        |                   ~~^~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:121:66: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    121 |     outputs.push_back(at::empty(inputs[i].sizes(), inputs[i].type()));  // clone for testing now\n",
            "        |                                                    ~~~~~~~~~~~~~~^~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n",
            "    222 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/ATen.h:11,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/mlp.cpp:1:\n",
            "  csrc/mlp.cpp: In lambda function:\n",
            "  csrc/mlp.cpp:124:53: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "        |                                       ~~~~~~~~~~~~~~^~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:228:28: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    228 |     const auto& the_type = TYPE;                                            \\\n",
            "        |                            ^~~~\n",
            "  csrc/mlp.cpp:124:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
            "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n",
            "    222 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/ATen.h:11,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:231:47: warning: c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&) is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "    231 |     at::ScalarType _st = ::detail::scalar_type(the_type);                   \\\n",
            "        |                          ~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:258:3: note: in expansion of macro AT_DISPATCH_SWITCH\n",
            "    258 |   AT_DISPATCH_SWITCH(                                        \\\n",
            "        |   ^~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:124:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
            "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:122:23: note: declared here\n",
            "    122 | inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "        |                       ^~~~~~~~~~~\n",
            "  csrc/mlp.cpp: In lambda function:\n",
            "  csrc/mlp.cpp:126:23: warning: comparison of integer expressions of different signedness: int and long unsigned int [-Wsign-compare]\n",
            "    126 |     for (int i = 0; i < num_layers; i++) {\n",
            "        |                     ~~^~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:253:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    253 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF\n",
            "    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:124:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
            "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:130:23: warning: comparison of integer expressions of different signedness: int and std::vector<at::Tensor>::size_type {aka long unsigned int} [-Wsign-compare]\n",
            "    130 |     for (int i = 0; i < inputs.size(); i++) {\n",
            "        |                     ~~^~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:253:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    253 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF\n",
            "    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:124:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
            "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:138:98: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    138 |     auto work_space = at::empty({static_cast<long>(work_size / sizeof(scalar_t))}, inputs[0].type());\n",
            "        |                                                                                    ~~~~~~~~~~~~~~^~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:253:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    253 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF\n",
            "    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:124:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
            "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n",
            "    222 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/ATen.h:11,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/mlp.cpp:1:\n",
            "  csrc/mlp.cpp:140:10: warning: unused variable result [-Wunused-variable]\n",
            "    140 |     auto result = mlp_bp<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:253:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    253 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF\n",
            "    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:124:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
            "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp: In lambda function:\n",
            "  csrc/mlp.cpp:126:23: warning: comparison of integer expressions of different signedness: int and long unsigned int [-Wsign-compare]\n",
            "    126 |     for (int i = 0; i < num_layers; i++) {\n",
            "        |                     ~~^~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:254:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    254 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF\n",
            "    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:124:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
            "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:130:23: warning: comparison of integer expressions of different signedness: int and std::vector<at::Tensor>::size_type {aka long unsigned int} [-Wsign-compare]\n",
            "    130 |     for (int i = 0; i < inputs.size(); i++) {\n",
            "        |                     ~~^~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:254:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    254 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF\n",
            "    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:124:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
            "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:138:98: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    138 |     auto work_space = at::empty({static_cast<long>(work_size / sizeof(scalar_t))}, inputs[0].type());\n",
            "        |                                                                                    ~~~~~~~~~~~~~~^~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:254:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    254 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF\n",
            "    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:124:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
            "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n",
            "    222 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/ATen.h:11,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/mlp.cpp:1:\n",
            "  csrc/mlp.cpp:140:10: warning: unused variable result [-Wunused-variable]\n",
            "    140 |     auto result = mlp_bp<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:254:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    254 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)  \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF\n",
            "    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:124:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
            "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp: In lambda function:\n",
            "  csrc/mlp.cpp:126:23: warning: comparison of integer expressions of different signedness: int and long unsigned int [-Wsign-compare]\n",
            "    126 |     for (int i = 0; i < num_layers; i++) {\n",
            "        |                     ~~^~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:255:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    255 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF\n",
            "    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:124:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
            "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:130:23: warning: comparison of integer expressions of different signedness: int and std::vector<at::Tensor>::size_type {aka long unsigned int} [-Wsign-compare]\n",
            "    130 |     for (int i = 0; i < inputs.size(); i++) {\n",
            "        |                     ~~^~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:255:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    255 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF\n",
            "    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:124:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
            "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:138:98: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    138 |     auto work_space = at::empty({static_cast<long>(work_size / sizeof(scalar_t))}, inputs[0].type());\n",
            "        |                                                                                    ~~~~~~~~~~~~~~^~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:255:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    255 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF\n",
            "    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:124:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
            "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/mlp.cpp:1:\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n",
            "    222 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/ATen.h:11,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/mlp.cpp:1:\n",
            "  csrc/mlp.cpp:140:10: warning: unused variable result [-Wunused-variable]\n",
            "    140 |     auto result = mlp_bp<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:255:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    255 |   AT_DISPATCH_CASE(at::ScalarType::Half, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:259:19: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF\n",
            "    259 |       TYPE, NAME, AT_DISPATCH_CASE_FLOATING_TYPES_AND_HALF(__VA_ARGS__))\n",
            "        |                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/mlp.cpp:124:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND_HALF\n",
            "    124 |   AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/mlp_cuda.cu -o build/temp.linux-x86_64-cpython-310/csrc/mlp_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n",
            "\n",
            "  x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/csrc/mlp.o build/temp.linux-x86_64-cpython-310/csrc/mlp_cuda.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/mlp_cuda.cpython-310-x86_64-linux-gnu.so\n",
            "  building 'fused_dense_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/fused_dense.cpp -o build/temp.linux-x86_64-cpython-310/csrc/fused_dense.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=fused_dense_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "  csrc/fused_dense.cpp: In function at::Tensor linear_bias_forward(at::Tensor, at::Tensor, at::Tensor):\n",
            "  csrc/fused_dense.cpp:30:62: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     30 |   auto out = at::empty({batch_size, out_features}, input.type());\n",
            "        |                                                    ~~~~~~~~~~^~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n",
            "    222 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  csrc/fused_dense.cpp:33:54: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     33 |   auto lt_workspace = at::empty({1 << 22}, input.type());\n",
            "        |                                            ~~~~~~~~~~^~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n",
            "    222 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/ATen.h:11,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  csrc/fused_dense.cpp: In lambda function:\n",
            "  csrc/fused_dense.cpp:37:15: warning: unused variable b_ptr [-Wunused-variable]\n",
            "     37 |     scalar_t* b_ptr = bias.data_ptr<scalar_t>();\n",
            "        |               ^~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:246:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    246 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:272:3: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES\n",
            "    272 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND2\n",
            "    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
            "        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:35:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND2\n",
            "     35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:38:10: warning: unused variable result [-Wunused-variable]\n",
            "     38 |     auto result = linear_bias_forward_cuda<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:246:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    246 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:272:3: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES\n",
            "    272 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND2\n",
            "    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
            "        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:35:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND2\n",
            "     35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp: In lambda function:\n",
            "  csrc/fused_dense.cpp:37:15: warning: unused variable b_ptr [-Wunused-variable]\n",
            "     37 |     scalar_t* b_ptr = bias.data_ptr<scalar_t>();\n",
            "        |               ^~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:247:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    247 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:272:3: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES\n",
            "    272 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND2\n",
            "    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
            "        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:35:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND2\n",
            "     35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:38:10: warning: unused variable result [-Wunused-variable]\n",
            "     38 |     auto result = linear_bias_forward_cuda<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:247:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    247 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:272:3: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES\n",
            "    272 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND2\n",
            "    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
            "        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:35:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND2\n",
            "     35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp: In lambda function:\n",
            "  csrc/fused_dense.cpp:37:15: warning: unused variable b_ptr [-Wunused-variable]\n",
            "     37 |     scalar_t* b_ptr = bias.data_ptr<scalar_t>();\n",
            "        |               ^~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:273:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    273 |   AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND2\n",
            "    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
            "        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:35:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND2\n",
            "     35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:38:10: warning: unused variable result [-Wunused-variable]\n",
            "     38 |     auto result = linear_bias_forward_cuda<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:273:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    273 |   AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND2\n",
            "    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
            "        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:35:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND2\n",
            "     35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp: In lambda function:\n",
            "  csrc/fused_dense.cpp:37:15: warning: unused variable b_ptr [-Wunused-variable]\n",
            "     37 |     scalar_t* b_ptr = bias.data_ptr<scalar_t>();\n",
            "        |               ^~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:274:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    274 |   AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND2\n",
            "    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
            "        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:35:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND2\n",
            "     35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:38:10: warning: unused variable result [-Wunused-variable]\n",
            "     38 |     auto result = linear_bias_forward_cuda<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:274:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    274 |   AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND2\n",
            "    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
            "        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:35:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND2\n",
            "     35 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp: In function std::vector<at::Tensor> linear_bias_backward(at::Tensor, at::Tensor, at::Tensor):\n",
            "  csrc/fused_dense.cpp:64:68: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     64 |   auto d_weight = at::empty({out_features, in_features}, input.type());\n",
            "        |                                                          ~~~~~~~~~~^~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n",
            "    222 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  csrc/fused_dense.cpp:68:53: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     68 |   auto d_bias = at::empty({out_features}, input.type());\n",
            "        |                                           ~~~~~~~~~~^~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n",
            "    222 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  csrc/fused_dense.cpp:70:65: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     70 |   auto d_input = at::empty({batch_size, in_features}, input.type());\n",
            "        |                                                       ~~~~~~~~~~^~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n",
            "    222 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  csrc/fused_dense.cpp:73:54: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     73 |   auto lt_workspace = at::empty({1 << 22}, input.type());\n",
            "        |                                            ~~~~~~~~~~^~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n",
            "    222 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/ATen.h:11,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  csrc/fused_dense.cpp: In lambda function:\n",
            "  csrc/fused_dense.cpp:77:15: warning: unused variable d_b_ptr [-Wunused-variable]\n",
            "     77 |     scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();\n",
            "        |               ^~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:246:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    246 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:272:3: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES\n",
            "    272 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND2\n",
            "    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
            "        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:75:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND2\n",
            "     75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:78:10: warning: unused variable result [-Wunused-variable]\n",
            "     78 |     auto result = linear_bias_backward_cuda<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:246:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    246 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:272:3: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES\n",
            "    272 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND2\n",
            "    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
            "        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:75:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND2\n",
            "     75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp: In lambda function:\n",
            "  csrc/fused_dense.cpp:77:15: warning: unused variable d_b_ptr [-Wunused-variable]\n",
            "     77 |     scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();\n",
            "        |               ^~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:247:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    247 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:272:3: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES\n",
            "    272 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND2\n",
            "    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
            "        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:75:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND2\n",
            "     75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:78:10: warning: unused variable result [-Wunused-variable]\n",
            "     78 |     auto result = linear_bias_backward_cuda<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:247:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    247 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:272:3: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES\n",
            "    272 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND2\n",
            "    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
            "        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:75:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND2\n",
            "     75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp: In lambda function:\n",
            "  csrc/fused_dense.cpp:77:15: warning: unused variable d_b_ptr [-Wunused-variable]\n",
            "     77 |     scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();\n",
            "        |               ^~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:273:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    273 |   AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND2\n",
            "    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
            "        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:75:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND2\n",
            "     75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:78:10: warning: unused variable result [-Wunused-variable]\n",
            "     78 |     auto result = linear_bias_backward_cuda<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:273:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    273 |   AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND2\n",
            "    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
            "        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:75:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND2\n",
            "     75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp: In lambda function:\n",
            "  csrc/fused_dense.cpp:77:15: warning: unused variable d_b_ptr [-Wunused-variable]\n",
            "     77 |     scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();\n",
            "        |               ^~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:274:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    274 |   AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND2\n",
            "    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
            "        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:75:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND2\n",
            "     75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:78:10: warning: unused variable result [-Wunused-variable]\n",
            "     78 |     auto result = linear_bias_backward_cuda<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:274:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    274 |   AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND2\n",
            "    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
            "        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:75:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND2\n",
            "     75 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp: In function std::vector<at::Tensor> linear_gelu_linear_forward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor):\n",
            "  csrc/fused_dense.cpp:106:69: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    106 |   auto output1 = at::empty({batch_size, hidden_features}, input.type());\n",
            "        |                                                           ~~~~~~~~~~^~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n",
            "    222 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  csrc/fused_dense.cpp:107:69: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    107 |   auto gelu_in = at::empty({batch_size, hidden_features}, input.type());\n",
            "        |                                                           ~~~~~~~~~~^~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n",
            "    222 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  csrc/fused_dense.cpp:108:66: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    108 |   auto output2 = at::empty({batch_size, out_features}, input.type());\n",
            "        |                                                        ~~~~~~~~~~^~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n",
            "    222 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  csrc/fused_dense.cpp:111:54: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    111 |   auto lt_workspace = at::empty({1 << 22}, input.type());\n",
            "        |                                            ~~~~~~~~~~^~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n",
            "    222 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/ATen.h:11,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  csrc/fused_dense.cpp: In lambda function:\n",
            "  csrc/fused_dense.cpp:118:10: warning: unused variable result [-Wunused-variable]\n",
            "    118 |     auto result = linear_gelu_linear_forward_cuda<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:246:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    246 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:272:3: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES\n",
            "    272 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND2\n",
            "    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
            "        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:113:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND2\n",
            "    113 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_gelu_linear_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp: In lambda function:\n",
            "  csrc/fused_dense.cpp:118:10: warning: unused variable result [-Wunused-variable]\n",
            "    118 |     auto result = linear_gelu_linear_forward_cuda<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:247:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    247 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:272:3: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES\n",
            "    272 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND2\n",
            "    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
            "        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:113:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND2\n",
            "    113 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_gelu_linear_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp: In lambda function:\n",
            "  csrc/fused_dense.cpp:118:10: warning: unused variable result [-Wunused-variable]\n",
            "    118 |     auto result = linear_gelu_linear_forward_cuda<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:273:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    273 |   AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND2\n",
            "    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
            "        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:113:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND2\n",
            "    113 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_gelu_linear_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp: In lambda function:\n",
            "  csrc/fused_dense.cpp:118:10: warning: unused variable result [-Wunused-variable]\n",
            "    118 |     auto result = linear_gelu_linear_forward_cuda<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:274:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    274 |   AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND2\n",
            "    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
            "        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:113:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND2\n",
            "    113 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_gelu_linear_forward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp: In function std::vector<at::Tensor> linear_gelu_linear_backward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor):\n",
            "  csrc/fused_dense.cpp:149:72: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    149 |   auto d_weight1 = at::empty({hidden_features, in_features}, input.type());\n",
            "        |                                                              ~~~~~~~~~~^~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n",
            "    222 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  csrc/fused_dense.cpp:150:73: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    150 |   auto d_weight2 = at::empty({out_features, hidden_features}, input.type());\n",
            "        |                                                               ~~~~~~~~~~^~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n",
            "    222 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  csrc/fused_dense.cpp:151:57: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    151 |   auto d_bias1 = at::empty({hidden_features}, input.type());\n",
            "        |                                               ~~~~~~~~~~^~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n",
            "    222 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  csrc/fused_dense.cpp:152:54: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    152 |   auto d_bias2 = at::empty({out_features}, input.type());\n",
            "        |                                            ~~~~~~~~~~^~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n",
            "    222 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  csrc/fused_dense.cpp:153:65: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    153 |   auto d_input = at::empty({batch_size, in_features}, input.type());\n",
            "        |                                                       ~~~~~~~~~~^~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n",
            "    222 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  csrc/fused_dense.cpp:154:71: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    154 |   auto d_output1 = at::empty({batch_size, hidden_features}, input.type());\n",
            "        |                                                             ~~~~~~~~~~^~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n",
            "    222 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  csrc/fused_dense.cpp:157:54: warning: at::DeprecatedTypeProperties& at::Tensor::type() const is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "    157 |   auto lt_workspace = at::empty({1 << 22}, input.type());\n",
            "        |                                            ~~~~~~~~~~^~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/TensorBody.h:222:30: note: declared here\n",
            "    222 |   DeprecatedTypeProperties & type() const {\n",
            "        |                              ^~~~\n",
            "  In file included from /usr/local/lib/python3.10/dist-packages/torch/include/ATen/ATen.h:11,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:4,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:9,\n",
            "                   from /usr/local/lib/python3.10/dist-packages/torch/include/torch/extension.h:4,\n",
            "                   from csrc/fused_dense.cpp:1:\n",
            "  csrc/fused_dense.cpp: In lambda function:\n",
            "  csrc/fused_dense.cpp:163:10: warning: unused variable result [-Wunused-variable]\n",
            "    163 |     auto result = linear_gelu_linear_backward_cuda<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:246:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    246 |   AT_DISPATCH_CASE(at::ScalarType::Double, __VA_ARGS__) \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:272:3: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES\n",
            "    272 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND2\n",
            "    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
            "        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:159:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND2\n",
            "    159 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp: In lambda function:\n",
            "  csrc/fused_dense.cpp:163:10: warning: unused variable result [-Wunused-variable]\n",
            "    163 |     auto result = linear_gelu_linear_backward_cuda<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:247:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    247 |   AT_DISPATCH_CASE(at::ScalarType::Float, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:272:3: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES\n",
            "    272 |   AT_DISPATCH_CASE_FLOATING_TYPES(__VA_ARGS__)                              \\\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND2\n",
            "    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
            "        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:159:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND2\n",
            "    159 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp: In lambda function:\n",
            "  csrc/fused_dense.cpp:163:10: warning: unused variable result [-Wunused-variable]\n",
            "    163 |     auto result = linear_gelu_linear_backward_cuda<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:273:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    273 |   AT_DISPATCH_CASE(SCALARTYPE1, __VA_ARGS__)                                \\\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND2\n",
            "    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
            "        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:159:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND2\n",
            "    159 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp: In lambda function:\n",
            "  csrc/fused_dense.cpp:163:10: warning: unused variable result [-Wunused-variable]\n",
            "    163 |     auto result = linear_gelu_linear_backward_cuda<scalar_t>(\n",
            "        |          ^~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:234:7: note: in definition of macro AT_DISPATCH_SWITCH\n",
            "    234 |       __VA_ARGS__                                                           \\\n",
            "        |       ^~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:87:3: note: in expansion of macro AT_PRIVATE_CASE_TYPE_USING_HINT\n",
            "     87 |   AT_PRIVATE_CASE_TYPE_USING_HINT(enum_type, scalar_t, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:274:3: note: in expansion of macro AT_DISPATCH_CASE\n",
            "    274 |   AT_DISPATCH_CASE(SCALARTYPE2, __VA_ARGS__)\n",
            "        |   ^~~~~~~~~~~~~~~~\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/Dispatch.h:281:7: note: in expansion of macro AT_DISPATCH_CASE_FLOATING_TYPES_AND2\n",
            "    281 |       AT_DISPATCH_CASE_FLOATING_TYPES_AND2(    \\\n",
            "        |       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  csrc/fused_dense.cpp:159:3: note: in expansion of macro AT_DISPATCH_FLOATING_TYPES_AND2\n",
            "    159 |   AT_DISPATCH_FLOATING_TYPES_AND2(at::ScalarType::Half, at::ScalarType::BFloat16, input.scalar_type(), \"linear_bias_backward\", [&] {\n",
            "        |   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "  /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/fused_dense_cuda.cu -o build/temp.linux-x86_64-cpython-310/csrc/fused_dense_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=fused_dense_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n",
            "\n",
            "  x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/csrc/fused_dense.o build/temp.linux-x86_64-cpython-310/csrc/fused_dense_cuda.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/fused_dense_cuda.cpython-310-x86_64-linux-gnu.so\n",
            "  building 'scaled_upper_triang_masked_softmax_cuda' extension\n",
            "  creating build/temp.linux-x86_64-cpython-310/csrc/megatron\n",
            "  x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/apex/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/megatron/scaled_upper_triang_masked_softmax.cpp -o build/temp.linux-x86_64-cpython-310/csrc/megatron/scaled_upper_triang_masked_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=scaled_upper_triang_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "  /usr/local/cuda/bin/nvcc -I/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/apex/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/megatron/scaled_upper_triang_masked_softmax_cuda.cu -o build/temp.linux-x86_64-cpython-310/csrc/megatron/scaled_upper_triang_masked_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=scaled_upper_triang_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n",
            "\n",
            "  x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/csrc/megatron/scaled_upper_triang_masked_softmax.o build/temp.linux-x86_64-cpython-310/csrc/megatron/scaled_upper_triang_masked_softmax_cuda.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/scaled_upper_triang_masked_softmax_cuda.cpython-310-x86_64-linux-gnu.so\n",
            "  building 'generic_scaled_masked_softmax_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/apex/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/megatron/generic_scaled_masked_softmax.cpp -o build/temp.linux-x86_64-cpython-310/csrc/megatron/generic_scaled_masked_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=generic_scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "  /usr/local/cuda/bin/nvcc -I/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/apex/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/megatron/generic_scaled_masked_softmax_cuda.cu -o build/temp.linux-x86_64-cpython-310/csrc/megatron/generic_scaled_masked_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=generic_scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n",
            "\n",
            "  x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/csrc/megatron/generic_scaled_masked_softmax.o build/temp.linux-x86_64-cpython-310/csrc/megatron/generic_scaled_masked_softmax_cuda.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/generic_scaled_masked_softmax_cuda.cpython-310-x86_64-linux-gnu.so\n",
            "  building 'scaled_masked_softmax_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/apex/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/megatron/scaled_masked_softmax.cpp -o build/temp.linux-x86_64-cpython-310/csrc/megatron/scaled_masked_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "  /usr/local/cuda/bin/nvcc -I/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/apex/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/megatron/scaled_masked_softmax_cuda.cu -o build/temp.linux-x86_64-cpython-310/csrc/megatron/scaled_masked_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n",
            "\n",
            "  x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/csrc/megatron/scaled_masked_softmax.o build/temp.linux-x86_64-cpython-310/csrc/megatron/scaled_masked_softmax_cuda.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/scaled_masked_softmax_cuda.cpython-310-x86_64-linux-gnu.so\n",
            "  building 'scaled_softmax_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/apex/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/megatron/scaled_softmax.cpp -o build/temp.linux-x86_64-cpython-310/csrc/megatron/scaled_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=scaled_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "  /usr/local/cuda/bin/nvcc -I/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/apex/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/megatron/scaled_softmax_cuda.cu -o build/temp.linux-x86_64-cpython-310/csrc/megatron/scaled_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=scaled_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n",
            "\n",
            "  x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/csrc/megatron/scaled_softmax.o build/temp.linux-x86_64-cpython-310/csrc/megatron/scaled_softmax_cuda.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/scaled_softmax_cuda.cpython-310-x86_64-linux-gnu.so\n",
            "  building 'fused_weight_gradient_mlp_cuda' extension\n",
            "  x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/apex/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/megatron/fused_weight_gradient_dense.cpp -o build/temp.linux-x86_64-cpython-310/csrc/megatron/fused_weight_gradient_dense.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=fused_weight_gradient_mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "  /usr/local/cuda/bin/nvcc -I/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/apex/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/megatron/fused_weight_gradient_dense_16bit_prec_cuda.cu -o build/temp.linux-x86_64-cpython-310/csrc/megatron/fused_weight_gradient_dense_16bit_prec_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=fused_weight_gradient_mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n",
            "\n",
            "  /usr/local/cuda/bin/nvcc -I/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/apex/csrc -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.10 -c csrc/megatron/fused_weight_gradient_dense_cuda.cu -o build/temp.linux-x86_64-cpython-310/csrc/megatron/fused_weight_gradient_dense_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_90,code=sm_90 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=fused_weight_gradient_mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=size_t, one_sided=false, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/core/TensorImpl.h(77): here\n",
            "\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/c10/util/irange.h(54): warning #186-D: pointless comparison of unsigned integer with zero\n",
            "            detected during:\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator==(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  (61): here\n",
            "              instantiation of \"__nv_bool c10::detail::integer_iterator<I, one_sided, <unnamed>>::operator!=(const c10::detail::integer_iterator<I, one_sided, <unnamed>> &) const [with I=std::size_t, one_sided=true, <unnamed>=0]\"\n",
            "  /usr/local/lib/python3.10/dist-packages/torch/include/ATen/core/qualified_name.h(73): here\n",
            "\n",
            "  x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/csrc/megatron/fused_weight_gradient_dense.o build/temp.linux-x86_64-cpython-310/csrc/megatron/fused_weight_gradient_dense_16bit_prec_cuda.o build/temp.linux-x86_64-cpython-310/csrc/megatron/fused_weight_gradient_dense_cuda.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-310/fused_weight_gradient_mlp_cuda.cpython-310-x86_64-linux-gnu.so\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/apex\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/__init__.py -> build/bdist.linux-x86_64/wheel/apex\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/_autocast_utils.py -> build/bdist.linux-x86_64/wheel/apex\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/RNN/RNNBackend.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/RNN/__init__.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/RNN/cells.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/RNN/models.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/amp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/amp/__version__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/amp/_amp_state.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/amp/_initialize.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/amp/_process_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/amp/amp.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/amp/compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/amp/frontend.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/amp/handle.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/amp/opt.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/amp/rnn_compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/amp/scaler.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/amp/utils.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/amp/wrap.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/amp/lists/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/amp/lists/functional_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/amp/lists/tensor_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/amp/lists/torch_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/bottleneck/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/bottleneck/bottleneck.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/bottleneck/halo_exchangers.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/bottleneck/test.py -> build/bdist.linux-x86_64/wheel/apex/contrib/bottleneck\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/clip_grad\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/clip_grad/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/clip_grad\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/clip_grad/clip_grad.py -> build/bdist.linux-x86_64/wheel/apex/contrib/clip_grad\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/conv_bias_relu\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/conv_bias_relu/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/conv_bias_relu\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/conv_bias_relu/conv_bias_relu.py -> build/bdist.linux-x86_64/wheel/apex/contrib/conv_bias_relu\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/cudnn_gbn\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/cudnn_gbn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/cudnn_gbn\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/cudnn_gbn/batch_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/cudnn_gbn\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/fmha/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/fmha/fmha.py -> build/bdist.linux-x86_64/wheel/apex/contrib/fmha\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/focal_loss\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/focal_loss/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/focal_loss\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/focal_loss/focal_loss.py -> build/bdist.linux-x86_64/wheel/apex/contrib/focal_loss\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/group_norm\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/group_norm/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/group_norm\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/group_norm/group_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/group_norm\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/groupbn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/groupbn/batch_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/index_mul_2d\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/index_mul_2d/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/index_mul_2d\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/index_mul_2d/index_mul_2d.py -> build/bdist.linux-x86_64/wheel/apex/contrib/index_mul_2d\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/layer_norm/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/layer_norm/layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/layer_norm\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn/self_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/optimizers/distributed_fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/optimizers/distributed_fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/optimizers/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/peer_memory\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/peer_memory/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/peer_memory\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/peer_memory/peer_halo_exchanger_1d.py -> build/bdist.linux-x86_64/wheel/apex/contrib/peer_memory\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/peer_memory/peer_memory.py -> build/bdist.linux-x86_64/wheel/apex/contrib/peer_memory\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity/asp.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity/permutation_lib.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity/sparse_masklib.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity/permutation_search_kernels/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity/permutation_search_kernels/channel_swap.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity/permutation_search_kernels\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/test\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/bottleneck\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/bottleneck/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/bottleneck\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/bottleneck/test_bottleneck_module.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/bottleneck\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/clip_grad\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/clip_grad/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/clip_grad\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/clip_grad/test_clip_grad.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/clip_grad\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/conv_bias_relu\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/conv_bias_relu/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/conv_bias_relu\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/conv_bias_relu/test_conv_bias_relu.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/conv_bias_relu\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/cudnn_gbn\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/cudnn_gbn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/cudnn_gbn\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/cudnn_gbn\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/fmha\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/fmha/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/fmha\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/fmha/test_fmha.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/fmha\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/focal_loss\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/focal_loss/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/focal_loss\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/focal_loss/test_focal_loss.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/focal_loss\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/group_norm\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/group_norm/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/group_norm\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/group_norm/test_group_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/group_norm\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/index_mul_2d\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/index_mul_2d/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/index_mul_2d\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/index_mul_2d/test_index_mul_2d.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/index_mul_2d\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/layer_norm\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/layer_norm/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/layer_norm\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/layer_norm/test_fast_layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/layer_norm\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/multihead_attn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/multihead_attn/test_encdec_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/multihead_attn/test_mha_fused_softmax.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/multihead_attn/test_self_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/multihead_attn\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/optimizers\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/optimizers\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/optimizers/test_dist_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/optimizers\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/optimizers/test_distributed_fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/optimizers\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/peer_memory\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/peer_memory/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/peer_memory\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/peer_memory/test_peer_halo_exchange_module.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/peer_memory\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/transducer\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/transducer/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/transducer\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/transducer/test_transducer_joint.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/transducer\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/transducer/test_transducer_loss.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/transducer\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/test/xentropy\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/xentropy/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/xentropy\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/test/xentropy/test_label_smoothing.py -> build/bdist.linux-x86_64/wheel/apex/contrib/test/xentropy\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/transducer/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/transducer/_transducer_ref.py -> build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/transducer/transducer.py -> build/bdist.linux-x86_64/wheel/apex/contrib/transducer\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/xentropy/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/contrib/xentropy/softmax_xentropy.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/fp16_utils/__init__.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/fp16_utils/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/fp16_utils/fp16util.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/fp16_utils/loss_scaler.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/fused_dense\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/fused_dense/__init__.py -> build/bdist.linux-x86_64/wheel/apex/fused_dense\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/fused_dense/fused_dense.py -> build/bdist.linux-x86_64/wheel/apex/fused_dense\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/mlp\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/mlp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/mlp\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/mlp/mlp.py -> build/bdist.linux-x86_64/wheel/apex/mlp\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/multi_tensor_apply/__init__.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/multi_tensor_apply/multi_tensor_apply.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/normalization\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/normalization/__init__.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/normalization/fused_layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/optimizers/fused_adagrad.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/optimizers/fused_mixed_precision_lamb.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/optimizers/fused_novograd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/parallel/LARC.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/parallel/__init__.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/parallel/distributed.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/parallel/multiproc.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/parallel/optimized_sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/parallel/optimized_sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/parallel/sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/parallel/sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/transformer\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/_ucc_util.py -> build/bdist.linux-x86_64/wheel/apex/transformer\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/enums.py -> build/bdist.linux-x86_64/wheel/apex/transformer\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/log_util.py -> build/bdist.linux-x86_64/wheel/apex/transformer\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/microbatches.py -> build/bdist.linux-x86_64/wheel/apex/transformer\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/parallel_state.py -> build/bdist.linux-x86_64/wheel/apex/transformer\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/utils.py -> build/bdist.linux-x86_64/wheel/apex/transformer\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/transformer/_data\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/_data/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/_data\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/_data/_batchsampler.py -> build/bdist.linux-x86_64/wheel/apex/transformer/_data\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/transformer/amp\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/amp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/amp\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/amp/grad_scaler.py -> build/bdist.linux-x86_64/wheel/apex/transformer/amp\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/transformer/functional\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/functional/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/functional\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/functional/fused_softmax.py -> build/bdist.linux-x86_64/wheel/apex/transformer/functional\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/transformer/layers\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/layers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/layers\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/layers/layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/transformer/layers\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel/_timers.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel/p2p_communication.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel/utils.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel/schedules/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel/schedules/common.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py -> build/bdist.linux-x86_64/wheel/apex/transformer/pipeline_parallel/schedules\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel/cross_entropy.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel/data.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel/layers.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel/mappings.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel/memory.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel/random.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/tensor_parallel/utils.py -> build/bdist.linux-x86_64/wheel/apex/transformer/tensor_parallel\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/transformer/testing\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/testing/__init__.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/testing/arguments.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/testing/commons.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/testing/distributed_test_base.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/testing/global_vars.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/testing/standalone_bert.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/testing/standalone_gpt.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex/transformer/testing/standalone_transformer_lm.py -> build/bdist.linux-x86_64/wheel/apex/transformer/testing\n",
            "  copying build/lib.linux-x86_64-cpython-310/apex_C.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n",
            "  copying build/lib.linux-x86_64-cpython-310/amp_C.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n",
            "  copying build/lib.linux-x86_64-cpython-310/syncbn.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n",
            "  copying build/lib.linux-x86_64-cpython-310/fused_layer_norm_cuda.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n",
            "  copying build/lib.linux-x86_64-cpython-310/mlp_cuda.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n",
            "  copying build/lib.linux-x86_64-cpython-310/fused_dense_cuda.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n",
            "  copying build/lib.linux-x86_64-cpython-310/scaled_upper_triang_masked_softmax_cuda.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n",
            "  copying build/lib.linux-x86_64-cpython-310/generic_scaled_masked_softmax_cuda.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n",
            "  copying build/lib.linux-x86_64-cpython-310/scaled_masked_softmax_cuda.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n",
            "  copying build/lib.linux-x86_64-cpython-310/scaled_softmax_cuda.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n",
            "  copying build/lib.linux-x86_64-cpython-310/fused_weight_gradient_mlp_cuda.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/wheel\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  creating apex.egg-info\n",
            "  writing apex.egg-info/PKG-INFO\n",
            "  writing dependency_links to apex.egg-info/dependency_links.txt\n",
            "  writing requirements to apex.egg-info/requires.txt\n",
            "  writing top-level names to apex.egg-info/top_level.txt\n",
            "  writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "  reading manifest file 'apex.egg-info/SOURCES.txt'\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "  Copying apex.egg-info to build/bdist.linux-x86_64/wheel/apex-0.1-py3.10.egg-info\n",
            "  running install_scripts\n",
            "  creating build/bdist.linux-x86_64/wheel/apex-0.1.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-d3ttvz1h/.tmp-eld9dset/apex-0.1-cp310-cp310-linux_x86_64.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'amp_C.cpython-310-x86_64-linux-gnu.so'\n",
            "  adding 'apex_C.cpython-310-x86_64-linux-gnu.so'\n",
            "  adding 'fused_dense_cuda.cpython-310-x86_64-linux-gnu.so'\n",
            "  adding 'fused_layer_norm_cuda.cpython-310-x86_64-linux-gnu.so'\n",
            "  adding 'fused_weight_gradient_mlp_cuda.cpython-310-x86_64-linux-gnu.so'\n",
            "  adding 'generic_scaled_masked_softmax_cuda.cpython-310-x86_64-linux-gnu.so'\n",
            "  adding 'mlp_cuda.cpython-310-x86_64-linux-gnu.so'\n",
            "  adding 'scaled_masked_softmax_cuda.cpython-310-x86_64-linux-gnu.so'\n",
            "  adding 'scaled_softmax_cuda.cpython-310-x86_64-linux-gnu.so'\n",
            "  adding 'scaled_upper_triang_masked_softmax_cuda.cpython-310-x86_64-linux-gnu.so'\n",
            "  adding 'syncbn.cpython-310-x86_64-linux-gnu.so'\n",
            "  adding 'apex/__init__.py'\n",
            "  adding 'apex/_autocast_utils.py'\n",
            "  adding 'apex/RNN/RNNBackend.py'\n",
            "  adding 'apex/RNN/__init__.py'\n",
            "  adding 'apex/RNN/cells.py'\n",
            "  adding 'apex/RNN/models.py'\n",
            "  adding 'apex/amp/__init__.py'\n",
            "  adding 'apex/amp/__version__.py'\n",
            "  adding 'apex/amp/_amp_state.py'\n",
            "  adding 'apex/amp/_initialize.py'\n",
            "  adding 'apex/amp/_process_optimizer.py'\n",
            "  adding 'apex/amp/amp.py'\n",
            "  adding 'apex/amp/compat.py'\n",
            "  adding 'apex/amp/frontend.py'\n",
            "  adding 'apex/amp/handle.py'\n",
            "  adding 'apex/amp/opt.py'\n",
            "  adding 'apex/amp/rnn_compat.py'\n",
            "  adding 'apex/amp/scaler.py'\n",
            "  adding 'apex/amp/utils.py'\n",
            "  adding 'apex/amp/wrap.py'\n",
            "  adding 'apex/amp/lists/__init__.py'\n",
            "  adding 'apex/amp/lists/functional_overrides.py'\n",
            "  adding 'apex/amp/lists/tensor_overrides.py'\n",
            "  adding 'apex/amp/lists/torch_overrides.py'\n",
            "  adding 'apex/contrib/__init__.py'\n",
            "  adding 'apex/contrib/bottleneck/__init__.py'\n",
            "  adding 'apex/contrib/bottleneck/bottleneck.py'\n",
            "  adding 'apex/contrib/bottleneck/halo_exchangers.py'\n",
            "  adding 'apex/contrib/bottleneck/test.py'\n",
            "  adding 'apex/contrib/clip_grad/__init__.py'\n",
            "  adding 'apex/contrib/clip_grad/clip_grad.py'\n",
            "  adding 'apex/contrib/conv_bias_relu/__init__.py'\n",
            "  adding 'apex/contrib/conv_bias_relu/conv_bias_relu.py'\n",
            "  adding 'apex/contrib/cudnn_gbn/__init__.py'\n",
            "  adding 'apex/contrib/cudnn_gbn/batch_norm.py'\n",
            "  adding 'apex/contrib/fmha/__init__.py'\n",
            "  adding 'apex/contrib/fmha/fmha.py'\n",
            "  adding 'apex/contrib/focal_loss/__init__.py'\n",
            "  adding 'apex/contrib/focal_loss/focal_loss.py'\n",
            "  adding 'apex/contrib/group_norm/__init__.py'\n",
            "  adding 'apex/contrib/group_norm/group_norm.py'\n",
            "  adding 'apex/contrib/groupbn/__init__.py'\n",
            "  adding 'apex/contrib/groupbn/batch_norm.py'\n",
            "  adding 'apex/contrib/index_mul_2d/__init__.py'\n",
            "  adding 'apex/contrib/index_mul_2d/index_mul_2d.py'\n",
            "  adding 'apex/contrib/layer_norm/__init__.py'\n",
            "  adding 'apex/contrib/layer_norm/layer_norm.py'\n",
            "  adding 'apex/contrib/multihead_attn/__init__.py'\n",
            "  adding 'apex/contrib/multihead_attn/encdec_multihead_attn.py'\n",
            "  adding 'apex/contrib/multihead_attn/encdec_multihead_attn_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/mask_softmax_dropout_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/self_multihead_attn.py'\n",
            "  adding 'apex/contrib/multihead_attn/self_multihead_attn_func.py'\n",
            "  adding 'apex/contrib/optimizers/__init__.py'\n",
            "  adding 'apex/contrib/optimizers/distributed_fused_adam.py'\n",
            "  adding 'apex/contrib/optimizers/distributed_fused_lamb.py'\n",
            "  adding 'apex/contrib/optimizers/fp16_optimizer.py'\n",
            "  adding 'apex/contrib/optimizers/fused_adam.py'\n",
            "  adding 'apex/contrib/optimizers/fused_lamb.py'\n",
            "  adding 'apex/contrib/optimizers/fused_sgd.py'\n",
            "  adding 'apex/contrib/peer_memory/__init__.py'\n",
            "  adding 'apex/contrib/peer_memory/peer_halo_exchanger_1d.py'\n",
            "  adding 'apex/contrib/peer_memory/peer_memory.py'\n",
            "  adding 'apex/contrib/sparsity/__init__.py'\n",
            "  adding 'apex/contrib/sparsity/asp.py'\n",
            "  adding 'apex/contrib/sparsity/permutation_lib.py'\n",
            "  adding 'apex/contrib/sparsity/sparse_masklib.py'\n",
            "  adding 'apex/contrib/sparsity/permutation_search_kernels/__init__.py'\n",
            "  adding 'apex/contrib/sparsity/permutation_search_kernels/call_permutation_search_kernels.py'\n",
            "  adding 'apex/contrib/sparsity/permutation_search_kernels/channel_swap.py'\n",
            "  adding 'apex/contrib/sparsity/permutation_search_kernels/exhaustive_search.py'\n",
            "  adding 'apex/contrib/sparsity/permutation_search_kernels/permutation_utilities.py'\n",
            "  adding 'apex/contrib/test/__init__.py'\n",
            "  adding 'apex/contrib/test/bottleneck/__init__.py'\n",
            "  adding 'apex/contrib/test/bottleneck/test_bottleneck_module.py'\n",
            "  adding 'apex/contrib/test/clip_grad/__init__.py'\n",
            "  adding 'apex/contrib/test/clip_grad/test_clip_grad.py'\n",
            "  adding 'apex/contrib/test/conv_bias_relu/__init__.py'\n",
            "  adding 'apex/contrib/test/conv_bias_relu/test_conv_bias_relu.py'\n",
            "  adding 'apex/contrib/test/cudnn_gbn/__init__.py'\n",
            "  adding 'apex/contrib/test/cudnn_gbn/test_cudnn_gbn_with_two_gpus.py'\n",
            "  adding 'apex/contrib/test/fmha/__init__.py'\n",
            "  adding 'apex/contrib/test/fmha/test_fmha.py'\n",
            "  adding 'apex/contrib/test/focal_loss/__init__.py'\n",
            "  adding 'apex/contrib/test/focal_loss/test_focal_loss.py'\n",
            "  adding 'apex/contrib/test/group_norm/__init__.py'\n",
            "  adding 'apex/contrib/test/group_norm/test_group_norm.py'\n",
            "  adding 'apex/contrib/test/index_mul_2d/__init__.py'\n",
            "  adding 'apex/contrib/test/index_mul_2d/test_index_mul_2d.py'\n",
            "  adding 'apex/contrib/test/layer_norm/__init__.py'\n",
            "  adding 'apex/contrib/test/layer_norm/test_fast_layer_norm.py'\n",
            "  adding 'apex/contrib/test/multihead_attn/__init__.py'\n",
            "  adding 'apex/contrib/test/multihead_attn/test_encdec_multihead_attn.py'\n",
            "  adding 'apex/contrib/test/multihead_attn/test_encdec_multihead_attn_norm_add.py'\n",
            "  adding 'apex/contrib/test/multihead_attn/test_fast_self_multihead_attn_bias.py'\n",
            "  adding 'apex/contrib/test/multihead_attn/test_mha_fused_softmax.py'\n",
            "  adding 'apex/contrib/test/multihead_attn/test_self_multihead_attn.py'\n",
            "  adding 'apex/contrib/test/multihead_attn/test_self_multihead_attn_norm_add.py'\n",
            "  adding 'apex/contrib/test/optimizers/__init__.py'\n",
            "  adding 'apex/contrib/test/optimizers/test_dist_adam.py'\n",
            "  adding 'apex/contrib/test/optimizers/test_distributed_fused_lamb.py'\n",
            "  adding 'apex/contrib/test/peer_memory/__init__.py'\n",
            "  adding 'apex/contrib/test/peer_memory/test_peer_halo_exchange_module.py'\n",
            "  adding 'apex/contrib/test/transducer/__init__.py'\n",
            "  adding 'apex/contrib/test/transducer/test_transducer_joint.py'\n",
            "  adding 'apex/contrib/test/transducer/test_transducer_loss.py'\n",
            "  adding 'apex/contrib/test/xentropy/__init__.py'\n",
            "  adding 'apex/contrib/test/xentropy/test_label_smoothing.py'\n",
            "  adding 'apex/contrib/transducer/__init__.py'\n",
            "  adding 'apex/contrib/transducer/_transducer_ref.py'\n",
            "  adding 'apex/contrib/transducer/transducer.py'\n",
            "  adding 'apex/contrib/xentropy/__init__.py'\n",
            "  adding 'apex/contrib/xentropy/softmax_xentropy.py'\n",
            "  adding 'apex/fp16_utils/__init__.py'\n",
            "  adding 'apex/fp16_utils/fp16_optimizer.py'\n",
            "  adding 'apex/fp16_utils/fp16util.py'\n",
            "  adding 'apex/fp16_utils/loss_scaler.py'\n",
            "  adding 'apex/fused_dense/__init__.py'\n",
            "  adding 'apex/fused_dense/fused_dense.py'\n",
            "  adding 'apex/mlp/__init__.py'\n",
            "  adding 'apex/mlp/mlp.py'\n",
            "  adding 'apex/multi_tensor_apply/__init__.py'\n",
            "  adding 'apex/multi_tensor_apply/multi_tensor_apply.py'\n",
            "  adding 'apex/normalization/__init__.py'\n",
            "  adding 'apex/normalization/fused_layer_norm.py'\n",
            "  adding 'apex/optimizers/__init__.py'\n",
            "  adding 'apex/optimizers/fused_adagrad.py'\n",
            "  adding 'apex/optimizers/fused_adam.py'\n",
            "  adding 'apex/optimizers/fused_lamb.py'\n",
            "  adding 'apex/optimizers/fused_mixed_precision_lamb.py'\n",
            "  adding 'apex/optimizers/fused_novograd.py'\n",
            "  adding 'apex/optimizers/fused_sgd.py'\n",
            "  adding 'apex/parallel/LARC.py'\n",
            "  adding 'apex/parallel/__init__.py'\n",
            "  adding 'apex/parallel/distributed.py'\n",
            "  adding 'apex/parallel/multiproc.py'\n",
            "  adding 'apex/parallel/optimized_sync_batchnorm.py'\n",
            "  adding 'apex/parallel/optimized_sync_batchnorm_kernel.py'\n",
            "  adding 'apex/parallel/sync_batchnorm.py'\n",
            "  adding 'apex/parallel/sync_batchnorm_kernel.py'\n",
            "  adding 'apex/transformer/__init__.py'\n",
            "  adding 'apex/transformer/_ucc_util.py'\n",
            "  adding 'apex/transformer/enums.py'\n",
            "  adding 'apex/transformer/log_util.py'\n",
            "  adding 'apex/transformer/microbatches.py'\n",
            "  adding 'apex/transformer/parallel_state.py'\n",
            "  adding 'apex/transformer/utils.py'\n",
            "  adding 'apex/transformer/_data/__init__.py'\n",
            "  adding 'apex/transformer/_data/_batchsampler.py'\n",
            "  adding 'apex/transformer/amp/__init__.py'\n",
            "  adding 'apex/transformer/amp/grad_scaler.py'\n",
            "  adding 'apex/transformer/functional/__init__.py'\n",
            "  adding 'apex/transformer/functional/fused_softmax.py'\n",
            "  adding 'apex/transformer/layers/__init__.py'\n",
            "  adding 'apex/transformer/layers/layer_norm.py'\n",
            "  adding 'apex/transformer/pipeline_parallel/__init__.py'\n",
            "  adding 'apex/transformer/pipeline_parallel/_timers.py'\n",
            "  adding 'apex/transformer/pipeline_parallel/p2p_communication.py'\n",
            "  adding 'apex/transformer/pipeline_parallel/utils.py'\n",
            "  adding 'apex/transformer/pipeline_parallel/schedules/__init__.py'\n",
            "  adding 'apex/transformer/pipeline_parallel/schedules/common.py'\n",
            "  adding 'apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py'\n",
            "  adding 'apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py'\n",
            "  adding 'apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py'\n",
            "  adding 'apex/transformer/tensor_parallel/__init__.py'\n",
            "  adding 'apex/transformer/tensor_parallel/cross_entropy.py'\n",
            "  adding 'apex/transformer/tensor_parallel/data.py'\n",
            "  adding 'apex/transformer/tensor_parallel/layers.py'\n",
            "  adding 'apex/transformer/tensor_parallel/mappings.py'\n",
            "  adding 'apex/transformer/tensor_parallel/memory.py'\n",
            "  adding 'apex/transformer/tensor_parallel/random.py'\n",
            "  adding 'apex/transformer/tensor_parallel/utils.py'\n",
            "  adding 'apex/transformer/testing/__init__.py'\n",
            "  adding 'apex/transformer/testing/arguments.py'\n",
            "  adding 'apex/transformer/testing/commons.py'\n",
            "  adding 'apex/transformer/testing/distributed_test_base.py'\n",
            "  adding 'apex/transformer/testing/global_vars.py'\n",
            "  adding 'apex/transformer/testing/standalone_bert.py'\n",
            "  adding 'apex/transformer/testing/standalone_gpt.py'\n",
            "  adding 'apex/transformer/testing/standalone_transformer_lm.py'\n",
            "  adding 'apex-0.1.dist-info/LICENSE'\n",
            "  adding 'apex-0.1.dist-info/METADATA'\n",
            "  adding 'apex-0.1.dist-info/WHEEL'\n",
            "  adding 'apex-0.1.dist-info/top_level.txt'\n",
            "  adding 'apex-0.1.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "  Building wheel for apex (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for apex: filename=apex-0.1-cp310-cp310-linux_x86_64.whl size=32236627 sha256=8d0f5d57c52dd93eda408da02959a0dc706e869e8b8c56c93333c8ac6452e593\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5ep_u209/wheels/af/00/73/0e6dbf1a46334a3c4c0360bcdaf1085990eaf534b2bb7efefb\n",
            "Successfully built apex\n",
            "Installing collected packages: apex\n",
            "Successfully installed apex-0.1\n"
          ]
        }
      ],
      "source": [
        "#!git clone https://github.com/NVIDIA/apex\n",
        "%cd apex\n",
        "# if pip >= 23.1 (ref: https://pip.pypa.io/en/stable/news/#v23-1) which supports multiple `--config-settings` with the same key...\n",
        "!pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation --config-settings \"--build-option=--cpp_ext\" --config-settings \"--build-option=--cuda_ext\" ./\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcWqZ45pecYH"
      },
      "source": [
        "# Utility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5OG31gwjegsb"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "import pandas as pd\n",
        "import subprocess\n",
        "\n",
        "# salva in pix2pixHD/results le metriche\n",
        "def calculate_metrics(synth_folder, gt_folder,type):\n",
        "    # Ottieni la lista dei nomi di file dalle cartelle\n",
        "\n",
        "    image_files = os.listdir(synth_folder)\n",
        "\n",
        "    # Filtra i nomi dei file per rimuovere quelli che contengono \"input_label\"\n",
        "    filtered_image_files = [file for file in image_files if \"input_label\" not in file]\n",
        "\n",
        "    # Inizializza liste per memorizzare i risultati\n",
        "    mse_scores = []\n",
        "    ssim_scores = []\n",
        "    psnr_scores = []\n",
        "\n",
        "    piqe_scores = []\n",
        "    niqe_scores = []\n",
        "\n",
        "    # Itera attraverso le immagini e calcola le metriche\n",
        "    for image_file in filtered_image_files:\n",
        "        # Carica le immagini\n",
        "\n",
        "        synth_image = cv2.imread(os.path.join(synth_folder, image_file))\n",
        "        gt_image = cv2.imread(os.path.join(gt_folder, image_file[:4]+\".png\"))\n",
        "\n",
        "        # Ridimensiona l'immagine sintetizzata alla stessa dimensione dell'immagine originale\n",
        "        synth_image = cv2.resize(synth_image, (gt_image.shape[1], gt_image.shape[0]))\n",
        "\n",
        "        # Calcola le metriche con skimage\n",
        "        mse = np.mean((gt_image - synth_image) ** 2)\n",
        "        ssim_score = ssim(gt_image, synth_image, channel_axis=2)\n",
        "        psnr_score = psnr(gt_image, synth_image)\n",
        "\n",
        "        # Calcola le metriche con piqe e niqe (high score means low quality)\n",
        "        synth_array = synth_image / 255.0\n",
        "\n",
        "        # Esegui il comando e cattura l'output\n",
        "        completed_process = subprocess.run(['python', '/content/drive/MyDrive/Haze-Fog-suppression/NRVQA/test.py', '--mode', 'piqe', f'--path={os.path.join(synth_folder, image_file)}'], stdout=subprocess.PIPE, text=True)\n",
        "\n",
        "        # Ottieni l'output dall'oggetto CompletedProcess\n",
        "        output = completed_process.stdout\n",
        "\n",
        "        # Estrai lo score dalla stringa di output\n",
        "        score_line = [line for line in output.splitlines() if 'score:' in line][0]\n",
        "        piqe_score = float(score_line.split(':')[-1])\n",
        "\n",
        "        # Esegui il comando e cattura l'output\n",
        "        completed_process = subprocess.run(['python', '/content/drive/MyDrive/Haze-Fog-suppression/NRVQA/test.py', '--mode', 'niqe', f'--path={os.path.join(synth_folder, image_file)}'], stdout=subprocess.PIPE, text=True)\n",
        "\n",
        "        # Ottieni l'output dall'oggetto CompletedProcess\n",
        "        output = completed_process.stdout\n",
        "\n",
        "        # Estrai lo score dalla stringa di output\n",
        "        score_line = [line for line in output.splitlines() if 'score:' in line][0]\n",
        "        niqe_score = float(score_line.split(':')[-1])\n",
        "\n",
        "        # Aggiungi i risultati alle liste\n",
        "        mse_scores.append(mse)\n",
        "        ssim_scores.append(ssim_score)\n",
        "        psnr_scores.append(psnr_score)\n",
        "        piqe_scores.append(piqe_score)\n",
        "        niqe_scores.append(niqe_score)\n",
        "\n",
        "\n",
        "    # Creazione del dataframe\n",
        "    data = {\n",
        "        'Image': filtered_image_files,  # Nomi dei file delle immagini generate\n",
        "        'MSE': mse_scores,\n",
        "        'SSIM': ssim_scores,\n",
        "        'PSNR': psnr_scores,\n",
        "        'PIQE': piqe_scores,\n",
        "        'NIQE': niqe_scores\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Calcolo dei valori medi\n",
        "    average_scores = df[['MSE', 'SSIM', 'PSNR', 'PIQE', 'NIQE']].mean()\n",
        "\n",
        "    # Aggiunta della riga con i valori medi al dataframe\n",
        "    average_scores_df = pd.DataFrame([average_scores], columns=['MSE', 'SSIM', 'PSNR', 'PIQE', 'NIQE'])\n",
        "    average_scores_df['Image'] = 'AVG'\n",
        "    # Aggiungi una riga vuota tra i risultati delle immagini e i valori medi\n",
        "    df = pd.concat([df, pd.DataFrame(columns=df.columns)], ignore_index=True)\n",
        "    df = pd.concat([df, average_scores_df], ignore_index=True)\n",
        "\n",
        "    # Salva il dataframe completo in un file CSV\n",
        "    df.to_csv(type + '_result.csv', index=False)\n",
        "\n",
        "def test_indoor_outdoor(indoor_synth_folder, indoor_original_folder, outdoor_synth_folder, outdoor_original_folder, type):\n",
        "  calculate_metrics(indoor_synth_folder, indoor_original_folder,type + \"_indoor\")\n",
        "  calculate_metrics(outdoor_synth_folder, outdoor_original_folder,type + \"_outdoor\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eqPZHOXEAfp"
      },
      "source": [
        "# Pix2PixHD download\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YoX7TkTS9MG",
        "outputId": "09120a1d-5280-4fed-f4ba-e3f727363778"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'pix2pixHD'...\n",
            "remote: Enumerating objects: 340, done.\u001b[K\n",
            "remote: Total 340 (delta 0), reused 0 (delta 0), pack-reused 340\u001b[K\n",
            "Receiving objects: 100% (340/340), 55.68 MiB | 20.18 MiB/s, done.\n",
            "Resolving deltas: 100% (156/156), done.\n",
            "Updating files: 100% (115/115), done.\n",
            "/content/drive/MyDrive/Haze-suppression/pix2pixHD\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/NVIDIA/pix2pixHD.git\n",
        "os.chdir(\"pix2pixHD\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKuREuwyAtxd"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"./checkpoints/label2city_1024p/\")\n",
        "os.chdir(\"./checkpoints/label2city_1024p/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "5VRByC-oFDWv",
        "outputId": "76edc983-ec8a-4868-c3e7-80a9d0229ce1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=1h9SykUnuZul7J3Nbms2QGH1wa85nbN2-&export=download\n",
            "To: /content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/checkpoints/label2city_1024p/latest_net_G.pth\n",
            "100%|| 732M/732M [00:11<00:00, 62.1MB/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'latest_net_G.pth'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "url = 'https://drive.google.com/u/0/uc?id=1h9SykUnuZul7J3Nbms2QGH1wa85nbN2-&export=download'\n",
        "output = 'latest_net_G.pth'\n",
        "gdown.download(url, output, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpELF8NXHBsE"
      },
      "outputs": [],
      "source": [
        "os.chdir(\"../..\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFdeWg-Sqj6O"
      },
      "source": [
        "# Pix2PixHD Train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxD4lD7grQjI",
        "outputId": "d19827ed-a782-4de0-c21d-187df1c9590b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1MeMU7hWD5WVMk25vU3ch5Ii3csnSydwf/Haze-Fog-suppression/pix2pixHD\n"
          ]
        }
      ],
      "source": [
        "%cd pix2pixHD/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9pGBD_A7jkh"
      },
      "source": [
        "##Unique model for different level of fog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBS7uIxAqn6W",
        "outputId": "98797bcc-129e-4794-b804-86e71a2df6eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------ Options -------------\n",
            "batchSize: 4\n",
            "beta1: 0.5\n",
            "checkpoints_dir: ./checkpoints\n",
            "continue_train: True\n",
            "data_type: 32\n",
            "dataroot: ./datasets/nebbia\n",
            "debug: False\n",
            "display_freq: 100\n",
            "display_winsize: 512\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: True\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "lambda_feat: 10.0\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "load_pretrain: \n",
            "local_rank: 0\n",
            "lr: 0.0002\n",
            "max_dataset_size: inf\n",
            "model: pix2pixHD\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_layers_D: 3\n",
            "n_local_enhancers: 1\n",
            "name: nebbia\n",
            "ndf: 64\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter: 100\n",
            "niter_decay: 100\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_ganFeat_loss: False\n",
            "no_html: False\n",
            "no_instance: True\n",
            "no_lsgan: False\n",
            "no_vgg_loss: False\n",
            "norm: instance\n",
            "num_D: 2\n",
            "output_nc: 3\n",
            "phase: train\n",
            "pool_size: 0\n",
            "print_freq: 100\n",
            "resize_or_crop: crop\n",
            "save_epoch_freq: 10\n",
            "save_latest_freq: 1000\n",
            "serial_batches: False\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "verbose: False\n",
            "which_epoch: latest\n",
            "-------------- End ----------------\n",
            "Resuming from epoch 97 at iteration 1800\n",
            "CustomDatasetDataLoader\n",
            "dataset [AlignedDataset] was created\n",
            "#training images = 4200\n",
            "GlobalGenerator(\n",
            "  (model): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (11): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (14): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (17): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (18): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (19): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (20): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (21): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (22): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (23): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (24): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (25): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (26): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (29): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (30): ReLU(inplace=True)\n",
            "    (31): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (32): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (33): ReLU(inplace=True)\n",
            "    (34): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (35): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (38): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (39): Tanh()\n",
            "  )\n",
            ")\n",
            "MultiscaleDiscriminator(\n",
            "  (scale0_layer0): Sequential(\n",
            "    (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale0_layer1): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale0_layer2): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale0_layer3): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale0_layer4): Sequential(\n",
            "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "  )\n",
            "  (scale1_layer0): Sequential(\n",
            "    (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale1_layer1): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale1_layer2): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale1_layer3): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale1_layer4): Sequential(\n",
            "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "  )\n",
            "  (downsample): AvgPool2d(kernel_size=3, stride=2, padding=[1, 1])\n",
            ")\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
            "100% 548M/548M [00:07<00:00, 81.8MB/s]\n",
            "create web directory ./checkpoints/nebbia/web...\n",
            "(epoch: 97, iters: 1900, time: 1.948) G_GAN: 2.089 G_GAN_Feat: 2.718 G_VGG: 1.824 D_real: 0.113 D_fake: 0.053 \n",
            "(epoch: 97, iters: 2000, time: 0.559) G_GAN: 1.776 G_GAN_Feat: 2.576 G_VGG: 1.368 D_real: 0.017 D_fake: 0.116 \n",
            "(epoch: 97, iters: 2100, time: 0.551) G_GAN: 1.953 G_GAN_Feat: 2.653 G_VGG: 1.674 D_real: 0.014 D_fake: 0.010 \n",
            "(epoch: 97, iters: 2200, time: 0.553) G_GAN: 1.932 G_GAN_Feat: 2.998 G_VGG: 2.237 D_real: 0.007 D_fake: 0.007 \n",
            "(epoch: 97, iters: 2300, time: 0.554) G_GAN: 1.616 G_GAN_Feat: 2.476 G_VGG: 1.229 D_real: 0.017 D_fake: 0.143 \n",
            "(epoch: 97, iters: 2400, time: 0.552) G_GAN: 1.637 G_GAN_Feat: 2.797 G_VGG: 1.949 D_real: 0.007 D_fake: 0.139 \n",
            "(epoch: 97, iters: 2500, time: 0.554) G_GAN: 1.909 G_GAN_Feat: 2.727 G_VGG: 1.499 D_real: 0.069 D_fake: 0.079 \n",
            "(epoch: 97, iters: 2600, time: 0.552) G_GAN: 2.069 G_GAN_Feat: 2.842 G_VGG: 1.586 D_real: 0.011 D_fake: 0.013 \n",
            "(epoch: 97, iters: 2700, time: 0.552) G_GAN: 1.790 G_GAN_Feat: 2.722 G_VGG: 1.862 D_real: 0.006 D_fake: 0.036 \n",
            "(epoch: 97, iters: 2800, time: 0.553) G_GAN: 1.904 G_GAN_Feat: 2.943 G_VGG: 1.584 D_real: 0.011 D_fake: 0.012 \n",
            "saving the latest model (epoch 97, total_steps 406000)\n",
            "(epoch: 97, iters: 2900, time: 0.556) G_GAN: 2.038 G_GAN_Feat: 2.717 G_VGG: 1.657 D_real: 0.266 D_fake: 0.025 \n",
            "(epoch: 97, iters: 3000, time: 0.553) G_GAN: 1.662 G_GAN_Feat: 2.671 G_VGG: 1.727 D_real: 0.015 D_fake: 0.081 \n",
            "(epoch: 97, iters: 3100, time: 0.553) G_GAN: 1.356 G_GAN_Feat: 2.756 G_VGG: 1.185 D_real: 0.059 D_fake: 0.270 \n",
            "(epoch: 97, iters: 3200, time: 0.553) G_GAN: 1.977 G_GAN_Feat: 3.140 G_VGG: 1.712 D_real: 0.016 D_fake: 0.009 \n",
            "(epoch: 97, iters: 3300, time: 0.554) G_GAN: 1.853 G_GAN_Feat: 2.989 G_VGG: 1.877 D_real: 0.029 D_fake: 0.078 \n",
            "(epoch: 97, iters: 3400, time: 0.554) G_GAN: 1.914 G_GAN_Feat: 2.883 G_VGG: 1.630 D_real: 0.063 D_fake: 0.017 \n",
            "(epoch: 97, iters: 3500, time: 0.554) G_GAN: 1.857 G_GAN_Feat: 2.601 G_VGG: 1.882 D_real: 0.016 D_fake: 0.048 \n",
            "(epoch: 97, iters: 3600, time: 0.553) G_GAN: 1.812 G_GAN_Feat: 2.531 G_VGG: 1.410 D_real: 0.020 D_fake: 0.026 \n",
            "(epoch: 97, iters: 3700, time: 0.553) G_GAN: 1.556 G_GAN_Feat: 2.395 G_VGG: 1.364 D_real: 0.058 D_fake: 0.119 \n",
            "(epoch: 97, iters: 3800, time: 0.554) G_GAN: 1.709 G_GAN_Feat: 2.822 G_VGG: 1.580 D_real: 0.009 D_fake: 0.081 \n",
            "saving the latest model (epoch 97, total_steps 407000)\n",
            "(epoch: 97, iters: 3900, time: 0.556) G_GAN: 1.977 G_GAN_Feat: 3.325 G_VGG: 2.262 D_real: 0.013 D_fake: 0.006 \n",
            "(epoch: 97, iters: 4000, time: 0.553) G_GAN: 2.256 G_GAN_Feat: 3.136 G_VGG: 1.894 D_real: 0.343 D_fake: 0.028 \n",
            "(epoch: 97, iters: 4100, time: 0.554) G_GAN: 1.617 G_GAN_Feat: 2.395 G_VGG: 1.395 D_real: 0.028 D_fake: 0.071 \n",
            "(epoch: 97, iters: 4200, time: 0.554) G_GAN: 1.833 G_GAN_Feat: 3.102 G_VGG: 1.853 D_real: 0.026 D_fake: 0.019 \n",
            "End of epoch 97 / 200 \t Time Taken: 1491 sec\n",
            "(epoch: 98, iters: 100, time: 0.554) G_GAN: 1.927 G_GAN_Feat: 2.838 G_VGG: 2.003 D_real: 0.012 D_fake: 0.011 \n",
            "(epoch: 98, iters: 200, time: 0.552) G_GAN: 1.688 G_GAN_Feat: 3.145 G_VGG: 2.240 D_real: 0.020 D_fake: 0.047 \n",
            "(epoch: 98, iters: 300, time: 0.552) G_GAN: 2.031 G_GAN_Feat: 3.002 G_VGG: 1.869 D_real: 0.027 D_fake: 0.008 \n",
            "(epoch: 98, iters: 400, time: 0.551) G_GAN: 2.198 G_GAN_Feat: 2.770 G_VGG: 1.639 D_real: 0.063 D_fake: 0.022 \n",
            "(epoch: 98, iters: 500, time: 0.550) G_GAN: 2.254 G_GAN_Feat: 2.304 G_VGG: 1.164 D_real: 0.129 D_fake: 0.049 \n",
            "(epoch: 98, iters: 600, time: 0.549) G_GAN: 2.200 G_GAN_Feat: 3.070 G_VGG: 1.983 D_real: 0.030 D_fake: 0.019 \n",
            "saving the latest model (epoch 98, total_steps 408000)\n",
            "(epoch: 98, iters: 700, time: 0.546) G_GAN: 1.991 G_GAN_Feat: 2.614 G_VGG: 1.670 D_real: 0.149 D_fake: 0.010 \n",
            "(epoch: 98, iters: 800, time: 0.547) G_GAN: 1.613 G_GAN_Feat: 2.951 G_VGG: 1.669 D_real: 0.044 D_fake: 0.132 \n",
            "(epoch: 98, iters: 900, time: 0.549) G_GAN: 1.858 G_GAN_Feat: 2.699 G_VGG: 1.811 D_real: 0.011 D_fake: 0.028 \n",
            "(epoch: 98, iters: 1000, time: 0.549) G_GAN: 1.930 G_GAN_Feat: 2.959 G_VGG: 1.917 D_real: 0.062 D_fake: 0.012 \n",
            "(epoch: 98, iters: 1100, time: 0.551) G_GAN: 2.304 G_GAN_Feat: 2.793 G_VGG: 1.849 D_real: 0.288 D_fake: 0.037 \n",
            "(epoch: 98, iters: 1200, time: 0.550) G_GAN: 1.669 G_GAN_Feat: 2.524 G_VGG: 1.611 D_real: 0.012 D_fake: 0.072 \n",
            "(epoch: 98, iters: 1300, time: 0.549) G_GAN: 1.636 G_GAN_Feat: 3.138 G_VGG: 2.353 D_real: 0.021 D_fake: 0.043 \n",
            "(epoch: 98, iters: 1400, time: 0.549) G_GAN: 1.778 G_GAN_Feat: 3.325 G_VGG: 1.740 D_real: 0.015 D_fake: 0.108 \n",
            "(epoch: 98, iters: 1500, time: 0.549) G_GAN: 1.687 G_GAN_Feat: 2.926 G_VGG: 1.550 D_real: 0.091 D_fake: 0.056 \n",
            "(epoch: 98, iters: 1600, time: 0.549) G_GAN: 2.187 G_GAN_Feat: 3.097 G_VGG: 1.893 D_real: 0.008 D_fake: 0.011 \n",
            "saving the latest model (epoch 98, total_steps 409000)\n",
            "(epoch: 98, iters: 1700, time: 0.547) G_GAN: 1.690 G_GAN_Feat: 2.706 G_VGG: 1.697 D_real: 0.030 D_fake: 0.085 \n",
            "(epoch: 98, iters: 1800, time: 0.547) G_GAN: 1.616 G_GAN_Feat: 2.825 G_VGG: 1.713 D_real: 0.013 D_fake: 0.079 \n",
            "(epoch: 98, iters: 1900, time: 0.548) G_GAN: 1.762 G_GAN_Feat: 2.624 G_VGG: 1.745 D_real: 0.164 D_fake: 0.056 \n",
            "(epoch: 98, iters: 2000, time: 0.548) G_GAN: 1.504 G_GAN_Feat: 2.842 G_VGG: 1.521 D_real: 0.449 D_fake: 0.101 \n",
            "(epoch: 98, iters: 2100, time: 0.549) G_GAN: 1.847 G_GAN_Feat: 2.831 G_VGG: 1.847 D_real: 0.032 D_fake: 0.034 \n",
            "(epoch: 98, iters: 2200, time: 0.549) G_GAN: 1.800 G_GAN_Feat: 2.856 G_VGG: 1.645 D_real: 0.042 D_fake: 0.061 \n",
            "(epoch: 98, iters: 2300, time: 0.549) G_GAN: 1.746 G_GAN_Feat: 2.572 G_VGG: 1.538 D_real: 0.010 D_fake: 0.088 \n",
            "(epoch: 98, iters: 2400, time: 0.549) G_GAN: 1.868 G_GAN_Feat: 2.759 G_VGG: 1.814 D_real: 0.365 D_fake: 0.023 \n",
            "(epoch: 98, iters: 2500, time: 0.549) G_GAN: 1.944 G_GAN_Feat: 2.746 G_VGG: 1.666 D_real: 0.019 D_fake: 0.015 \n",
            "(epoch: 98, iters: 2600, time: 0.549) G_GAN: 1.981 G_GAN_Feat: 2.628 G_VGG: 1.677 D_real: 0.016 D_fake: 0.013 \n",
            "saving the latest model (epoch 98, total_steps 410000)\n",
            "(epoch: 98, iters: 2700, time: 0.547) G_GAN: 1.858 G_GAN_Feat: 2.768 G_VGG: 1.671 D_real: 0.039 D_fake: 0.054 \n",
            "(epoch: 98, iters: 2800, time: 0.547) G_GAN: 2.111 G_GAN_Feat: 3.190 G_VGG: 2.182 D_real: 0.059 D_fake: 0.012 \n",
            "(epoch: 98, iters: 2900, time: 0.548) G_GAN: 2.024 G_GAN_Feat: 3.254 G_VGG: 1.935 D_real: 0.094 D_fake: 0.010 \n",
            "(epoch: 98, iters: 3000, time: 0.549) G_GAN: 1.113 G_GAN_Feat: 2.415 G_VGG: 1.216 D_real: 0.052 D_fake: 0.547 \n",
            "(epoch: 98, iters: 3100, time: 0.549) G_GAN: 1.857 G_GAN_Feat: 2.785 G_VGG: 1.481 D_real: 0.018 D_fake: 0.016 \n",
            "(epoch: 98, iters: 3200, time: 0.549) G_GAN: 1.943 G_GAN_Feat: 2.736 G_VGG: 1.410 D_real: 0.011 D_fake: 0.009 \n",
            "(epoch: 98, iters: 3300, time: 0.549) G_GAN: 2.116 G_GAN_Feat: 2.958 G_VGG: 2.145 D_real: 0.016 D_fake: 0.016 \n",
            "(epoch: 98, iters: 3400, time: 0.549) G_GAN: 1.920 G_GAN_Feat: 3.165 G_VGG: 1.807 D_real: 0.021 D_fake: 0.017 \n",
            "(epoch: 98, iters: 3500, time: 0.549) G_GAN: 1.977 G_GAN_Feat: 2.793 G_VGG: 1.292 D_real: 0.022 D_fake: 0.007 \n",
            "(epoch: 98, iters: 3600, time: 0.549) G_GAN: 1.816 G_GAN_Feat: 2.809 G_VGG: 2.106 D_real: 0.023 D_fake: 0.041 \n",
            "saving the latest model (epoch 98, total_steps 411000)\n",
            "(epoch: 98, iters: 3700, time: 0.547) G_GAN: 1.512 G_GAN_Feat: 2.545 G_VGG: 1.556 D_real: 0.010 D_fake: 0.156 \n",
            "(epoch: 98, iters: 3800, time: 0.548) G_GAN: 1.895 G_GAN_Feat: 2.567 G_VGG: 1.677 D_real: 0.060 D_fake: 0.038 \n",
            "(epoch: 98, iters: 3900, time: 0.548) G_GAN: 2.115 G_GAN_Feat: 2.609 G_VGG: 1.530 D_real: 0.025 D_fake: 0.008 \n",
            "(epoch: 98, iters: 4000, time: 0.549) G_GAN: 1.682 G_GAN_Feat: 2.741 G_VGG: 2.013 D_real: 0.055 D_fake: 0.047 \n",
            "(epoch: 98, iters: 4100, time: 0.549) G_GAN: 1.692 G_GAN_Feat: 2.344 G_VGG: 1.172 D_real: 0.050 D_fake: 0.110 \n",
            "(epoch: 98, iters: 4200, time: 0.549) G_GAN: 1.891 G_GAN_Feat: 2.831 G_VGG: 1.953 D_real: 0.011 D_fake: 0.016 \n",
            "End of epoch 98 / 200 \t Time Taken: 2329 sec\n",
            "(epoch: 99, iters: 100, time: 0.549) G_GAN: 2.074 G_GAN_Feat: 2.720 G_VGG: 1.932 D_real: 0.035 D_fake: 0.016 \n",
            "(epoch: 99, iters: 200, time: 0.549) G_GAN: 1.184 G_GAN_Feat: 2.494 G_VGG: 1.661 D_real: 0.026 D_fake: 0.541 \n",
            "(epoch: 99, iters: 300, time: 0.549) G_GAN: 1.913 G_GAN_Feat: 2.700 G_VGG: 1.563 D_real: 0.031 D_fake: 0.025 \n",
            "(epoch: 99, iters: 400, time: 0.549) G_GAN: 1.729 G_GAN_Feat: 2.747 G_VGG: 1.441 D_real: 0.019 D_fake: 0.073 \n",
            "saving the latest model (epoch 99, total_steps 412000)\n",
            "(epoch: 99, iters: 500, time: 0.547) G_GAN: 1.938 G_GAN_Feat: 3.020 G_VGG: 2.087 D_real: 0.010 D_fake: 0.009 \n",
            "(epoch: 99, iters: 600, time: 0.548) G_GAN: 1.817 G_GAN_Feat: 2.844 G_VGG: 2.002 D_real: 0.083 D_fake: 0.053 \n",
            "(epoch: 99, iters: 700, time: 0.549) G_GAN: 1.826 G_GAN_Feat: 2.927 G_VGG: 1.803 D_real: 0.014 D_fake: 0.155 \n",
            "(epoch: 99, iters: 800, time: 0.549) G_GAN: 2.048 G_GAN_Feat: 2.719 G_VGG: 1.958 D_real: 0.018 D_fake: 0.010 \n",
            "(epoch: 99, iters: 900, time: 0.549) G_GAN: 1.648 G_GAN_Feat: 2.854 G_VGG: 2.243 D_real: 0.019 D_fake: 0.070 \n",
            "(epoch: 99, iters: 1000, time: 0.549) G_GAN: 1.992 G_GAN_Feat: 2.778 G_VGG: 1.683 D_real: 0.021 D_fake: 0.005 \n",
            "(epoch: 99, iters: 1100, time: 0.549) G_GAN: 2.081 G_GAN_Feat: 2.619 G_VGG: 1.748 D_real: 0.025 D_fake: 0.008 \n",
            "(epoch: 99, iters: 1200, time: 0.549) G_GAN: 1.109 G_GAN_Feat: 2.362 G_VGG: 1.549 D_real: 0.114 D_fake: 0.336 \n",
            "(epoch: 99, iters: 1300, time: 0.549) G_GAN: 2.043 G_GAN_Feat: 3.186 G_VGG: 1.761 D_real: 0.006 D_fake: 0.003 \n",
            "(epoch: 99, iters: 1400, time: 0.549) G_GAN: 2.011 G_GAN_Feat: 2.506 G_VGG: 1.637 D_real: 0.012 D_fake: 0.007 \n",
            "saving the latest model (epoch 99, total_steps 413000)\n",
            "(epoch: 99, iters: 1500, time: 0.547) G_GAN: 1.754 G_GAN_Feat: 2.620 G_VGG: 1.468 D_real: 0.124 D_fake: 0.153 \n",
            "(epoch: 99, iters: 1600, time: 0.550) G_GAN: 2.073 G_GAN_Feat: 2.351 G_VGG: 1.345 D_real: 0.078 D_fake: 0.022 \n",
            "(epoch: 99, iters: 1700, time: 0.554) G_GAN: 1.755 G_GAN_Feat: 2.612 G_VGG: 1.582 D_real: 0.100 D_fake: 0.046 \n",
            "(epoch: 99, iters: 1800, time: 0.554) G_GAN: 1.714 G_GAN_Feat: 2.459 G_VGG: 1.403 D_real: 0.014 D_fake: 0.062 \n",
            "(epoch: 99, iters: 1900, time: 0.553) G_GAN: 1.947 G_GAN_Feat: 3.306 G_VGG: 1.894 D_real: 0.007 D_fake: 0.006 \n",
            "(epoch: 99, iters: 2000, time: 0.554) G_GAN: 1.665 G_GAN_Feat: 2.794 G_VGG: 1.520 D_real: 0.069 D_fake: 0.048 \n",
            "(epoch: 99, iters: 2100, time: 0.554) G_GAN: 1.914 G_GAN_Feat: 3.322 G_VGG: 1.894 D_real: 0.013 D_fake: 0.019 \n",
            "(epoch: 99, iters: 2200, time: 0.554) G_GAN: 1.889 G_GAN_Feat: 2.654 G_VGG: 1.821 D_real: 0.008 D_fake: 0.018 \n",
            "(epoch: 99, iters: 2300, time: 0.553) G_GAN: 1.745 G_GAN_Feat: 2.808 G_VGG: 2.120 D_real: 0.024 D_fake: 0.043 \n",
            "(epoch: 99, iters: 2400, time: 0.553) G_GAN: 1.740 G_GAN_Feat: 3.011 G_VGG: 2.121 D_real: 0.011 D_fake: 0.025 \n",
            "saving the latest model (epoch 99, total_steps 414000)\n",
            "(epoch: 99, iters: 2500, time: 0.552) G_GAN: 1.617 G_GAN_Feat: 2.687 G_VGG: 1.218 D_real: 0.008 D_fake: 0.114 \n",
            "(epoch: 99, iters: 2600, time: 0.551) G_GAN: 1.897 G_GAN_Feat: 2.901 G_VGG: 1.661 D_real: 0.010 D_fake: 0.013 \n",
            "(epoch: 99, iters: 2700, time: 0.550) G_GAN: 2.195 G_GAN_Feat: 2.783 G_VGG: 2.024 D_real: 0.052 D_fake: 0.023 \n",
            "(epoch: 99, iters: 2800, time: 0.550) G_GAN: 1.758 G_GAN_Feat: 2.996 G_VGG: 2.116 D_real: 0.019 D_fake: 0.025 \n",
            "(epoch: 99, iters: 2900, time: 0.549) G_GAN: 1.612 G_GAN_Feat: 2.586 G_VGG: 1.547 D_real: 0.058 D_fake: 0.109 \n",
            "(epoch: 99, iters: 3000, time: 0.549) G_GAN: 2.024 G_GAN_Feat: 2.702 G_VGG: 1.456 D_real: 0.010 D_fake: 0.009 \n",
            "(epoch: 99, iters: 3100, time: 0.548) G_GAN: 1.887 G_GAN_Feat: 2.752 G_VGG: 1.515 D_real: 0.012 D_fake: 0.017 \n",
            "(epoch: 99, iters: 3200, time: 0.549) G_GAN: 1.722 G_GAN_Feat: 2.869 G_VGG: 1.913 D_real: 0.022 D_fake: 0.096 \n",
            "(epoch: 99, iters: 3300, time: 0.549) G_GAN: 1.989 G_GAN_Feat: 2.893 G_VGG: 1.723 D_real: 0.085 D_fake: 0.007 \n",
            "(epoch: 99, iters: 3400, time: 0.549) G_GAN: 2.044 G_GAN_Feat: 2.686 G_VGG: 1.735 D_real: 0.004 D_fake: 0.008 \n",
            "saving the latest model (epoch 99, total_steps 415000)\n",
            "(epoch: 99, iters: 3500, time: 0.547) G_GAN: 1.912 G_GAN_Feat: 2.797 G_VGG: 1.559 D_real: 0.009 D_fake: 0.025 \n",
            "(epoch: 99, iters: 3600, time: 0.548) G_GAN: 2.063 G_GAN_Feat: 2.656 G_VGG: 1.708 D_real: 0.147 D_fake: 0.012 \n",
            "(epoch: 99, iters: 3700, time: 0.548) G_GAN: 1.399 G_GAN_Feat: 2.756 G_VGG: 1.594 D_real: 0.140 D_fake: 0.114 \n",
            "(epoch: 99, iters: 3800, time: 0.548) G_GAN: 2.039 G_GAN_Feat: 2.849 G_VGG: 1.777 D_real: 0.036 D_fake: 0.007 \n",
            "(epoch: 99, iters: 3900, time: 0.549) G_GAN: 1.833 G_GAN_Feat: 2.657 G_VGG: 1.735 D_real: 0.085 D_fake: 0.053 \n",
            "(epoch: 99, iters: 4000, time: 0.549) G_GAN: 2.017 G_GAN_Feat: 2.816 G_VGG: 2.053 D_real: 0.243 D_fake: 0.014 \n",
            "(epoch: 99, iters: 4100, time: 0.549) G_GAN: 1.900 G_GAN_Feat: 2.901 G_VGG: 1.966 D_real: 0.016 D_fake: 0.009 \n",
            "(epoch: 99, iters: 4200, time: 0.549) G_GAN: 2.084 G_GAN_Feat: 2.667 G_VGG: 1.881 D_real: 0.021 D_fake: 0.015 \n",
            "End of epoch 99 / 200 \t Time Taken: 2332 sec\n",
            "(epoch: 100, iters: 100, time: 0.549) G_GAN: 1.942 G_GAN_Feat: 2.866 G_VGG: 1.855 D_real: 0.046 D_fake: 0.017 \n",
            "(epoch: 100, iters: 200, time: 0.549) G_GAN: 1.877 G_GAN_Feat: 2.907 G_VGG: 2.342 D_real: 0.014 D_fake: 0.023 \n",
            "saving the latest model (epoch 100, total_steps 416000)\n",
            "(epoch: 100, iters: 300, time: 0.547) G_GAN: 1.781 G_GAN_Feat: 2.847 G_VGG: 1.744 D_real: 0.031 D_fake: 0.035 \n",
            "(epoch: 100, iters: 400, time: 0.548) G_GAN: 1.777 G_GAN_Feat: 2.565 G_VGG: 1.514 D_real: 0.040 D_fake: 0.138 \n",
            "(epoch: 100, iters: 500, time: 0.548) G_GAN: 2.203 G_GAN_Feat: 2.456 G_VGG: 1.511 D_real: 0.100 D_fake: 0.090 \n",
            "(epoch: 100, iters: 600, time: 0.549) G_GAN: 1.670 G_GAN_Feat: 3.231 G_VGG: 2.109 D_real: 0.029 D_fake: 0.144 \n",
            "(epoch: 100, iters: 700, time: 0.549) G_GAN: 1.765 G_GAN_Feat: 2.679 G_VGG: 1.638 D_real: 0.032 D_fake: 0.053 \n",
            "(epoch: 100, iters: 800, time: 0.549) G_GAN: 2.044 G_GAN_Feat: 2.652 G_VGG: 1.256 D_real: 0.076 D_fake: 0.015 \n",
            "(epoch: 100, iters: 900, time: 0.549) G_GAN: 1.687 G_GAN_Feat: 2.701 G_VGG: 1.847 D_real: 0.343 D_fake: 0.050 \n",
            "(epoch: 100, iters: 1000, time: 0.549) G_GAN: 1.852 G_GAN_Feat: 2.450 G_VGG: 1.163 D_real: 0.043 D_fake: 0.068 \n",
            "(epoch: 100, iters: 1100, time: 0.550) G_GAN: 1.707 G_GAN_Feat: 2.770 G_VGG: 1.736 D_real: 0.026 D_fake: 0.021 \n",
            "(epoch: 100, iters: 1200, time: 0.549) G_GAN: 1.617 G_GAN_Feat: 2.579 G_VGG: 1.579 D_real: 0.147 D_fake: 0.056 \n",
            "saving the latest model (epoch 100, total_steps 417000)\n",
            "(epoch: 100, iters: 1300, time: 0.547) G_GAN: 2.101 G_GAN_Feat: 3.213 G_VGG: 1.824 D_real: 0.013 D_fake: 0.009 \n",
            "(epoch: 100, iters: 1400, time: 0.548) G_GAN: 2.122 G_GAN_Feat: 2.775 G_VGG: 2.171 D_real: 0.007 D_fake: 0.009 \n",
            "(epoch: 100, iters: 1500, time: 0.548) G_GAN: 1.092 G_GAN_Feat: 2.871 G_VGG: 1.996 D_real: 0.140 D_fake: 0.316 \n",
            "(epoch: 100, iters: 1600, time: 0.549) G_GAN: 1.635 G_GAN_Feat: 2.556 G_VGG: 1.899 D_real: 0.021 D_fake: 0.060 \n",
            "(epoch: 100, iters: 1700, time: 0.548) G_GAN: 1.618 G_GAN_Feat: 3.139 G_VGG: 2.025 D_real: 0.028 D_fake: 0.122 \n",
            "(epoch: 100, iters: 1800, time: 0.550) G_GAN: 2.097 G_GAN_Feat: 2.481 G_VGG: 1.524 D_real: 0.019 D_fake: 0.015 \n",
            "(epoch: 100, iters: 1900, time: 0.549) G_GAN: 1.889 G_GAN_Feat: 2.602 G_VGG: 1.597 D_real: 0.018 D_fake: 0.046 \n",
            "(epoch: 100, iters: 2000, time: 0.549) G_GAN: 1.420 G_GAN_Feat: 2.255 G_VGG: 1.411 D_real: 0.032 D_fake: 0.137 \n",
            "(epoch: 100, iters: 2100, time: 0.549) G_GAN: 1.851 G_GAN_Feat: 3.077 G_VGG: 1.699 D_real: 0.015 D_fake: 0.017 \n",
            "(epoch: 100, iters: 2200, time: 0.549) G_GAN: 2.041 G_GAN_Feat: 2.649 G_VGG: 1.825 D_real: 0.015 D_fake: 0.015 \n",
            "saving the latest model (epoch 100, total_steps 418000)\n",
            "(epoch: 100, iters: 2300, time: 0.548) G_GAN: 2.057 G_GAN_Feat: 2.966 G_VGG: 1.944 D_real: 0.010 D_fake: 0.009 \n",
            "(epoch: 100, iters: 2400, time: 0.549) G_GAN: 1.629 G_GAN_Feat: 3.283 G_VGG: 2.600 D_real: 0.044 D_fake: 0.081 \n",
            "(epoch: 100, iters: 2500, time: 0.549) G_GAN: 1.462 G_GAN_Feat: 2.737 G_VGG: 1.641 D_real: 0.038 D_fake: 0.109 \n",
            "(epoch: 100, iters: 2600, time: 0.549) G_GAN: 1.799 G_GAN_Feat: 2.397 G_VGG: 1.305 D_real: 0.027 D_fake: 0.025 \n",
            "(epoch: 100, iters: 2700, time: 0.550) G_GAN: 2.069 G_GAN_Feat: 2.537 G_VGG: 1.461 D_real: 0.110 D_fake: 0.008 \n",
            "(epoch: 100, iters: 2800, time: 0.550) G_GAN: 2.045 G_GAN_Feat: 2.336 G_VGG: 1.625 D_real: 0.268 D_fake: 0.013 \n",
            "(epoch: 100, iters: 2900, time: 0.550) G_GAN: 1.720 G_GAN_Feat: 2.933 G_VGG: 2.184 D_real: 0.020 D_fake: 0.051 \n",
            "(epoch: 100, iters: 3000, time: 0.550) G_GAN: 1.845 G_GAN_Feat: 2.979 G_VGG: 2.273 D_real: 0.012 D_fake: 0.017 \n",
            "(epoch: 100, iters: 3100, time: 0.550) G_GAN: 1.864 G_GAN_Feat: 2.574 G_VGG: 1.765 D_real: 0.009 D_fake: 0.012 \n",
            "(epoch: 100, iters: 3200, time: 0.550) G_GAN: 1.623 G_GAN_Feat: 3.072 G_VGG: 1.968 D_real: 0.074 D_fake: 0.080 \n",
            "saving the latest model (epoch 100, total_steps 419000)\n",
            "(epoch: 100, iters: 3300, time: 0.548) G_GAN: 1.736 G_GAN_Feat: 2.945 G_VGG: 1.864 D_real: 0.027 D_fake: 0.023 \n",
            "(epoch: 100, iters: 3400, time: 0.549) G_GAN: 1.836 G_GAN_Feat: 2.391 G_VGG: 1.475 D_real: 0.039 D_fake: 0.033 \n",
            "(epoch: 100, iters: 3500, time: 0.549) G_GAN: 1.739 G_GAN_Feat: 2.657 G_VGG: 1.495 D_real: 0.197 D_fake: 0.041 \n",
            "(epoch: 100, iters: 3600, time: 0.549) G_GAN: 1.593 G_GAN_Feat: 2.596 G_VGG: 1.564 D_real: 0.039 D_fake: 0.154 \n",
            "(epoch: 100, iters: 3700, time: 0.550) G_GAN: 2.056 G_GAN_Feat: 2.805 G_VGG: 1.510 D_real: 0.038 D_fake: 0.006 \n",
            "(epoch: 100, iters: 3800, time: 0.550) G_GAN: 1.737 G_GAN_Feat: 2.571 G_VGG: 1.838 D_real: 0.223 D_fake: 0.068 \n",
            "(epoch: 100, iters: 3900, time: 0.550) G_GAN: 1.847 G_GAN_Feat: 2.914 G_VGG: 2.210 D_real: 0.010 D_fake: 0.013 \n",
            "(epoch: 100, iters: 4000, time: 0.550) G_GAN: 1.812 G_GAN_Feat: 3.255 G_VGG: 1.485 D_real: 0.011 D_fake: 0.012 \n",
            "(epoch: 100, iters: 4100, time: 0.550) G_GAN: 2.081 G_GAN_Feat: 2.711 G_VGG: 1.778 D_real: 0.254 D_fake: 0.027 \n",
            "(epoch: 100, iters: 4200, time: 0.550) G_GAN: 1.938 G_GAN_Feat: 2.901 G_VGG: 1.430 D_real: 0.065 D_fake: 0.006 \n",
            "saving the latest model (epoch 100, total_steps 420000)\n",
            "End of epoch 100 / 200 \t Time Taken: 2333 sec\n",
            "saving the model at the end of epoch 100, iters 420000\n",
            "(epoch: 101, iters: 100, time: 0.541) G_GAN: 1.836 G_GAN_Feat: 2.893 G_VGG: 2.319 D_real: 0.153 D_fake: 0.013 \n",
            "(epoch: 101, iters: 200, time: 0.545) G_GAN: 1.966 G_GAN_Feat: 2.941 G_VGG: 1.396 D_real: 0.284 D_fake: 0.012 \n",
            "(epoch: 101, iters: 300, time: 0.547) G_GAN: 1.727 G_GAN_Feat: 2.774 G_VGG: 1.855 D_real: 0.031 D_fake: 0.081 \n",
            "(epoch: 101, iters: 400, time: 0.548) G_GAN: 1.618 G_GAN_Feat: 2.941 G_VGG: 1.917 D_real: 0.013 D_fake: 0.137 \n",
            "(epoch: 101, iters: 500, time: 0.550) G_GAN: 1.926 G_GAN_Feat: 2.785 G_VGG: 1.905 D_real: 0.230 D_fake: 0.027 \n",
            "(epoch: 101, iters: 600, time: 0.550) G_GAN: 1.983 G_GAN_Feat: 2.726 G_VGG: 1.910 D_real: 0.042 D_fake: 0.007 \n",
            "(epoch: 101, iters: 700, time: 0.550) G_GAN: 1.453 G_GAN_Feat: 2.512 G_VGG: 1.446 D_real: 0.235 D_fake: 0.169 \n",
            "(epoch: 101, iters: 800, time: 0.550) G_GAN: 1.771 G_GAN_Feat: 2.562 G_VGG: 1.153 D_real: 0.009 D_fake: 0.024 \n",
            "(epoch: 101, iters: 900, time: 0.550) G_GAN: 2.028 G_GAN_Feat: 2.823 G_VGG: 1.667 D_real: 0.043 D_fake: 0.031 \n",
            "(epoch: 101, iters: 1000, time: 0.550) G_GAN: 2.037 G_GAN_Feat: 2.565 G_VGG: 1.734 D_real: 0.036 D_fake: 0.004 \n",
            "saving the latest model (epoch 101, total_steps 421000)\n",
            "(epoch: 101, iters: 1100, time: 0.548) G_GAN: 1.987 G_GAN_Feat: 2.842 G_VGG: 1.824 D_real: 0.009 D_fake: 0.013 \n",
            "(epoch: 101, iters: 1200, time: 0.549) G_GAN: 1.533 G_GAN_Feat: 2.895 G_VGG: 2.024 D_real: 0.055 D_fake: 0.060 \n",
            "(epoch: 101, iters: 1300, time: 0.550) G_GAN: 1.947 G_GAN_Feat: 2.882 G_VGG: 1.722 D_real: 0.071 D_fake: 0.055 \n",
            "(epoch: 101, iters: 1400, time: 0.550) G_GAN: 1.957 G_GAN_Feat: 2.480 G_VGG: 1.662 D_real: 0.014 D_fake: 0.009 \n",
            "(epoch: 101, iters: 1500, time: 0.550) G_GAN: 2.067 G_GAN_Feat: 2.951 G_VGG: 1.828 D_real: 0.012 D_fake: 0.005 \n",
            "(epoch: 101, iters: 1600, time: 0.550) G_GAN: 1.997 G_GAN_Feat: 2.685 G_VGG: 1.591 D_real: 0.038 D_fake: 0.028 \n",
            "(epoch: 101, iters: 1700, time: 0.550) G_GAN: 1.881 G_GAN_Feat: 2.525 G_VGG: 1.584 D_real: 0.075 D_fake: 0.051 \n",
            "(epoch: 101, iters: 1800, time: 0.550) G_GAN: 1.963 G_GAN_Feat: 2.731 G_VGG: 1.428 D_real: 0.067 D_fake: 0.023 \n",
            "(epoch: 101, iters: 1900, time: 0.550) G_GAN: 1.634 G_GAN_Feat: 2.614 G_VGG: 1.824 D_real: 0.006 D_fake: 0.078 \n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1MeMU7hWD5WVMk25vU3ch5Ii3csnSydwf/Haze-Fog-suppression/pix2pixHD/train.py\", line 95, in <module>\n",
            "    loss_D.backward()        \n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 487, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\", line 200, in backward\n",
            "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "#training on low resolution(512) only G1 (global net)\n",
        "!python train.py --continue_train --label_nc 0 --no_instance --name nebbia --dataroot ./datasets/nebbia --resize_or_crop crop --fineSize 512 --batchSize 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XhQJ5s95ZUj",
        "outputId": "0af758e4-b91d-4f05-9e94-cc43ba4a6f47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------ Options -------------\n",
            "batchSize: 2\n",
            "beta1: 0.5\n",
            "checkpoints_dir: ./checkpoints\n",
            "continue_train: True\n",
            "data_type: 32\n",
            "dataroot: ./datasets/nebbia\n",
            "debug: False\n",
            "display_freq: 100\n",
            "display_winsize: 512\n",
            "feat_num: 3\n",
            "fineSize: 1024\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: True\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "lambda_feat: 10.0\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "load_pretrain: checkpoints/nebbia/\n",
            "local_rank: 0\n",
            "lr: 0.0002\n",
            "max_dataset_size: inf\n",
            "model: pix2pixHD\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_layers_D: 3\n",
            "n_local_enhancers: 1\n",
            "name: nebbia\n",
            "ndf: 64\n",
            "nef: 16\n",
            "netG: local\n",
            "ngf: 64\n",
            "niter: 100\n",
            "niter_decay: 100\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_ganFeat_loss: False\n",
            "no_html: False\n",
            "no_instance: True\n",
            "no_lsgan: False\n",
            "no_vgg_loss: False\n",
            "norm: instance\n",
            "num_D: 2\n",
            "output_nc: 3\n",
            "phase: train\n",
            "pool_size: 0\n",
            "print_freq: 100\n",
            "resize_or_crop: crop\n",
            "save_epoch_freq: 10\n",
            "save_latest_freq: 1000\n",
            "serial_batches: False\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "verbose: False\n",
            "which_epoch: latest\n",
            "-------------- End ----------------\n",
            "Resuming from epoch 110 at iteration 3200\n",
            "CustomDatasetDataLoader\n",
            "dataset [AlignedDataset] was created\n",
            "#training images = 4200\n",
            "LocalEnhancer(\n",
            "  (model): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(3, 128, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (8): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (11): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (14): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (17): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (18): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (19): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (20): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (21): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (22): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (23): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (24): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (25): ConvTranspose2d(2048, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (26): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (29): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (30): ReLU(inplace=True)\n",
            "    (31): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (32): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (33): ReLU(inplace=True)\n",
            "    (34): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (35): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (36): ReLU(inplace=True)\n",
            "  )\n",
            "  (model1_1): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace=True)\n",
            "  )\n",
            "  (model1_2): Sequential(\n",
            "    (0): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (1): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (2): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (3): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (4): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (7): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (8): Tanh()\n",
            "  )\n",
            "  (downsample): AvgPool2d(kernel_size=3, stride=2, padding=[1, 1])\n",
            ")\n",
            "MultiscaleDiscriminator(\n",
            "  (scale0_layer0): Sequential(\n",
            "    (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale0_layer1): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale0_layer2): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale0_layer3): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale0_layer4): Sequential(\n",
            "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "  )\n",
            "  (scale1_layer0): Sequential(\n",
            "    (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale1_layer1): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale1_layer2): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale1_layer3): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale1_layer4): Sequential(\n",
            "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "  )\n",
            "  (downsample): AvgPool2d(kernel_size=3, stride=2, padding=[1, 1])\n",
            ")\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/models/base_model.py\", line 62, in load_network\n",
            "    network.load_state_dict(torch.load(save_path))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 797, in load\n",
            "    with _open_zipfile_reader(opened_file) as opened_zipfile:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 283, in __init__\n",
            "    super().__init__(torch._C.PyTorchFileReader(name_or_buffer))\n",
            "RuntimeError: PytorchStreamReader failed reading zip archive: failed finding central directory\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/train.py\", line 41, in <module>\n",
            "    model = create_model(opt)\n",
            "  File \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/models/models.py\", line 13, in create_model\n",
            "    model.initialize(opt)\n",
            "  File \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/models/pix2pixHD_model.py\", line 58, in initialize\n",
            "    self.load_network(self.netG, 'G', opt.which_epoch, pretrained_path)            \n",
            "  File \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/models/base_model.py\", line 64, in load_network\n",
            "    pretrained_dict = torch.load(save_path)                \n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 797, in load\n",
            "    with _open_zipfile_reader(opened_file) as opened_zipfile:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 283, in __init__\n",
            "    super().__init__(torch._C.PyTorchFileReader(name_or_buffer))\n",
            "RuntimeError: PytorchStreamReader failed reading zip archive: failed finding central directory\n"
          ]
        }
      ],
      "source": [
        "#training on high resolution (1024) G1 and G2 (local+global) starting from epoch 100 of G1\n",
        "\n",
        "#import torch\n",
        "#os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'\n",
        "#torch.cuda.empty_cache()\n",
        "\n",
        "!python train.py --netG local --continue_train --load_pretrain checkpoints/nebbia/ --label_nc 0 --no_instance --name nebbia --dataroot ./datasets/nebbia --resize_or_crop crop --fineSize 1024 --batchSize 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlZUpp-N9Yni"
      },
      "source": [
        "## 3 GANS for each fog level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhRBwxm3Cxxr",
        "outputId": "0b1ba6eb-6eb5-4f18-f47b-649f05450d9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------ Options -------------\n",
            "batchSize: 4\n",
            "beta1: 0.5\n",
            "checkpoints_dir: ./checkpoints\n",
            "continue_train: True\n",
            "data_type: 32\n",
            "dataroot: ./datasets/nebbia_low\n",
            "debug: False\n",
            "display_freq: 100\n",
            "display_winsize: 512\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: True\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "lambda_feat: 10.0\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "load_pretrain: \n",
            "local_rank: 0\n",
            "lr: 0.0002\n",
            "max_dataset_size: inf\n",
            "model: pix2pixHD\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_layers_D: 3\n",
            "n_local_enhancers: 1\n",
            "name: nebbia_low\n",
            "ndf: 64\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter: 100\n",
            "niter_decay: 100\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_ganFeat_loss: False\n",
            "no_html: False\n",
            "no_instance: True\n",
            "no_lsgan: False\n",
            "no_vgg_loss: False\n",
            "norm: instance\n",
            "num_D: 2\n",
            "output_nc: 3\n",
            "phase: train\n",
            "pool_size: 0\n",
            "print_freq: 100\n",
            "resize_or_crop: crop\n",
            "save_epoch_freq: 10\n",
            "save_latest_freq: 1000\n",
            "serial_batches: False\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "verbose: False\n",
            "which_epoch: latest\n",
            "-------------- End ----------------\n",
            "Resuming from epoch 46 at iteration 2000\n",
            "CustomDatasetDataLoader\n",
            "dataset [AlignedDataset] was created\n",
            "#training images = 4200\n",
            "GlobalGenerator(\n",
            "  (model): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (11): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (14): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (17): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (18): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (19): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (20): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (21): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (22): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (23): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (24): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (25): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (26): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (29): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (30): ReLU(inplace=True)\n",
            "    (31): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (32): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (33): ReLU(inplace=True)\n",
            "    (34): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (35): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (38): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (39): Tanh()\n",
            "  )\n",
            ")\n",
            "MultiscaleDiscriminator(\n",
            "  (scale0_layer0): Sequential(\n",
            "    (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale0_layer1): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale0_layer2): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale0_layer3): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale0_layer4): Sequential(\n",
            "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "  )\n",
            "  (scale1_layer0): Sequential(\n",
            "    (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale1_layer1): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale1_layer2): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale1_layer3): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (scale1_layer4): Sequential(\n",
            "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "  )\n",
            "  (downsample): AvgPool2d(kernel_size=3, stride=2, padding=[1, 1])\n",
            ")\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
            "100% 548M/548M [00:07<00:00, 79.7MB/s]\n",
            "create web directory ./checkpoints/nebbia_low/web...\n",
            "(epoch: 46, iters: 2100, time: 2.033) G_GAN: 1.831 G_GAN_Feat: 3.535 G_VGG: 1.215 D_real: 0.078 D_fake: 0.020 \n",
            "(epoch: 46, iters: 2200, time: 0.541) G_GAN: 1.994 G_GAN_Feat: 3.654 G_VGG: 1.360 D_real: 0.010 D_fake: 0.010 \n",
            "(epoch: 46, iters: 2300, time: 0.565) G_GAN: 1.787 G_GAN_Feat: 3.365 G_VGG: 1.581 D_real: 0.013 D_fake: 0.171 \n",
            "(epoch: 46, iters: 2400, time: 0.565) G_GAN: 1.894 G_GAN_Feat: 3.882 G_VGG: 1.889 D_real: 0.013 D_fake: 0.010 \n",
            "(epoch: 46, iters: 2500, time: 0.566) G_GAN: 1.832 G_GAN_Feat: 3.075 G_VGG: 1.415 D_real: 0.004 D_fake: 0.076 \n",
            "(epoch: 46, iters: 2600, time: 0.566) G_GAN: 2.027 G_GAN_Feat: 3.414 G_VGG: 1.470 D_real: 0.034 D_fake: 0.016 \n",
            "(epoch: 46, iters: 2700, time: 0.566) G_GAN: 2.481 G_GAN_Feat: 3.493 G_VGG: 1.408 D_real: 0.052 D_fake: 0.038 \n",
            "(epoch: 46, iters: 2800, time: 0.564) G_GAN: 1.439 G_GAN_Feat: 3.772 G_VGG: 1.472 D_real: 0.039 D_fake: 0.077 \n",
            "(epoch: 46, iters: 2900, time: 0.565) G_GAN: 2.277 G_GAN_Feat: 4.214 G_VGG: 1.679 D_real: 0.018 D_fake: 0.016 \n",
            "(epoch: 46, iters: 3000, time: 0.564) G_GAN: 1.819 G_GAN_Feat: 3.599 G_VGG: 2.208 D_real: 0.030 D_fake: 0.019 \n",
            "saving the latest model (epoch 46, total_steps 192000)\n",
            "(epoch: 46, iters: 3100, time: 0.567) G_GAN: 1.911 G_GAN_Feat: 3.672 G_VGG: 1.599 D_real: 0.013 D_fake: 0.011 \n",
            "(epoch: 46, iters: 3200, time: 0.564) G_GAN: 2.082 G_GAN_Feat: 4.140 G_VGG: 1.608 D_real: 0.007 D_fake: 0.004 \n",
            "(epoch: 46, iters: 3300, time: 0.566) G_GAN: 2.045 G_GAN_Feat: 3.007 G_VGG: 1.459 D_real: 0.017 D_fake: 0.006 \n",
            "(epoch: 46, iters: 3400, time: 0.566) G_GAN: 1.902 G_GAN_Feat: 3.477 G_VGG: 1.229 D_real: 0.036 D_fake: 0.029 \n",
            "(epoch: 46, iters: 3500, time: 0.566) G_GAN: 1.923 G_GAN_Feat: 3.444 G_VGG: 1.594 D_real: 0.068 D_fake: 0.051 \n",
            "(epoch: 46, iters: 3600, time: 0.566) G_GAN: 2.039 G_GAN_Feat: 3.629 G_VGG: 1.929 D_real: 0.038 D_fake: 0.007 \n",
            "(epoch: 46, iters: 3700, time: 0.566) G_GAN: 1.995 G_GAN_Feat: 3.599 G_VGG: 1.336 D_real: 0.004 D_fake: 0.003 \n",
            "(epoch: 46, iters: 3800, time: 0.566) G_GAN: 1.965 G_GAN_Feat: 3.367 G_VGG: 1.607 D_real: 0.010 D_fake: 0.006 \n",
            "(epoch: 46, iters: 3900, time: 0.566) G_GAN: 1.855 G_GAN_Feat: 3.266 G_VGG: 1.643 D_real: 0.008 D_fake: 0.019 \n",
            "(epoch: 46, iters: 4000, time: 0.566) G_GAN: 1.732 G_GAN_Feat: 3.909 G_VGG: 1.314 D_real: 0.028 D_fake: 0.024 \n",
            "saving the latest model (epoch 46, total_steps 193000)\n",
            "(epoch: 46, iters: 4100, time: 0.567) G_GAN: 2.145 G_GAN_Feat: 3.465 G_VGG: 1.233 D_real: 0.026 D_fake: 0.016 \n",
            "(epoch: 46, iters: 4200, time: 0.564) G_GAN: 2.077 G_GAN_Feat: 4.345 G_VGG: 1.768 D_real: 0.024 D_fake: 0.006 \n",
            "End of epoch 46 / 200 \t Time Taken: 1411 sec\n",
            "(epoch: 47, iters: 100, time: 0.567) G_GAN: 1.318 G_GAN_Feat: 3.398 G_VGG: 1.403 D_real: 0.037 D_fake: 0.175 \n",
            "(epoch: 47, iters: 200, time: 0.564) G_GAN: 1.906 G_GAN_Feat: 3.411 G_VGG: 1.754 D_real: 0.056 D_fake: 0.014 \n",
            "(epoch: 47, iters: 300, time: 0.566) G_GAN: 1.671 G_GAN_Feat: 3.748 G_VGG: 1.622 D_real: 0.024 D_fake: 0.039 \n",
            "(epoch: 47, iters: 400, time: 0.566) G_GAN: 1.940 G_GAN_Feat: 3.126 G_VGG: 1.432 D_real: 0.020 D_fake: 0.032 \n",
            "(epoch: 47, iters: 500, time: 0.566) G_GAN: 1.766 G_GAN_Feat: 3.586 G_VGG: 1.408 D_real: 0.105 D_fake: 0.033 \n",
            "(epoch: 47, iters: 600, time: 0.566) G_GAN: 2.179 G_GAN_Feat: 4.642 G_VGG: 1.503 D_real: 0.031 D_fake: 0.023 \n",
            "(epoch: 47, iters: 700, time: 0.564) G_GAN: 1.881 G_GAN_Feat: 3.317 G_VGG: 1.191 D_real: 0.021 D_fake: 0.015 \n",
            "(epoch: 47, iters: 800, time: 0.565) G_GAN: 2.079 G_GAN_Feat: 3.483 G_VGG: 1.387 D_real: 0.011 D_fake: 0.004 \n",
            "saving the latest model (epoch 47, total_steps 194000)\n",
            "(epoch: 47, iters: 900, time: 0.567) G_GAN: 2.089 G_GAN_Feat: 3.598 G_VGG: 2.025 D_real: 0.017 D_fake: 0.014 \n",
            "(epoch: 47, iters: 1000, time: 0.563) G_GAN: 1.952 G_GAN_Feat: 4.098 G_VGG: 1.383 D_real: 0.011 D_fake: 0.014 \n",
            "(epoch: 47, iters: 1100, time: 0.565) G_GAN: 2.044 G_GAN_Feat: 3.484 G_VGG: 1.292 D_real: 0.004 D_fake: 0.004 \n",
            "(epoch: 47, iters: 1200, time: 0.566) G_GAN: 2.024 G_GAN_Feat: 3.588 G_VGG: 1.479 D_real: 0.008 D_fake: 0.003 \n",
            "(epoch: 47, iters: 1300, time: 0.566) G_GAN: 2.008 G_GAN_Feat: 3.376 G_VGG: 1.562 D_real: 0.010 D_fake: 0.009 \n",
            "(epoch: 47, iters: 1400, time: 0.566) G_GAN: 2.220 G_GAN_Feat: 3.720 G_VGG: 1.556 D_real: 0.260 D_fake: 0.021 \n",
            "(epoch: 47, iters: 1500, time: 0.566) G_GAN: 2.251 G_GAN_Feat: 3.569 G_VGG: 1.620 D_real: 0.057 D_fake: 0.040 \n",
            "(epoch: 47, iters: 1600, time: 0.566) G_GAN: 2.033 G_GAN_Feat: 3.678 G_VGG: 1.441 D_real: 0.006 D_fake: 0.004 \n",
            "(epoch: 47, iters: 1700, time: 0.567) G_GAN: 1.978 G_GAN_Feat: 3.644 G_VGG: 1.290 D_real: 0.044 D_fake: 0.017 \n",
            "(epoch: 47, iters: 1800, time: 0.565) G_GAN: 1.577 G_GAN_Feat: 3.933 G_VGG: 1.908 D_real: 0.021 D_fake: 0.109 \n",
            "saving the latest model (epoch 47, total_steps 195000)\n",
            "(epoch: 47, iters: 1900, time: 0.567) G_GAN: 1.786 G_GAN_Feat: 3.150 G_VGG: 1.658 D_real: 0.022 D_fake: 0.036 \n",
            "(epoch: 47, iters: 2000, time: 0.564) G_GAN: 1.946 G_GAN_Feat: 3.285 G_VGG: 1.282 D_real: 0.008 D_fake: 0.009 \n",
            "(epoch: 47, iters: 2100, time: 0.566) G_GAN: 1.865 G_GAN_Feat: 3.526 G_VGG: 1.308 D_real: 0.012 D_fake: 0.019 \n",
            "(epoch: 47, iters: 2200, time: 0.564) G_GAN: 2.029 G_GAN_Feat: 3.107 G_VGG: 1.517 D_real: 0.007 D_fake: 0.006 \n",
            "(epoch: 47, iters: 2300, time: 0.566) G_GAN: 2.112 G_GAN_Feat: 3.596 G_VGG: 1.956 D_real: 0.012 D_fake: 0.008 \n",
            "(epoch: 47, iters: 2400, time: 0.565) G_GAN: 1.880 G_GAN_Feat: 3.284 G_VGG: 1.690 D_real: 0.111 D_fake: 0.052 \n",
            "(epoch: 47, iters: 2500, time: 0.566) G_GAN: 1.878 G_GAN_Feat: 3.615 G_VGG: 1.552 D_real: 0.016 D_fake: 0.009 \n",
            "(epoch: 47, iters: 2600, time: 0.565) G_GAN: 1.997 G_GAN_Feat: 3.495 G_VGG: 1.438 D_real: 0.040 D_fake: 0.011 \n",
            "(epoch: 47, iters: 2700, time: 0.566) G_GAN: 1.952 G_GAN_Feat: 3.405 G_VGG: 1.522 D_real: 0.035 D_fake: 0.016 \n",
            "(epoch: 47, iters: 2800, time: 0.565) G_GAN: 1.891 G_GAN_Feat: 4.202 G_VGG: 2.159 D_real: 0.048 D_fake: 0.009 \n",
            "saving the latest model (epoch 47, total_steps 196000)\n",
            "(epoch: 47, iters: 2900, time: 0.566) G_GAN: 2.017 G_GAN_Feat: 3.775 G_VGG: 2.439 D_real: 0.009 D_fake: 0.007 \n",
            "(epoch: 47, iters: 3000, time: 0.564) G_GAN: 2.264 G_GAN_Feat: 3.276 G_VGG: 1.598 D_real: 0.042 D_fake: 0.015 \n",
            "(epoch: 47, iters: 3100, time: 0.565) G_GAN: 1.886 G_GAN_Feat: 3.744 G_VGG: 1.556 D_real: 0.014 D_fake: 0.010 \n",
            "(epoch: 47, iters: 3200, time: 0.566) G_GAN: 2.026 G_GAN_Feat: 3.631 G_VGG: 1.580 D_real: 0.005 D_fake: 0.003 \n",
            "(epoch: 47, iters: 3300, time: 0.566) G_GAN: 3.737 G_GAN_Feat: 3.761 G_VGG: 1.587 D_real: 1.429 D_fake: 1.178 \n",
            "(epoch: 47, iters: 3400, time: 0.566) G_GAN: 1.929 G_GAN_Feat: 3.117 G_VGG: 1.687 D_real: 0.056 D_fake: 0.025 \n",
            "(epoch: 47, iters: 3500, time: 0.564) G_GAN: 1.500 G_GAN_Feat: 2.859 G_VGG: 1.664 D_real: 0.013 D_fake: 0.213 \n",
            "(epoch: 47, iters: 3600, time: 0.566) G_GAN: 1.831 G_GAN_Feat: 3.641 G_VGG: 1.666 D_real: 0.009 D_fake: 0.046 \n",
            "(epoch: 47, iters: 3700, time: 0.565) G_GAN: 2.114 G_GAN_Feat: 4.187 G_VGG: 1.524 D_real: 0.193 D_fake: 0.015 \n",
            "(epoch: 47, iters: 3800, time: 0.566) G_GAN: 2.007 G_GAN_Feat: 3.823 G_VGG: 1.821 D_real: 0.018 D_fake: 0.005 \n",
            "saving the latest model (epoch 47, total_steps 197000)\n",
            "(epoch: 47, iters: 3900, time: 0.566) G_GAN: 2.148 G_GAN_Feat: 3.888 G_VGG: 1.685 D_real: 0.047 D_fake: 0.012 \n",
            "(epoch: 47, iters: 4000, time: 0.564) G_GAN: 1.946 G_GAN_Feat: 3.858 G_VGG: 1.809 D_real: 0.015 D_fake: 0.006 \n",
            "(epoch: 47, iters: 4100, time: 0.567) G_GAN: 1.689 G_GAN_Feat: 3.653 G_VGG: 1.342 D_real: 0.043 D_fake: 0.036 \n",
            "(epoch: 47, iters: 4200, time: 0.564) G_GAN: 1.868 G_GAN_Feat: 3.820 G_VGG: 1.498 D_real: 0.029 D_fake: 0.046 \n",
            "End of epoch 47 / 200 \t Time Taken: 2394 sec\n",
            "(epoch: 48, iters: 100, time: 0.565) G_GAN: 1.510 G_GAN_Feat: 3.535 G_VGG: 1.507 D_real: 0.008 D_fake: 0.145 \n",
            "(epoch: 48, iters: 200, time: 0.566) G_GAN: 1.690 G_GAN_Feat: 3.136 G_VGG: 1.672 D_real: 0.016 D_fake: 0.162 \n",
            "(epoch: 48, iters: 300, time: 0.566) G_GAN: 2.064 G_GAN_Feat: 3.868 G_VGG: 1.761 D_real: 0.115 D_fake: 0.005 \n",
            "(epoch: 48, iters: 400, time: 0.566) G_GAN: 1.823 G_GAN_Feat: 3.496 G_VGG: 1.691 D_real: 0.052 D_fake: 0.028 \n",
            "(epoch: 48, iters: 500, time: 0.566) G_GAN: 1.509 G_GAN_Feat: 3.180 G_VGG: 1.397 D_real: 0.019 D_fake: 0.182 \n",
            "(epoch: 48, iters: 600, time: 0.565) G_GAN: 2.163 G_GAN_Feat: 3.608 G_VGG: 1.540 D_real: 0.006 D_fake: 0.008 \n",
            "saving the latest model (epoch 48, total_steps 198000)\n",
            "(epoch: 48, iters: 700, time: 0.566) G_GAN: 2.050 G_GAN_Feat: 3.851 G_VGG: 1.922 D_real: 0.003 D_fake: 0.003 \n",
            "(epoch: 48, iters: 800, time: 0.563) G_GAN: 1.693 G_GAN_Feat: 3.151 G_VGG: 1.331 D_real: 0.105 D_fake: 0.040 \n",
            "(epoch: 48, iters: 900, time: 0.566) G_GAN: 1.658 G_GAN_Feat: 3.238 G_VGG: 1.524 D_real: 0.021 D_fake: 0.062 \n",
            "(epoch: 48, iters: 1000, time: 0.563) G_GAN: 1.601 G_GAN_Feat: 4.518 G_VGG: 1.836 D_real: 0.026 D_fake: 0.056 \n",
            "(epoch: 48, iters: 1100, time: 0.564) G_GAN: 1.970 G_GAN_Feat: 3.087 G_VGG: 1.556 D_real: 0.004 D_fake: 0.005 \n",
            "(epoch: 48, iters: 1200, time: 0.566) G_GAN: 1.803 G_GAN_Feat: 3.915 G_VGG: 1.582 D_real: 0.011 D_fake: 0.014 \n",
            "(epoch: 48, iters: 1300, time: 0.564) G_GAN: 1.840 G_GAN_Feat: 3.434 G_VGG: 1.753 D_real: 0.007 D_fake: 0.056 \n",
            "(epoch: 48, iters: 1400, time: 0.566) G_GAN: 1.856 G_GAN_Feat: 2.937 G_VGG: 1.366 D_real: 0.014 D_fake: 0.205 \n",
            "(epoch: 48, iters: 1500, time: 0.565) G_GAN: 1.811 G_GAN_Feat: 3.178 G_VGG: 1.696 D_real: 0.013 D_fake: 0.058 \n",
            "(epoch: 48, iters: 1600, time: 0.566) G_GAN: 2.038 G_GAN_Feat: 3.379 G_VGG: 1.337 D_real: 0.047 D_fake: 0.006 \n",
            "saving the latest model (epoch 48, total_steps 199000)\n",
            "(epoch: 48, iters: 1700, time: 0.566) G_GAN: 1.967 G_GAN_Feat: 3.504 G_VGG: 1.700 D_real: 0.007 D_fake: 0.028 \n",
            "(epoch: 48, iters: 1800, time: 0.564) G_GAN: 2.133 G_GAN_Feat: 3.374 G_VGG: 1.815 D_real: 0.129 D_fake: 0.010 \n",
            "(epoch: 48, iters: 1900, time: 0.566) G_GAN: 2.008 G_GAN_Feat: 4.039 G_VGG: 1.726 D_real: 0.005 D_fake: 0.002 \n",
            "(epoch: 48, iters: 2000, time: 0.564) G_GAN: 1.909 G_GAN_Feat: 3.822 G_VGG: 1.224 D_real: 0.007 D_fake: 0.005 \n",
            "(epoch: 48, iters: 2100, time: 0.566) G_GAN: 2.104 G_GAN_Feat: 3.618 G_VGG: 1.637 D_real: 0.052 D_fake: 0.015 \n",
            "(epoch: 48, iters: 2200, time: 0.564) G_GAN: 1.886 G_GAN_Feat: 3.016 G_VGG: 1.210 D_real: 0.019 D_fake: 0.078 \n",
            "(epoch: 48, iters: 2300, time: 0.564) G_GAN: 2.094 G_GAN_Feat: 3.824 G_VGG: 1.393 D_real: 0.007 D_fake: 0.005 \n",
            "(epoch: 48, iters: 2400, time: 0.566) G_GAN: 1.771 G_GAN_Feat: 3.637 G_VGG: 1.575 D_real: 0.016 D_fake: 0.016 \n",
            "(epoch: 48, iters: 2500, time: 0.564) G_GAN: 2.121 G_GAN_Feat: 4.086 G_VGG: 1.604 D_real: 0.130 D_fake: 0.007 \n",
            "(epoch: 48, iters: 2600, time: 0.566) G_GAN: 1.843 G_GAN_Feat: 3.098 G_VGG: 1.512 D_real: 0.004 D_fake: 0.076 \n",
            "saving the latest model (epoch 48, total_steps 200000)\n",
            "(epoch: 48, iters: 2700, time: 0.566) G_GAN: 2.399 G_GAN_Feat: 3.472 G_VGG: 1.693 D_real: 0.095 D_fake: 0.033 \n",
            "(epoch: 48, iters: 2800, time: 0.566) G_GAN: 1.682 G_GAN_Feat: 3.672 G_VGG: 1.221 D_real: 0.040 D_fake: 0.038 \n",
            "(epoch: 48, iters: 2900, time: 0.564) G_GAN: 1.771 G_GAN_Feat: 3.266 G_VGG: 1.529 D_real: 0.073 D_fake: 0.030 \n",
            "(epoch: 48, iters: 3000, time: 0.565) G_GAN: 1.788 G_GAN_Feat: 3.631 G_VGG: 1.480 D_real: 0.008 D_fake: 0.016 \n",
            "(epoch: 48, iters: 3100, time: 0.565) G_GAN: 1.978 G_GAN_Feat: 3.477 G_VGG: 1.619 D_real: 0.020 D_fake: 0.005 \n",
            "(epoch: 48, iters: 3200, time: 0.567) G_GAN: 2.306 G_GAN_Feat: 3.714 G_VGG: 1.695 D_real: 0.071 D_fake: 0.019 \n",
            "(epoch: 48, iters: 3300, time: 0.565) G_GAN: 1.988 G_GAN_Feat: 3.415 G_VGG: 1.615 D_real: 0.012 D_fake: 0.026 \n",
            "(epoch: 48, iters: 3400, time: 0.565) G_GAN: 1.947 G_GAN_Feat: 3.326 G_VGG: 1.374 D_real: 0.044 D_fake: 0.004 \n",
            "(epoch: 48, iters: 3500, time: 0.566) G_GAN: 2.050 G_GAN_Feat: 3.328 G_VGG: 1.447 D_real: 0.005 D_fake: 0.005 \n",
            "(epoch: 48, iters: 3600, time: 0.565) G_GAN: 2.060 G_GAN_Feat: 4.175 G_VGG: 1.484 D_real: 0.003 D_fake: 0.003 \n",
            "saving the latest model (epoch 48, total_steps 201000)\n",
            "(epoch: 48, iters: 3700, time: 0.567) G_GAN: 2.105 G_GAN_Feat: 3.204 G_VGG: 1.622 D_real: 0.009 D_fake: 0.007 \n",
            "(epoch: 48, iters: 3800, time: 0.564) G_GAN: 1.782 G_GAN_Feat: 3.510 G_VGG: 1.549 D_real: 0.036 D_fake: 0.056 \n",
            "(epoch: 48, iters: 3900, time: 0.564) G_GAN: 1.891 G_GAN_Feat: 3.860 G_VGG: 1.592 D_real: 0.014 D_fake: 0.009 \n",
            "(epoch: 48, iters: 4000, time: 0.565) G_GAN: 1.908 G_GAN_Feat: 3.141 G_VGG: 1.567 D_real: 0.009 D_fake: 0.029 \n",
            "(epoch: 48, iters: 4100, time: 0.566) G_GAN: 2.013 G_GAN_Feat: 3.811 G_VGG: 1.627 D_real: 0.003 D_fake: 0.008 \n",
            "(epoch: 48, iters: 4200, time: 0.566) G_GAN: 1.804 G_GAN_Feat: 3.061 G_VGG: 1.385 D_real: 0.008 D_fake: 0.110 \n",
            "End of epoch 48 / 200 \t Time Taken: 2391 sec\n",
            "(epoch: 49, iters: 100, time: 0.566) G_GAN: 2.053 G_GAN_Feat: 4.104 G_VGG: 1.520 D_real: 0.006 D_fake: 0.004 \n",
            "(epoch: 49, iters: 200, time: 0.566) G_GAN: 1.826 G_GAN_Feat: 3.041 G_VGG: 1.603 D_real: 0.008 D_fake: 0.028 \n",
            "(epoch: 49, iters: 300, time: 0.566) G_GAN: 2.039 G_GAN_Feat: 4.251 G_VGG: 1.343 D_real: 0.005 D_fake: 0.004 \n",
            "(epoch: 49, iters: 400, time: 0.566) G_GAN: 2.055 G_GAN_Feat: 3.834 G_VGG: 1.576 D_real: 0.009 D_fake: 0.006 \n",
            "saving the latest model (epoch 49, total_steps 202000)\n",
            "(epoch: 49, iters: 500, time: 0.566) G_GAN: 2.035 G_GAN_Feat: 3.855 G_VGG: 1.706 D_real: 0.037 D_fake: 0.016 \n",
            "(epoch: 49, iters: 600, time: 0.564) G_GAN: 1.572 G_GAN_Feat: 3.612 G_VGG: 1.627 D_real: 0.028 D_fake: 0.077 \n",
            "(epoch: 49, iters: 700, time: 0.565) G_GAN: 1.792 G_GAN_Feat: 3.170 G_VGG: 1.286 D_real: 0.007 D_fake: 0.143 \n",
            "(epoch: 49, iters: 800, time: 0.566) G_GAN: 2.322 G_GAN_Feat: 3.774 G_VGG: 1.728 D_real: 0.104 D_fake: 0.023 \n",
            "(epoch: 49, iters: 900, time: 0.565) G_GAN: 2.003 G_GAN_Feat: 3.539 G_VGG: 1.567 D_real: 0.013 D_fake: 0.008 \n",
            "(epoch: 49, iters: 1000, time: 0.566) G_GAN: 2.270 G_GAN_Feat: 4.460 G_VGG: 1.794 D_real: 0.034 D_fake: 0.027 \n",
            "(epoch: 49, iters: 1100, time: 0.565) G_GAN: 2.102 G_GAN_Feat: 4.086 G_VGG: 1.240 D_real: 0.008 D_fake: 0.006 \n",
            "(epoch: 49, iters: 1200, time: 0.566) G_GAN: 2.046 G_GAN_Feat: 4.353 G_VGG: 1.444 D_real: 0.031 D_fake: 0.003 \n",
            "(epoch: 49, iters: 1300, time: 0.564) G_GAN: 2.260 G_GAN_Feat: 3.821 G_VGG: 1.810 D_real: 0.039 D_fake: 0.025 \n",
            "(epoch: 49, iters: 1400, time: 0.566) G_GAN: 1.921 G_GAN_Feat: 3.081 G_VGG: 1.625 D_real: 0.007 D_fake: 0.006 \n",
            "saving the latest model (epoch 49, total_steps 203000)\n",
            "(epoch: 49, iters: 1500, time: 0.567) G_GAN: 2.005 G_GAN_Feat: 3.360 G_VGG: 1.317 D_real: 0.059 D_fake: 0.014 \n",
            "(epoch: 49, iters: 1600, time: 0.565) G_GAN: 2.168 G_GAN_Feat: 3.582 G_VGG: 1.599 D_real: 0.078 D_fake: 0.010 \n",
            "(epoch: 49, iters: 1700, time: 0.564) G_GAN: 2.086 G_GAN_Feat: 3.379 G_VGG: 1.429 D_real: 0.009 D_fake: 0.005 \n",
            "(epoch: 49, iters: 1800, time: 0.566) G_GAN: 1.992 G_GAN_Feat: 3.611 G_VGG: 1.487 D_real: 0.005 D_fake: 0.006 \n",
            "(epoch: 49, iters: 1900, time: 0.566) G_GAN: 1.798 G_GAN_Feat: 3.674 G_VGG: 1.524 D_real: 0.057 D_fake: 0.044 \n",
            "(epoch: 49, iters: 2000, time: 0.565) G_GAN: 1.811 G_GAN_Feat: 3.315 G_VGG: 1.874 D_real: 0.008 D_fake: 0.020 \n",
            "(epoch: 49, iters: 2100, time: 0.566) G_GAN: 1.975 G_GAN_Feat: 3.808 G_VGG: 1.616 D_real: 0.036 D_fake: 0.008 \n",
            "(epoch: 49, iters: 2200, time: 0.565) G_GAN: 1.884 G_GAN_Feat: 3.858 G_VGG: 1.959 D_real: 0.037 D_fake: 0.013 \n",
            "(epoch: 49, iters: 2300, time: 0.566) G_GAN: 1.794 G_GAN_Feat: 4.037 G_VGG: 1.581 D_real: 0.020 D_fake: 0.013 \n",
            "(epoch: 49, iters: 2400, time: 0.565) G_GAN: 1.819 G_GAN_Feat: 4.098 G_VGG: 1.300 D_real: 0.006 D_fake: 0.057 \n",
            "saving the latest model (epoch 49, total_steps 204000)\n",
            "(epoch: 49, iters: 2500, time: 0.568) G_GAN: 1.740 G_GAN_Feat: 3.360 G_VGG: 1.614 D_real: 0.048 D_fake: 0.191 \n",
            "(epoch: 49, iters: 2600, time: 0.564) G_GAN: 1.680 G_GAN_Feat: 3.281 G_VGG: 1.246 D_real: 0.017 D_fake: 0.027 \n",
            "(epoch: 49, iters: 2700, time: 0.565) G_GAN: 1.756 G_GAN_Feat: 3.469 G_VGG: 1.539 D_real: 0.018 D_fake: 0.020 \n",
            "(epoch: 49, iters: 2800, time: 0.566) G_GAN: 2.503 G_GAN_Feat: 3.425 G_VGG: 1.447 D_real: 0.073 D_fake: 0.033 \n",
            "(epoch: 49, iters: 2900, time: 0.566) G_GAN: 1.974 G_GAN_Feat: 2.911 G_VGG: 1.213 D_real: 0.017 D_fake: 0.020 \n",
            "(epoch: 49, iters: 3000, time: 0.566) G_GAN: 1.776 G_GAN_Feat: 3.297 G_VGG: 1.426 D_real: 0.010 D_fake: 0.016 \n",
            "(epoch: 49, iters: 3100, time: 0.566) G_GAN: 1.826 G_GAN_Feat: 3.100 G_VGG: 1.415 D_real: 0.005 D_fake: 0.047 \n",
            "(epoch: 49, iters: 3200, time: 0.565) G_GAN: 1.956 G_GAN_Feat: 3.689 G_VGG: 1.481 D_real: 0.005 D_fake: 0.004 \n",
            "(epoch: 49, iters: 3300, time: 0.566) G_GAN: 2.276 G_GAN_Feat: 3.480 G_VGG: 1.751 D_real: 0.048 D_fake: 0.023 \n",
            "(epoch: 49, iters: 3400, time: 0.564) G_GAN: 2.074 G_GAN_Feat: 3.562 G_VGG: 1.312 D_real: 0.019 D_fake: 0.004 \n",
            "saving the latest model (epoch 49, total_steps 205000)\n",
            "(epoch: 49, iters: 3500, time: 0.567) G_GAN: 1.156 G_GAN_Feat: 3.115 G_VGG: 1.498 D_real: 0.049 D_fake: 0.416 \n",
            "(epoch: 49, iters: 3600, time: 0.564) G_GAN: 1.985 G_GAN_Feat: 3.362 G_VGG: 1.824 D_real: 0.013 D_fake: 0.018 \n",
            "(epoch: 49, iters: 3700, time: 0.565) G_GAN: 1.688 G_GAN_Feat: 3.303 G_VGG: 1.544 D_real: 0.023 D_fake: 0.059 \n",
            "(epoch: 49, iters: 3800, time: 0.566) G_GAN: 1.933 G_GAN_Feat: 3.989 G_VGG: 1.512 D_real: 0.010 D_fake: 0.005 \n",
            "(epoch: 49, iters: 3900, time: 0.566) G_GAN: 1.754 G_GAN_Feat: 3.375 G_VGG: 1.475 D_real: 0.010 D_fake: 0.177 \n",
            "(epoch: 49, iters: 4000, time: 0.565) G_GAN: 2.057 G_GAN_Feat: 3.394 G_VGG: 1.403 D_real: 0.006 D_fake: 0.006 \n",
            "(epoch: 49, iters: 4100, time: 0.565) G_GAN: 1.698 G_GAN_Feat: 3.527 G_VGG: 1.683 D_real: 0.024 D_fake: 0.047 \n",
            "(epoch: 49, iters: 4200, time: 0.565) G_GAN: 1.883 G_GAN_Feat: 3.699 G_VGG: 1.771 D_real: 0.004 D_fake: 0.012 \n",
            "End of epoch 49 / 200 \t Time Taken: 2392 sec\n",
            "(epoch: 50, iters: 100, time: 0.564) G_GAN: 2.049 G_GAN_Feat: 3.784 G_VGG: 1.324 D_real: 0.005 D_fake: 0.005 \n",
            "(epoch: 50, iters: 200, time: 0.566) G_GAN: 1.921 G_GAN_Feat: 3.931 G_VGG: 1.659 D_real: 0.005 D_fake: 0.004 \n",
            "saving the latest model (epoch 50, total_steps 206000)\n",
            "(epoch: 50, iters: 300, time: 0.566) G_GAN: 1.957 G_GAN_Feat: 3.716 G_VGG: 1.389 D_real: 0.021 D_fake: 0.006 \n",
            "(epoch: 50, iters: 400, time: 0.566) G_GAN: 2.002 G_GAN_Feat: 3.126 G_VGG: 1.714 D_real: 0.043 D_fake: 0.005 \n",
            "(epoch: 50, iters: 500, time: 0.564) G_GAN: 1.918 G_GAN_Feat: 3.106 G_VGG: 1.140 D_real: 0.004 D_fake: 0.040 \n",
            "(epoch: 50, iters: 600, time: 0.565) G_GAN: 2.015 G_GAN_Feat: 3.601 G_VGG: 1.606 D_real: 0.012 D_fake: 0.003 \n",
            "(epoch: 50, iters: 700, time: 0.565) G_GAN: 1.957 G_GAN_Feat: 3.905 G_VGG: 1.547 D_real: 0.007 D_fake: 0.006 \n",
            "(epoch: 50, iters: 800, time: 0.566) G_GAN: 1.624 G_GAN_Feat: 3.057 G_VGG: 1.376 D_real: 0.020 D_fake: 0.213 \n",
            "(epoch: 50, iters: 900, time: 0.566) G_GAN: 1.866 G_GAN_Feat: 4.734 G_VGG: 1.771 D_real: 0.032 D_fake: 0.020 \n",
            "(epoch: 50, iters: 1000, time: 0.565) G_GAN: 1.844 G_GAN_Feat: 3.334 G_VGG: 1.391 D_real: 0.006 D_fake: 0.025 \n",
            "(epoch: 50, iters: 1100, time: 0.567) G_GAN: 2.057 G_GAN_Feat: 3.410 G_VGG: 1.095 D_real: 0.008 D_fake: 0.004 \n",
            "(epoch: 50, iters: 1200, time: 0.565) G_GAN: 1.839 G_GAN_Feat: 3.008 G_VGG: 1.569 D_real: 0.006 D_fake: 0.041 \n",
            "saving the latest model (epoch 50, total_steps 207000)\n",
            "(epoch: 50, iters: 1300, time: 0.568) G_GAN: 1.939 G_GAN_Feat: 3.100 G_VGG: 1.365 D_real: 0.006 D_fake: 0.005 \n",
            "(epoch: 50, iters: 1400, time: 0.564) G_GAN: 2.015 G_GAN_Feat: 4.059 G_VGG: 1.142 D_real: 0.014 D_fake: 0.003 \n",
            "(epoch: 50, iters: 1500, time: 0.566) G_GAN: 2.126 G_GAN_Feat: 3.532 G_VGG: 1.658 D_real: 0.011 D_fake: 0.009 \n",
            "(epoch: 50, iters: 1600, time: 0.565) G_GAN: 2.081 G_GAN_Feat: 3.654 G_VGG: 1.488 D_real: 0.008 D_fake: 0.006 \n",
            "(epoch: 50, iters: 1700, time: 0.565) G_GAN: 1.960 G_GAN_Feat: 3.285 G_VGG: 1.624 D_real: 0.007 D_fake: 0.016 \n",
            "(epoch: 50, iters: 1800, time: 0.565) G_GAN: 1.906 G_GAN_Feat: 3.920 G_VGG: 1.575 D_real: 0.191 D_fake: 0.014 \n",
            "(epoch: 50, iters: 1900, time: 0.566) G_GAN: 1.387 G_GAN_Feat: 3.364 G_VGG: 1.291 D_real: 0.106 D_fake: 0.379 \n",
            "(epoch: 50, iters: 2000, time: 0.565) G_GAN: 1.830 G_GAN_Feat: 3.077 G_VGG: 1.374 D_real: 0.024 D_fake: 0.051 \n",
            "(epoch: 50, iters: 2100, time: 0.566) G_GAN: 1.989 G_GAN_Feat: 3.553 G_VGG: 1.364 D_real: 0.009 D_fake: 0.008 \n",
            "(epoch: 50, iters: 2200, time: 0.565) G_GAN: 1.800 G_GAN_Feat: 3.455 G_VGG: 1.592 D_real: 0.018 D_fake: 0.018 \n",
            "saving the latest model (epoch 50, total_steps 208000)\n",
            "(epoch: 50, iters: 2300, time: 0.567) G_GAN: 1.873 G_GAN_Feat: 3.513 G_VGG: 1.597 D_real: 0.078 D_fake: 0.067 \n",
            "(epoch: 50, iters: 2400, time: 0.567) G_GAN: 1.735 G_GAN_Feat: 3.481 G_VGG: 1.663 D_real: 0.022 D_fake: 0.074 \n",
            "(epoch: 50, iters: 2500, time: 0.566) G_GAN: 2.000 G_GAN_Feat: 3.215 G_VGG: 1.355 D_real: 0.007 D_fake: 0.009 \n",
            "(epoch: 50, iters: 2600, time: 0.566) G_GAN: 2.052 G_GAN_Feat: 3.496 G_VGG: 1.486 D_real: 0.005 D_fake: 0.004 \n",
            "(epoch: 50, iters: 2700, time: 0.565) G_GAN: 1.702 G_GAN_Feat: 3.103 G_VGG: 1.577 D_real: 0.009 D_fake: 0.044 \n",
            "(epoch: 50, iters: 2800, time: 0.566) G_GAN: 1.800 G_GAN_Feat: 3.415 G_VGG: 1.425 D_real: 0.004 D_fake: 0.031 \n",
            "(epoch: 50, iters: 2900, time: 0.567) G_GAN: 1.913 G_GAN_Feat: 3.896 G_VGG: 1.379 D_real: 0.034 D_fake: 0.006 \n",
            "(epoch: 50, iters: 3000, time: 0.564) G_GAN: 2.232 G_GAN_Feat: 3.793 G_VGG: 1.694 D_real: 0.204 D_fake: 0.019 \n",
            "(epoch: 50, iters: 3100, time: 0.567) G_GAN: 1.861 G_GAN_Feat: 3.369 G_VGG: 1.588 D_real: 0.035 D_fake: 0.024 \n",
            "(epoch: 50, iters: 3200, time: 0.564) G_GAN: 1.788 G_GAN_Feat: 2.864 G_VGG: 1.397 D_real: 0.071 D_fake: 0.026 \n",
            "saving the latest model (epoch 50, total_steps 209000)\n",
            "(epoch: 50, iters: 3300, time: 0.567) G_GAN: 1.965 G_GAN_Feat: 3.575 G_VGG: 1.729 D_real: 0.115 D_fake: 0.076 \n",
            "(epoch: 50, iters: 3400, time: 0.565) G_GAN: 1.890 G_GAN_Feat: 4.545 G_VGG: 1.407 D_real: 0.021 D_fake: 0.006 \n",
            "(epoch: 50, iters: 3500, time: 0.566) G_GAN: 2.216 G_GAN_Feat: 3.566 G_VGG: 1.388 D_real: 0.019 D_fake: 0.016 \n",
            "(epoch: 50, iters: 3600, time: 0.566) G_GAN: 1.994 G_GAN_Feat: 3.989 G_VGG: 1.453 D_real: 0.016 D_fake: 0.005 \n",
            "(epoch: 50, iters: 3700, time: 0.565) G_GAN: 1.921 G_GAN_Feat: 3.533 G_VGG: 1.643 D_real: 0.006 D_fake: 0.006 \n",
            "(epoch: 50, iters: 3800, time: 0.565) G_GAN: 2.163 G_GAN_Feat: 4.375 G_VGG: 1.676 D_real: 0.012 D_fake: 0.006 \n",
            "(epoch: 50, iters: 3900, time: 0.564) G_GAN: 1.408 G_GAN_Feat: 3.425 G_VGG: 1.537 D_real: 0.030 D_fake: 0.346 \n",
            "(epoch: 50, iters: 4000, time: 0.565) G_GAN: 1.757 G_GAN_Feat: 2.877 G_VGG: 1.473 D_real: 0.010 D_fake: 0.045 \n",
            "(epoch: 50, iters: 4100, time: 0.566) G_GAN: 2.160 G_GAN_Feat: 5.176 G_VGG: 1.871 D_real: 0.012 D_fake: 0.010 \n",
            "(epoch: 50, iters: 4200, time: 0.566) G_GAN: 2.068 G_GAN_Feat: 3.600 G_VGG: 1.203 D_real: 0.064 D_fake: 0.047 \n",
            "saving the latest model (epoch 50, total_steps 210000)\n",
            "End of epoch 50 / 200 \t Time Taken: 2393 sec\n",
            "saving the model at the end of epoch 50, iters 210000\n",
            "(epoch: 51, iters: 100, time: 0.571) G_GAN: 2.017 G_GAN_Feat: 3.511 G_VGG: 1.727 D_real: 0.013 D_fake: 0.008 \n",
            "(epoch: 51, iters: 200, time: 0.563) G_GAN: 1.909 G_GAN_Feat: 3.503 G_VGG: 1.196 D_real: 0.005 D_fake: 0.022 \n",
            "(epoch: 51, iters: 300, time: 0.565) G_GAN: 2.011 G_GAN_Feat: 3.585 G_VGG: 1.418 D_real: 0.016 D_fake: 0.007 \n",
            "(epoch: 51, iters: 400, time: 0.567) G_GAN: 2.084 G_GAN_Feat: 3.762 G_VGG: 1.568 D_real: 0.011 D_fake: 0.007 \n",
            "(epoch: 51, iters: 500, time: 0.566) G_GAN: 1.820 G_GAN_Feat: 3.397 G_VGG: 1.562 D_real: 0.020 D_fake: 0.021 \n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1MeMU7hWD5WVMk25vU3ch5Ii3csnSydwf/Haze-Fog-suppression/pix2pixHD/train.py\", line 70, in <module>\n",
            "    losses, generated = model(Variable(data['label']), Variable(data['inst']), \n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n",
            "    return self.module(*inputs[0], **kwargs[0])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1MeMU7hWD5WVMk25vU3ch5Ii3csnSydwf/Haze-Fog-suppression/pix2pixHD/models/pix2pixHD_model.py\", line 170, in forward\n",
            "    pred_real = self.discriminate(input_label, real_image)\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1MeMU7hWD5WVMk25vU3ch5Ii3csnSydwf/Haze-Fog-suppression/pix2pixHD/models/pix2pixHD_model.py\", line 150, in discriminate\n",
            "    return self.netD.forward(input_concat)\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1MeMU7hWD5WVMk25vU3ch5Ii3csnSydwf/Haze-Fog-suppression/pix2pixHD/models/networks.py\", line 328, in forward\n",
            "    result.append(self.singleD_forward(model, input_downsampled))\n",
            "  File \"/content/drive/.shortcut-targets-by-id/1MeMU7hWD5WVMk25vU3ch5Ii3csnSydwf/Haze-Fog-suppression/pix2pixHD/models/networks.py\", line 314, in singleD_forward\n",
            "    result.append(model[i](result[-1]))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\", line 217, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/instancenorm.py\", line 74, in forward\n",
            "    return self._apply_instance_norm(input)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/instancenorm.py\", line 34, in _apply_instance_norm\n",
            "    return F.instance_norm(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\", line 2495, in instance_norm\n",
            "    return torch.instance_norm(\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "#training on low resolution only G1\n",
        "!python train.py --continue_train --label_nc 0 --no_instance --name nebbia_low --dataroot ./datasets/nebbia_low --resize_or_crop crop --fineSize 512 --batchSize 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KHhH8FILC0Od",
        "outputId": "3e24808e-2079-4187-e544-cc59b988786b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------ Options -------------\n",
            "batchSize: 4\n",
            "beta1: 0.5\n",
            "checkpoints_dir: ./checkpoints\n",
            "continue_train: True\n",
            "data_type: 32\n",
            "dataroot: ./datasets/nebbia_medium\n",
            "debug: False\n",
            "display_freq: 100\n",
            "display_winsize: 512\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: True\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "lambda_feat: 10.0\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "load_pretrain: \n",
            "local_rank: 0\n",
            "lr: 0.0002\n",
            "max_dataset_size: inf\n",
            "model: pix2pixHD\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_layers_D: 3\n",
            "n_local_enhancers: 1\n",
            "name: nebbia_medium\n",
            "ndf: 64\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter: 100\n",
            "niter_decay: 100\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_ganFeat_loss: False\n",
            "no_html: False\n",
            "no_instance: True\n",
            "no_lsgan: False\n",
            "no_vgg_loss: False\n",
            "norm: instance\n",
            "num_D: 2\n",
            "output_nc: 3\n",
            "phase: train\n",
            "pool_size: 0\n",
            "print_freq: 100\n",
            "resize_or_crop: crop\n",
            "save_epoch_freq: 10\n",
            "save_latest_freq: 1000\n",
            "serial_batches: False\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "verbose: False\n",
            "which_epoch: latest\n",
            "-------------- End ----------------\n",
            "Resuming from epoch 51 at iteration 3000\n",
            "CustomDatasetDataLoader\n",
            "dataset [AlignedDataset] was created\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-c5cac3211b9c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#training on low resolution only G1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python train.py --continue_train --label_nc 0 --no_instance --name nebbia_medium --dataroot ./datasets/nebbia_medium --resize_or_crop crop --fineSize 512 --batchSize 4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    451\u001b[0m   \u001b[0;31m# is expected to call this function, thus adding one level of nesting to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m   result = _run_command(\n\u001b[0m\u001b[1;32m    454\u001b[0m       \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    201\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_monitor_process\u001b[0;34m(parent_pty, epoll, p, cmd, update_stdin_widget)\u001b[0m\n\u001b[1;32m    231\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_poll_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_poll_process\u001b[0;34m(parent_pty, epoll, p, cmd, decoder, state)\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;31m# TODO(b/115527726): Rather than sleep, poll for incoming messages from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;31m# the frontend in the same poll as for the output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#training on low resolution only G1\n",
        "!python train.py --continue_train --label_nc 0 --no_instance --name nebbia_medium --dataroot ./datasets/nebbia_medium --resize_or_crop crop --fineSize 512 --batchSize 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QnrdU2E9C0hN",
        "outputId": "f442f15d-aa97-4bb7-b406-89a392c75029"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------ Options -------------\n",
            "batchSize: 4\n",
            "beta1: 0.5\n",
            "checkpoints_dir: ./checkpoints\n",
            "continue_train: True\n",
            "data_type: 32\n",
            "dataroot: ./datasets/nebbia_high\n",
            "debug: False\n",
            "display_freq: 100\n",
            "display_winsize: 512\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: True\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "lambda_feat: 10.0\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "load_pretrain: \n",
            "local_rank: 0\n",
            "lr: 0.0002\n",
            "max_dataset_size: inf\n",
            "model: pix2pixHD\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_layers_D: 3\n",
            "n_local_enhancers: 1\n",
            "name: nebbia_high\n",
            "ndf: 64\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter: 100\n",
            "niter_decay: 100\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_ganFeat_loss: False\n",
            "no_html: False\n",
            "no_instance: True\n",
            "no_lsgan: False\n",
            "no_vgg_loss: False\n",
            "norm: instance\n",
            "num_D: 2\n",
            "output_nc: 3\n",
            "phase: train\n",
            "pool_size: 0\n",
            "print_freq: 100\n",
            "resize_or_crop: crop\n",
            "save_epoch_freq: 10\n",
            "save_latest_freq: 1000\n",
            "serial_batches: False\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "verbose: False\n",
            "which_epoch: latest\n",
            "-------------- End ----------------\n",
            "Resuming from epoch 51 at iteration 2000\n",
            "CustomDatasetDataLoader\n",
            "dataset [AlignedDataset] was created\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-62a011cc3f7e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#training on low resolution only G1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python train.py --continue_train --label_nc 0 --no_instance --name nebbia_high --dataroot ./datasets/nebbia_high --resize_or_crop crop --fineSize 512 --batchSize 4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    451\u001b[0m   \u001b[0;31m# is expected to call this function, thus adding one level of nesting to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m   result = _run_command(\n\u001b[0m\u001b[1;32m    454\u001b[0m       \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    201\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_monitor_process\u001b[0;34m(parent_pty, epoll, p, cmd, update_stdin_widget)\u001b[0m\n\u001b[1;32m    231\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_poll_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_poll_process\u001b[0;34m(parent_pty, epoll, p, cmd, decoder, state)\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;31m# TODO(b/115527726): Rather than sleep, poll for incoming messages from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;31m# the frontend in the same poll as for the output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#training on low resolution only G1\n",
        "!python train.py --continue_train --label_nc 0 --no_instance --name nebbia_high --dataroot ./datasets/nebbia_high --resize_or_crop crop --fineSize 512 --batchSize 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEuQqQPxGISq"
      },
      "source": [
        "# Pix2Pix test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79Es7B0cdWS-"
      },
      "source": [
        "## General model epoch 50\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_m4nxHHLAtxf",
        "outputId": "0bbb556c-789e-470a-bf89-ba2b113b4201"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------ Options -------------\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 1\n",
            "checkpoints_dir: ./checkpoints\n",
            "cluster_path: features_clustered_010.npy\n",
            "data_type: 32\n",
            "dataroot: ./datasets/indoor\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 500\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "model: pix2pixHD\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_local_enhancers: 1\n",
            "name: nebbia\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: True\n",
            "norm: instance\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "phase: test\n",
            "resize_or_crop: none\n",
            "results_dir: ./datasets/indoor/synth\n",
            "serial_batches: False\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "verbose: False\n",
            "which_epoch: 50\n",
            "-------------- End ----------------\n",
            "CustomDatasetDataLoader\n",
            "dataset [AlignedDataset] was created\n",
            "GlobalGenerator(\n",
            "  (model): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (11): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (14): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (17): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (18): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (19): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (20): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (21): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (22): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (23): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (24): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (25): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (26): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (29): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (30): ReLU(inplace=True)\n",
            "    (31): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (32): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (33): ReLU(inplace=True)\n",
            "    (34): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (35): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (38): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (39): Tanh()\n",
            "  )\n",
            ")\n",
            "/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/models/pix2pixHD_model.py:128: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  input_label = Variable(input_label, volatile=infer)\n",
            "process image... ['./datasets/indoor/test_A/1400_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1400_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1400_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1400_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1400_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1400_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1400_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1400_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1400_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1400_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1401_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1401_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1401_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1401_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1401_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1401_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1401_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1401_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1401_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1401_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1402_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1402_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1402_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1402_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1402_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1402_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1402_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1402_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1402_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1402_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1403_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1403_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1403_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1403_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1403_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1403_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1403_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1403_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1403_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1403_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1404_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1404_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1404_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1404_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1404_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1404_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1404_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1404_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1404_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1404_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1405_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1405_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1405_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1405_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1405_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1405_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1405_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1405_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1405_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1405_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1406_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1406_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1406_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1406_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1406_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1406_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1406_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1406_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1406_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1406_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1407_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1407_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1407_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1407_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1407_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1407_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1407_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1407_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1407_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1407_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1408_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1408_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1408_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1408_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1408_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1408_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1408_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1408_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1408_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1408_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1409_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1409_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1409_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1409_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1409_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1409_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1409_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1409_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1409_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1409_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1410_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1410_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1410_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1410_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1410_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1410_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1410_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1410_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1410_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1410_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1411_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1411_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1411_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1411_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1411_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1411_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1411_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1411_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1411_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1411_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1412_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1412_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1412_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1412_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1412_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1412_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1412_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1412_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1412_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1412_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1413_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1413_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1413_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1413_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1413_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1413_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1413_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1413_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1413_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1413_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1414_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1414_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1414_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1414_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1414_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1414_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1414_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1414_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1414_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1414_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1415_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1415_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1415_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1415_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1415_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1415_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1415_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1415_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1415_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1415_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1416_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1416_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1416_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1416_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1416_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1416_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1416_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1416_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1416_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1416_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1417_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1417_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1417_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1417_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1417_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1417_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1417_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1417_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1417_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1417_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1418_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1418_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1418_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1418_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1418_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1418_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1418_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1418_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1418_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1418_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1419_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1419_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1419_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1419_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1419_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1419_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1419_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1419_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1419_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1419_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1420_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1420_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1420_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1420_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1420_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1420_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1420_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1420_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1420_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1420_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1421_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1421_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1421_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1421_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1421_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1421_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1421_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1421_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1421_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1421_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1422_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1422_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1422_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1422_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1422_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1422_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1422_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1422_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1422_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1422_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1423_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1423_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1423_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1423_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1423_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1423_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1423_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1423_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1423_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1423_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1424_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1424_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1424_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1424_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1424_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1424_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1424_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1424_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1424_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1424_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1425_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1425_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1425_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1425_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1425_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1425_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1425_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1425_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1425_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1425_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1426_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1426_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1426_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1426_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1426_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1426_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1426_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1426_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1426_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1426_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1427_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1427_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1427_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1427_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1427_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1427_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1427_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1427_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1427_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1427_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1428_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1428_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1428_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1428_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1428_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1428_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1428_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1428_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1428_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1428_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1429_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1429_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1429_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1429_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1429_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1429_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1429_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1429_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1429_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1429_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1430_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1430_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1430_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1430_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1430_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1430_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1430_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1430_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1430_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1430_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1431_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1431_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1431_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1431_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1431_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1431_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1431_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1431_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1431_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1431_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1432_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1432_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1432_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1432_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1432_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1432_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1432_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1432_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1432_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1432_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1433_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1433_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1433_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1433_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1433_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1433_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1433_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1433_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1433_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1433_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1434_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1434_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1434_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1434_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1434_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1434_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1434_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1434_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1434_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1434_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1435_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1435_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1435_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1435_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1435_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1435_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1435_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1435_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1435_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1435_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1436_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1436_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1436_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1436_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1436_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1436_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1436_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1436_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1436_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1436_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1437_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1437_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1437_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1437_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1437_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1437_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1437_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1437_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1437_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1437_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1438_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1438_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1438_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1438_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1438_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1438_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1438_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1438_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1438_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1438_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1439_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1439_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1439_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1439_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1439_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1439_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1439_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1439_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1439_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1439_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1440_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1440_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1440_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1440_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1440_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1440_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1440_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1440_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1440_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1440_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1441_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1441_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1441_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1441_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1441_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1441_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1441_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1441_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1441_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1441_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1442_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1442_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1442_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1442_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1442_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1442_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1442_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1442_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1442_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1442_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1443_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1443_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1443_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1443_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1443_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1443_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1443_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1443_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1443_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1443_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1444_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1444_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1444_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1444_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1444_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1444_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1444_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1444_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1444_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1444_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1445_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1445_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1445_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1445_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1445_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1445_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1445_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1445_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1445_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1445_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1446_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1446_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1446_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1446_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1446_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1446_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1446_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1446_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1446_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1446_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1447_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1447_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1447_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1447_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1447_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1447_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1447_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1447_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1447_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1447_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1448_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1448_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1448_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1448_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1448_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1448_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1448_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1448_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1448_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1448_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1449_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1449_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1449_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1449_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1449_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1449_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1449_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1449_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1449_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1449_9.png']\n",
            "------------ Options -------------\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 1\n",
            "checkpoints_dir: ./checkpoints\n",
            "cluster_path: features_clustered_010.npy\n",
            "data_type: 32\n",
            "dataroot: ./datasets/outdoor\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 500\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "model: pix2pixHD\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_local_enhancers: 1\n",
            "name: nebbia\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: True\n",
            "norm: instance\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "phase: test\n",
            "resize_or_crop: none\n",
            "results_dir: ./datasets/outdoor/synth\n",
            "serial_batches: False\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "verbose: False\n",
            "which_epoch: 50\n",
            "-------------- End ----------------\n",
            "CustomDatasetDataLoader\n",
            "dataset [AlignedDataset] was created\n",
            "GlobalGenerator(\n",
            "  (model): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (11): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (14): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (17): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (18): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (19): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (20): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (21): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (22): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (23): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (24): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (25): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (26): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (29): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (30): ReLU(inplace=True)\n",
            "    (31): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (32): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (33): ReLU(inplace=True)\n",
            "    (34): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (35): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (38): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (39): Tanh()\n",
            "  )\n",
            ")\n",
            "/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/models/pix2pixHD_model.py:128: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  input_label = Variable(input_label, volatile=infer)\n",
            "process image... ['./datasets/outdoor/test_A/0001_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0002_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0003_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0004_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0006_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0007_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0009_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0010_0.95_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0011_0.95_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0014_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0016_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0017_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0018_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0019_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0021_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0022_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0023_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0024_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0025_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0026_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0029_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0030_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0033_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0034_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0036_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0039_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0040_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0042_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0045_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0046_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0047_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0048_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0049_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0051_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0051_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0052_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0053_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0054_0.85_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0055_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0056_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0057_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0058_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0059_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0060_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0061_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0062_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0063_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0064_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0065_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0066_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0068_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0069_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0070_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0071_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0072_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0073_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0074_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0075_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0076_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0076_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0077_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0079_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0081_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0082_0.85_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0083_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0084_0.95_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0085_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0086_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0086_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0087_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0088_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0089_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0090_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0091_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0092_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0093_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0094_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0095_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0096_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0097_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0098_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0099_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0100_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0101_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0102_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0104_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0105_0.95_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0106_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0107_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0108_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0108_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0109_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0110_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0111_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0112_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0113_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0115_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0116_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0117_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0118_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0119_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0120_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0121_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0123_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0125_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0126_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0127_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0129_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0131_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0132_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0133_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0134_0.95_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0135_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0137_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0138_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0139_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0140_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0141_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0142_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0143_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0145_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0146_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0147_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0148_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0149_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0150_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0151_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0152_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0153_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0154_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0155_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0157_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0158_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0160_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0161_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0162_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0163_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0164_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0165_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0166_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0167_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0168_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0169_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0170_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0171_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0172_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0174_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0175_0.85_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0176_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0178_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0179_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0180_0.85_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0181_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0182_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0183_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0184_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0185_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0187_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0188_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0189_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0191_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0194_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0195_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0196_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0197_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0198_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0199_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0200_1_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0201_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0202_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0204_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0205_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0206_1_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0207_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0208_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0209_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0210_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0212_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0213_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0215_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0216_1_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0217_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0218_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0219_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0220_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0222_0.85_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0223_0.95_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0225_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0226_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0228_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0230_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0233_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0235_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0237_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0238_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0239_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0240_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0242_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0243_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0244_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0245_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0246_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0248_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0249_1_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0251_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0253_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0253_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0255_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0256_0.95_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0258_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0259_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0260_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0261_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0262_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0263_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0264_0.95_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0266_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0267_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0268_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0269_0.95_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0270_0.85_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0271_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0272_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0273_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0274_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0275_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0276_1_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0277_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0279_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0280_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0281_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0282_0.85_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0283_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0284_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0285_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0286_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0287_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0287_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0288_0.95_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0290_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0291_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0292_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0294_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0295_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0296_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0297_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0298_1_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0299_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0300_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0302_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0303_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0304_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0305_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0306_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0307_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0308_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0309_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0311_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0312_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0313_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0314_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0315_0.85_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0316_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0317_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0318_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0319_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0320_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0320_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0321_1_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0323_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0324_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0325_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0326_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0327_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0329_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0330_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0330_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0331_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0332_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0333_0.95_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0334_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0335_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0337_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0338_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0340_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0341_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0342_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0343_0.95_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0344_0.85_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0345_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0346_0.95_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0348_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0349_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0350_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0351_0.95_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0353_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0354_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0355_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0356_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0357_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0359_0.85_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0361_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0362_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0364_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0366_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0369_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0371_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0372_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0375_0.85_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0380_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0382_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0383_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0385_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0386_1_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0388_0.95_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0390_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0391_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0392_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0393_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0395_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0397_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0399_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0400_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0402_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0404_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0405_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0406_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0407_0.95_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0409_1_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0411_0.95_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0413_0.95_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1001_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1002_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1005_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1006_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1007_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1008_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1009_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1010_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1011_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1012_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1015_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1016_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1018_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1020_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1022_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1027_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1030_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1034_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1037_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1038_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1040_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1042_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1044_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1046_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1048_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1050_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1051_1_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1053_0.95_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1055_0.95_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1057_0.95_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1059_0.95_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1060_0.85_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1063_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1709_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1712_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1713_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1714_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1716_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1718_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1722_0.95_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1724_0.95_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1726_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1728_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1730_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1731_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1732_0.95_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1734_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1736_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1738_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1741_0.85_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1742_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1743_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1744_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1747_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1749_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1753_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1756_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1757_0.85_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1759_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1760_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1765_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1771_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1774_0.95_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1778_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1781_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1784_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1790_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1800_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1805_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1812_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1815_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1818_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1821_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1822_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1824_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1826_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1828_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1831_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1832_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1834_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1837_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1839_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1840_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1843_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1845_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1846_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1848_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1849_1_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1851_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1852_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1853_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1855_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1857_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1858_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1859_0.85_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1861_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1862_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1863_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1865_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1867_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1868_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1869_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1871_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1872_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1873_0.85_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1874_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1875_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1876_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1877_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1878_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1879_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1880_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1881_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1882_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1883_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1887_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1889_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1891_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1893_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1896_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1898_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1899_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1900_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1903_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1909_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1913_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1915_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1917_0.95_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1919_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1920_0.95_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1921_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1923_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1924_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1926_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1927_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1928_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1930_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1931_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1932_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1933_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1934_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1936_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1938_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1940_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1942_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1944_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1945_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1947_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1949_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1950_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1953_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1954_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1956_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1958_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1960_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1962_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1964_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1966_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1968_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1970_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1971_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1973_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1975_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1977_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1981_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1982_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1984_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1986_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1988_0.8_0.12.jpg']\n"
          ]
        }
      ],
      "source": [
        "#se non  stato eseguito il download\n",
        "if os.getcwd() != \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD\":\n",
        "  os.chdir(\"pix2pixHD\")\n",
        "\n",
        "!python test.py --dataroot ./datasets/indoor --name nebbia --resize_or_crop none --label_nc 0 --no_instance --how_many 500 --which_epoch 50 --results_dir ./datasets/indoor/synth\n",
        "!python test.py --dataroot ./datasets/outdoor --name nebbia --resize_or_crop none --label_nc 0 --no_instance --how_many 500 --which_epoch 50 --results_dir ./datasets/outdoor/synth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-Uvp5SC9u4Z"
      },
      "outputs": [],
      "source": [
        "# Definisci i percorsi delle cartelle contenenti le immagini\n",
        "indoor_synth_folder = \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/datasets/indoor/synth/nebbia/test_50/images\"  # Cartella con le immagini generate\n",
        "indoor_original_folder = \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/datasets/indoor/gt\"        # Cartella con le immagini originali\n",
        "outdoor_synth_folder = \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/datasets/outdoor/synth/nebbia/test_50/images\"  # Cartella con le immagini generate\n",
        "outdoor_original_folder = \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/datasets/outdoor/gt\"       # Cartella con le immagini originali\n",
        "result_folder = \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/results\"\n",
        "\n",
        "test_indoor_outdoor(indoor_synth_folder, indoor_original_folder, outdoor_synth_folder, outdoor_original_folder,os.path.join(result_folder,\"50\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## General model epoch 100"
      ],
      "metadata": {
        "id": "YMq_DkvXPl9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#se non  stato eseguito il download\n",
        "if os.getcwd() != \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD\":\n",
        "  os.chdir(\"pix2pixHD\")\n",
        "\n",
        "!python test.py --dataroot ./datasets/indoor --name nebbia --resize_or_crop none --label_nc 0 --no_instance --how_many 500 --which_epoch 100 --results_dir ./datasets/indoor/synth\n",
        "!python test.py --dataroot ./datasets/outdoor --name nebbia --resize_or_crop none --label_nc 0 --no_instance --how_many 500 --which_epoch 100 --results_dir ./datasets/outdoor/synth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_ogDxJSP2BB",
        "outputId": "a6f423a0-d38f-449a-f407-fdbad2052a0b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------ Options -------------\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 1\n",
            "checkpoints_dir: ./checkpoints\n",
            "cluster_path: features_clustered_010.npy\n",
            "data_type: 32\n",
            "dataroot: ./datasets/indoor\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 500\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "model: pix2pixHD\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_local_enhancers: 1\n",
            "name: nebbia\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: True\n",
            "norm: instance\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "phase: test\n",
            "resize_or_crop: none\n",
            "results_dir: ./datasets/indoor/synth\n",
            "serial_batches: False\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "verbose: False\n",
            "which_epoch: 100\n",
            "-------------- End ----------------\n",
            "CustomDatasetDataLoader\n",
            "dataset [AlignedDataset] was created\n",
            "GlobalGenerator(\n",
            "  (model): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (11): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (14): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (17): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (18): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (19): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (20): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (21): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (22): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (23): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (24): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (25): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (26): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (29): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (30): ReLU(inplace=True)\n",
            "    (31): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (32): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (33): ReLU(inplace=True)\n",
            "    (34): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (35): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (38): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (39): Tanh()\n",
            "  )\n",
            ")\n",
            "/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/models/pix2pixHD_model.py:128: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  input_label = Variable(input_label, volatile=infer)\n",
            "process image... ['./datasets/indoor/test_A/1400_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1400_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1400_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1400_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1400_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1400_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1400_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1400_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1400_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1400_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1401_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1401_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1401_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1401_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1401_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1401_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1401_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1401_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1401_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1401_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1402_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1402_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1402_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1402_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1402_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1402_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1402_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1402_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1402_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1402_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1403_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1403_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1403_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1403_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1403_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1403_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1403_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1403_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1403_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1403_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1404_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1404_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1404_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1404_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1404_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1404_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1404_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1404_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1404_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1404_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1405_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1405_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1405_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1405_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1405_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1405_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1405_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1405_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1405_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1405_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1406_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1406_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1406_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1406_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1406_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1406_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1406_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1406_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1406_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1406_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1407_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1407_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1407_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1407_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1407_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1407_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1407_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1407_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1407_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1407_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1408_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1408_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1408_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1408_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1408_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1408_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1408_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1408_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1408_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1408_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1409_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1409_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1409_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1409_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1409_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1409_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1409_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1409_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1409_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1409_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1410_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1410_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1410_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1410_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1410_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1410_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1410_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1410_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1410_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1410_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1411_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1411_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1411_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1411_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1411_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1411_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1411_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1411_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1411_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1411_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1412_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1412_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1412_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1412_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1412_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1412_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1412_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1412_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1412_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1412_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1413_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1413_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1413_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1413_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1413_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1413_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1413_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1413_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1413_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1413_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1414_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1414_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1414_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1414_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1414_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1414_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1414_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1414_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1414_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1414_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1415_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1415_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1415_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1415_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1415_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1415_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1415_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1415_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1415_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1415_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1416_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1416_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1416_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1416_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1416_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1416_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1416_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1416_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1416_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1416_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1417_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1417_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1417_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1417_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1417_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1417_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1417_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1417_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1417_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1417_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1418_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1418_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1418_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1418_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1418_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1418_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1418_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1418_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1418_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1418_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1419_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1419_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1419_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1419_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1419_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1419_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1419_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1419_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1419_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1419_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1420_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1420_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1420_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1420_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1420_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1420_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1420_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1420_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1420_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1420_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1421_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1421_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1421_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1421_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1421_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1421_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1421_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1421_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1421_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1421_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1422_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1422_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1422_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1422_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1422_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1422_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1422_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1422_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1422_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1422_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1423_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1423_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1423_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1423_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1423_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1423_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1423_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1423_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1423_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1423_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1424_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1424_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1424_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1424_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1424_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1424_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1424_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1424_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1424_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1424_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1425_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1425_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1425_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1425_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1425_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1425_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1425_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1425_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1425_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1425_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1426_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1426_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1426_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1426_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1426_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1426_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1426_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1426_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1426_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1426_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1427_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1427_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1427_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1427_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1427_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1427_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1427_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1427_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1427_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1427_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1428_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1428_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1428_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1428_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1428_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1428_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1428_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1428_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1428_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1428_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1429_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1429_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1429_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1429_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1429_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1429_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1429_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1429_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1429_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1429_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1430_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1430_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1430_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1430_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1430_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1430_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1430_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1430_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1430_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1430_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1431_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1431_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1431_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1431_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1431_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1431_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1431_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1431_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1431_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1431_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1432_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1432_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1432_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1432_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1432_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1432_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1432_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1432_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1432_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1432_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1433_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1433_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1433_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1433_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1433_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1433_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1433_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1433_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1433_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1433_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1434_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1434_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1434_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1434_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1434_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1434_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1434_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1434_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1434_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1434_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1435_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1435_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1435_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1435_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1435_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1435_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1435_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1435_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1435_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1435_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1436_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1436_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1436_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1436_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1436_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1436_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1436_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1436_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1436_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1436_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1437_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1437_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1437_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1437_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1437_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1437_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1437_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1437_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1437_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1437_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1438_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1438_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1438_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1438_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1438_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1438_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1438_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1438_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1438_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1438_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1439_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1439_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1439_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1439_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1439_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1439_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1439_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1439_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1439_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1439_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1440_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1440_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1440_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1440_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1440_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1440_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1440_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1440_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1440_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1440_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1441_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1441_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1441_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1441_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1441_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1441_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1441_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1441_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1441_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1441_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1442_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1442_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1442_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1442_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1442_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1442_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1442_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1442_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1442_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1442_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1443_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1443_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1443_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1443_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1443_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1443_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1443_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1443_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1443_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1443_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1444_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1444_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1444_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1444_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1444_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1444_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1444_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1444_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1444_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1444_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1445_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1445_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1445_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1445_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1445_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1445_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1445_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1445_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1445_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1445_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1446_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1446_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1446_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1446_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1446_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1446_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1446_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1446_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1446_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1446_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1447_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1447_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1447_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1447_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1447_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1447_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1447_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1447_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1447_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1447_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1448_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1448_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1448_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1448_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1448_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1448_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1448_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1448_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1448_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1448_9.png']\n",
            "process image... ['./datasets/indoor/test_A/1449_1.png']\n",
            "process image... ['./datasets/indoor/test_A/1449_10.png']\n",
            "process image... ['./datasets/indoor/test_A/1449_2.png']\n",
            "process image... ['./datasets/indoor/test_A/1449_3.png']\n",
            "process image... ['./datasets/indoor/test_A/1449_4.png']\n",
            "process image... ['./datasets/indoor/test_A/1449_5.png']\n",
            "process image... ['./datasets/indoor/test_A/1449_6.png']\n",
            "process image... ['./datasets/indoor/test_A/1449_7.png']\n",
            "process image... ['./datasets/indoor/test_A/1449_8.png']\n",
            "process image... ['./datasets/indoor/test_A/1449_9.png']\n",
            "------------ Options -------------\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 1\n",
            "checkpoints_dir: ./checkpoints\n",
            "cluster_path: features_clustered_010.npy\n",
            "data_type: 32\n",
            "dataroot: ./datasets/outdoor\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 500\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "model: pix2pixHD\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_local_enhancers: 1\n",
            "name: nebbia\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: True\n",
            "norm: instance\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "phase: test\n",
            "resize_or_crop: none\n",
            "results_dir: ./datasets/outdoor/synth\n",
            "serial_batches: False\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "verbose: False\n",
            "which_epoch: 100\n",
            "-------------- End ----------------\n",
            "CustomDatasetDataLoader\n",
            "dataset [AlignedDataset] was created\n",
            "GlobalGenerator(\n",
            "  (model): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (11): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (14): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (17): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (18): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (19): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (20): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (21): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (22): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (23): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (24): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (25): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (26): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (29): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (30): ReLU(inplace=True)\n",
            "    (31): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (32): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (33): ReLU(inplace=True)\n",
            "    (34): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (35): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (38): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (39): Tanh()\n",
            "  )\n",
            ")\n",
            "/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/models/pix2pixHD_model.py:128: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  input_label = Variable(input_label, volatile=infer)\n",
            "process image... ['./datasets/outdoor/test_A/0001_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0002_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0003_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0004_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0006_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0007_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0009_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0010_0.95_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0011_0.95_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0014_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0016_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0017_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0018_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0019_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0021_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0022_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0023_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0024_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0025_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0026_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0029_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0030_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0033_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0034_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0036_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0039_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0040_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0042_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0045_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0046_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0047_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0048_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0049_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0051_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0051_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0052_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0053_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0054_0.85_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0055_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0056_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0057_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0058_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0059_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0060_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0061_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0062_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0063_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0064_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0065_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0066_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0068_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0069_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0070_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0071_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0072_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0073_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0074_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0075_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0076_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0076_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0077_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0079_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0081_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0082_0.85_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0083_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0084_0.95_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0085_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0086_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0086_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0087_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0088_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0089_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0090_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0091_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0092_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0093_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0094_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0095_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0096_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0097_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0098_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0099_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0100_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0101_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0102_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0104_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0105_0.95_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0106_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0107_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0108_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0108_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0109_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0110_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0111_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0112_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0113_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0115_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0116_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0117_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0118_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0119_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0120_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0121_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0123_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0125_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0126_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0127_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0129_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0131_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0132_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0133_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0134_0.95_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0135_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0137_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0138_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0139_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0140_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0141_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0142_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0143_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0145_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0146_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0147_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0148_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0149_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0150_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0151_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0152_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0153_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0154_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0155_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0157_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0158_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0160_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0161_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0162_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0163_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0164_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0165_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0166_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0167_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0168_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0169_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0170_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0171_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0172_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0174_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0175_0.85_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0176_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0178_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0179_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0180_0.85_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0181_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0182_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0183_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0184_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0185_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0187_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0188_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0189_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0191_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0194_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0195_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0196_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0197_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0198_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0199_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0200_1_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0201_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0202_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0204_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0205_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0206_1_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0207_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0208_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0209_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0210_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0212_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0213_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0215_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0216_1_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0217_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0218_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0219_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0220_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0222_0.85_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0223_0.95_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0225_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0226_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0228_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0230_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0233_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0235_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0237_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0238_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0239_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0240_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0242_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0243_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0244_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0245_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0246_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0248_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0249_1_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0251_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0253_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0253_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0255_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0256_0.95_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0258_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0259_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0260_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0261_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0262_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0263_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0264_0.95_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0266_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0267_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0268_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0269_0.95_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0270_0.85_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0271_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0272_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0273_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0274_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0275_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0276_1_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0277_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0279_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0280_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0281_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0282_0.85_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0283_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0284_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0285_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0286_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0287_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0287_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0288_0.95_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0290_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0291_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0292_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0294_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0295_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0296_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0297_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0298_1_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0299_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0300_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0302_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0303_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0304_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0305_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0306_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0307_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0308_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0309_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0311_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0312_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0313_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0314_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0315_0.85_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0316_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0317_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0318_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0319_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0320_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0320_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0321_1_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0323_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0324_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0325_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0326_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0327_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0329_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0330_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0330_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0331_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0332_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0333_0.95_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0334_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0335_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0337_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0338_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0340_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0341_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0342_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0343_0.95_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0344_0.85_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0345_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0346_0.95_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0348_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0349_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0350_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0351_0.95_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0353_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0354_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0355_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0356_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0357_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0359_0.85_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0361_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0362_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0364_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0366_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0369_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0371_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0372_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0375_0.85_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0380_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0382_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0383_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0385_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0386_1_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0388_0.95_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0390_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0391_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0392_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0393_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0395_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0397_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0399_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0400_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0402_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0404_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0405_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0406_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0407_0.95_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0409_1_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0411_0.95_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/0413_0.95_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1001_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1002_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1005_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1006_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1007_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1008_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1009_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1010_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1011_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1012_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1015_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1016_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1018_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1020_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1022_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1027_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1030_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1034_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1037_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1038_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1040_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1042_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1044_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1046_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1048_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1050_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1051_1_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1053_0.95_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1055_0.95_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1057_0.95_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1059_0.95_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1060_0.85_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1063_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1709_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1712_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1713_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1714_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1716_0.95_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1718_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1722_0.95_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1724_0.95_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1726_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1728_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1730_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1731_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1732_0.95_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1734_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1736_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1738_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1741_0.85_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1742_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1743_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1744_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1747_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1749_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1753_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1756_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1757_0.85_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1759_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1760_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1765_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1771_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1774_0.95_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1778_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1781_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1784_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1790_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1800_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1805_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1812_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1815_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1818_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1821_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1822_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1824_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1826_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1828_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1831_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1832_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1834_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1837_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1839_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1840_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1843_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1845_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1846_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1848_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1849_1_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1851_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1852_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1853_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1855_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1857_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1858_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1859_0.85_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1861_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1862_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1863_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1865_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1867_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1868_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1869_1_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1871_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1872_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1873_0.85_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1874_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1875_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1876_1_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1877_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1878_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1879_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1880_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1881_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1882_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1883_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1887_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1889_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1891_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1893_0.9_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1896_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1898_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1899_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1900_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1903_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1909_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1913_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1915_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1917_0.95_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1919_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1920_0.95_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1921_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1923_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1924_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1926_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1927_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1928_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1930_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1931_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1932_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1933_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1934_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1936_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1938_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1940_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1942_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1944_0.9_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1945_0.9_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1947_0.8_0.16.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1949_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1950_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1953_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1954_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1956_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1958_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1960_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1962_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1964_0.85_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1966_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1968_0.8_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1970_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1971_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1973_0.95_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1975_0.85_0.12.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1977_0.8_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1981_0.8_0.2.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1982_1_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1984_0.85_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1986_0.9_0.08.jpg']\n",
            "process image... ['./datasets/outdoor/test_A/1988_0.8_0.12.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definisci i percorsi delle cartelle contenenti le immagini\n",
        "indoor_synth_folder = \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/datasets/indoor/synth/nebbia/test_100/images\"  # Cartella con le immagini generate\n",
        "indoor_original_folder = \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/datasets/indoor/gt\"        # Cartella con le immagini originali\n",
        "outdoor_synth_folder = \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/datasets/outdoor/synth/nebbia/test_100/images\"  # Cartella con le immagini generate\n",
        "outdoor_original_folder = \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/datasets/outdoor/gt\"       # Cartella con le immagini originali\n",
        "result_folder = \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/results\"\n",
        "\n",
        "test_indoor_outdoor(indoor_synth_folder, indoor_original_folder, outdoor_synth_folder, outdoor_original_folder,os.path.join(result_folder,\"100\"))"
      ],
      "metadata": {
        "id": "J6Ct6lNZP2O_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hRFAx1AdjyN"
      },
      "source": [
        "## General Model full train epoch 110"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjQklq0JevLQ",
        "outputId": "4ff59cf5-541f-4ae4-e2d0-77b261f6b907"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------ Options -------------\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 1\n",
            "checkpoints_dir: ./checkpoints\n",
            "cluster_path: features_clustered_010.npy\n",
            "data_type: 32\n",
            "dataroot: ./datasets/indoor\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 500\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "model: pix2pixHD\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_local_enhancers: 1\n",
            "name: nebbia\n",
            "nef: 16\n",
            "netG: local\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: True\n",
            "norm: instance\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "phase: test\n",
            "resize_or_crop: none\n",
            "results_dir: ./datasets/indoor/synth\n",
            "serial_batches: False\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "verbose: False\n",
            "which_epoch: latest\n",
            "-------------- End ----------------\n",
            "CustomDatasetDataLoader\n",
            "dataset [AlignedDataset] was created\n",
            "LocalEnhancer(\n",
            "  (model): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(3, 128, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (8): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (11): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (14): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (17): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (18): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (19): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (20): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (21): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (22): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (23): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (24): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (25): ConvTranspose2d(2048, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (26): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (29): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (30): ReLU(inplace=True)\n",
            "    (31): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (32): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (33): ReLU(inplace=True)\n",
            "    (34): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (35): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (36): ReLU(inplace=True)\n",
            "  )\n",
            "  (model1_1): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace=True)\n",
            "  )\n",
            "  (model1_2): Sequential(\n",
            "    (0): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (1): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (2): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (3): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (4): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (7): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (8): Tanh()\n",
            "  )\n",
            "  (downsample): AvgPool2d(kernel_size=3, stride=2, padding=[1, 1])\n",
            ")\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/models/base_model.py\", line 62, in load_network\n",
            "    network.load_state_dict(torch.load(save_path))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 797, in load\n",
            "    with _open_zipfile_reader(opened_file) as opened_zipfile:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 283, in __init__\n",
            "    super().__init__(torch._C.PyTorchFileReader(name_or_buffer))\n",
            "RuntimeError: PytorchStreamReader failed reading zip archive: failed finding central directory\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/test.py\", line 27, in <module>\n",
            "    model = create_model(opt)\n",
            "  File \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/models/models.py\", line 13, in create_model\n",
            "    model.initialize(opt)\n",
            "  File \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/models/pix2pixHD_model.py\", line 58, in initialize\n",
            "    self.load_network(self.netG, 'G', opt.which_epoch, pretrained_path)            \n",
            "  File \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/models/base_model.py\", line 64, in load_network\n",
            "    pretrained_dict = torch.load(save_path)                \n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 797, in load\n",
            "    with _open_zipfile_reader(opened_file) as opened_zipfile:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 283, in __init__\n",
            "    super().__init__(torch._C.PyTorchFileReader(name_or_buffer))\n",
            "RuntimeError: PytorchStreamReader failed reading zip archive: failed finding central directory\n",
            "------------ Options -------------\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 1\n",
            "checkpoints_dir: ./checkpoints\n",
            "cluster_path: features_clustered_010.npy\n",
            "data_type: 32\n",
            "dataroot: ./datasets/outdoor\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 500\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "model: pix2pixHD\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_local_enhancers: 1\n",
            "name: nebbia\n",
            "nef: 16\n",
            "netG: local\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: True\n",
            "norm: instance\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "phase: test\n",
            "resize_or_crop: none\n",
            "results_dir: ./datasets/outdoor/synth\n",
            "serial_batches: False\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "verbose: False\n",
            "which_epoch: latest\n",
            "-------------- End ----------------\n",
            "CustomDatasetDataLoader\n",
            "dataset [AlignedDataset] was created\n",
            "LocalEnhancer(\n",
            "  (model): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(3, 128, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (8): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (11): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (14): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (17): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (18): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (19): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (20): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (21): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (22): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (23): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (24): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (25): ConvTranspose2d(2048, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (26): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (29): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (30): ReLU(inplace=True)\n",
            "    (31): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (32): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (33): ReLU(inplace=True)\n",
            "    (34): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (35): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (36): ReLU(inplace=True)\n",
            "  )\n",
            "  (model1_1): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace=True)\n",
            "  )\n",
            "  (model1_2): Sequential(\n",
            "    (0): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (1): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (2): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (3): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (4): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (7): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (8): Tanh()\n",
            "  )\n",
            "  (downsample): AvgPool2d(kernel_size=3, stride=2, padding=[1, 1])\n",
            ")\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/models/base_model.py\", line 62, in load_network\n",
            "    network.load_state_dict(torch.load(save_path))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 797, in load\n",
            "    with _open_zipfile_reader(opened_file) as opened_zipfile:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 283, in __init__\n",
            "    super().__init__(torch._C.PyTorchFileReader(name_or_buffer))\n",
            "RuntimeError: PytorchStreamReader failed reading zip archive: failed finding central directory\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/test.py\", line 27, in <module>\n",
            "    model = create_model(opt)\n",
            "  File \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/models/models.py\", line 13, in create_model\n",
            "    model.initialize(opt)\n",
            "  File \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/models/pix2pixHD_model.py\", line 58, in initialize\n",
            "    self.load_network(self.netG, 'G', opt.which_epoch, pretrained_path)            \n",
            "  File \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/models/base_model.py\", line 64, in load_network\n",
            "    pretrained_dict = torch.load(save_path)                \n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 797, in load\n",
            "    with _open_zipfile_reader(opened_file) as opened_zipfile:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 283, in __init__\n",
            "    super().__init__(torch._C.PyTorchFileReader(name_or_buffer))\n",
            "RuntimeError: PytorchStreamReader failed reading zip archive: failed finding central directory\n"
          ]
        }
      ],
      "source": [
        "# NON FUNZIONA PERCHE TRAIN.PY HA CORROTTO IL FILE LATEST_NET DURANTE IL TRAINING\n",
        "!python test.py --netG local --dataroot ./datasets/indoor --name nebbia --resize_or_crop none --label_nc 0 --no_instance --how_many 500 --results_dir ./datasets/indoor/synth\n",
        "!python test.py --netG local --dataroot ./datasets/outdoor --name nebbia --resize_or_crop none --label_nc 0 --no_instance --how_many 500 --results_dir ./datasets/outdoor/synth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETiBNR0-niVM"
      },
      "outputs": [],
      "source": [
        "# Definisci i percorsi delle cartelle contenenti le immagini\n",
        "indoor_synth_folder = \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/datasets/indoor/synth/nebbia/test_latest/images\"  # Cartella con le immagini generate\n",
        "outdoor_synth_folder = \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/datasets/outdoor/synth/nebbia/test_latest/images\"  # Cartella con le immagini generate\n",
        "\n",
        "test_indoor_outdoor(indoor_synth_folder, indoor_original_folder, outdoor_synth_folder, outdoor_original_folder,os.path.join(result_folder,\"latest\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIQ7RJpK-vH7"
      },
      "source": [
        "## Classifier + 3GAN epoch 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EA3lpWp4pCPs"
      },
      "source": [
        "### Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flcY45R3-Xkt",
        "outputId": "708edbb7-d836-4a19-d656-b6e9b3fae6c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 9s 9s/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Carica il tuo modello di classificazione\n",
        "classification_model = load_model(\"./classifier/dataset/models/InceptionV3/InceptionV3_128.h5\")\n",
        "#classification_model = load_model('./classifier/dataset/models/VGG16/VGG16_model.h5')\n",
        "\n",
        "# Definisci le etichette delle classi\n",
        "class_labels = ['nebbia_high', 'nebbia_low', 'nebbia_medium', 'no_nebbia']\n",
        "\n",
        "# Percorso delle immagini di input\n",
        "base_path = \"./pix2pixHD/datasets/\"\n",
        "context = [\"indoor\",\"outdoor\"]\n",
        "\n",
        "# Percorso della cartella dei risultati\n",
        "output_folder = \"./pix2pixHD/results/\"\n",
        "for scene in context:\n",
        "  input_folder = os.path.join(base_path, os.path.join(scene, \"test_A\"))\n",
        "  # Ciclo attraverso tutte le immagini nella cartella di input\n",
        "  for filename in os.listdir(input_folder):\n",
        "    if filename.endswith(\".png\") or filename.endswith(\".jpg\"):\n",
        "      # Carica l'immagine di input\n",
        "      input_image = cv2.imread(os.path.join(input_folder, filename))\n",
        "\n",
        "      # Ridimensiona l'immagine se necessario\n",
        "      width, height = 512, 512\n",
        "      if input_image.shape[:2] != (height, width):\n",
        "          input_image = cv2.resize(input_image, (width, height), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "      # Converti l'immagine in un array NumPy\n",
        "      image_array = np.array(input_image)\n",
        "\n",
        "      # Normalizza i valori dei pixel nell'intervallo [0, 1]\n",
        "      image_array = image_array.astype('float32') / 255.0\n",
        "\n",
        "      # Aggiungi una dimensione al batch se necessario\n",
        "      image_batch = np.expand_dims(image_array, axis=0)\n",
        "\n",
        "      # Esegui la classificazione dell'immagine\n",
        "      predicted_probabilities = classification_model.predict(image_batch)\n",
        "      predicted_class = np.argmax(predicted_probabilities)\n",
        "      image_class_label = class_labels[predicted_class]\n",
        "\n",
        "      # Crea la cartella di output se non esiste\n",
        "      output_class_folder = os.path.join(output_folder, os.path.join(\"nebbia3GAN\",os.path.join(scene,os.path.join(image_class_label,\"test_A\"))))\n",
        "      os.makedirs(output_class_folder, exist_ok=True)\n",
        "\n",
        "      # Salva l'immagine classificata nella cartella di output\n",
        "      output_path = os.path.join(output_class_folder, filename)\n",
        "      cv2.imwrite(output_path, input_image)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSl4-OJnpIoX"
      },
      "source": [
        "### Generate Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87e6vnloNtFe",
        "outputId": "713a33d3-c85a-483d-ba54-dafefbde3110"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nebbia_high\n",
            "------------ Options -------------\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 1\n",
            "checkpoints_dir: ./checkpoints\n",
            "cluster_path: features_clustered_010.npy\n",
            "data_type: 32\n",
            "dataroot: ./results/nebbia3GAN/indoor/nebbia_high\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 500\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "model: pix2pixHD\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_local_enhancers: 1\n",
            "name: nebbia_high\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: True\n",
            "norm: instance\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "phase: test\n",
            "resize_or_crop: none\n",
            "results_dir: ./results/nebbia3GAN/indoor/nebbia_high/synth\n",
            "serial_batches: False\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "verbose: False\n",
            "which_epoch: 50\n",
            "-------------- End ----------------\n",
            "CustomDatasetDataLoader\n",
            "dataset [AlignedDataset] was created\n",
            "GlobalGenerator(\n",
            "  (model): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (11): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (14): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (17): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (18): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (19): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (20): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (21): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (22): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (23): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (24): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (25): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (26): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (29): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (30): ReLU(inplace=True)\n",
            "    (31): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (32): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (33): ReLU(inplace=True)\n",
            "    (34): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (35): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (38): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (39): Tanh()\n",
            "  )\n",
            ")\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1404_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1404_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1404_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1404_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1404_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1404_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1404_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1404_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1404_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1404_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1405_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1405_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1405_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1405_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1405_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1406_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1406_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1406_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1406_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1411_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1411_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1412_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1412_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1412_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1412_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1413_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1413_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1413_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1413_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1413_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1413_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1413_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1413_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1414_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1414_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1414_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1414_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1414_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1414_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1414_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1414_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1414_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1414_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1415_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1417_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1417_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1417_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1417_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1420_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1420_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1421_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1421_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1427_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1427_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1427_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1427_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1427_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1427_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1427_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1427_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1427_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1427_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1429_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1429_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1429_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1429_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1429_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1430_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1430_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1430_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1430_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1430_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1430_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1430_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1430_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1430_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1430_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1435_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1437_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1437_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1437_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1437_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1437_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1437_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1437_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1437_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1437_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1438_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1438_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1438_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1438_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1438_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1438_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1438_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1438_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1438_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1438_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1440_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1440_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1440_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1440_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1440_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1440_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1440_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1440_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1440_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1443_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1443_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1443_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1446_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1446_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_high/test_A/1446_9.png']\n",
            "\n",
            "nebbia_low\n",
            "------------ Options -------------\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 1\n",
            "checkpoints_dir: ./checkpoints\n",
            "cluster_path: features_clustered_010.npy\n",
            "data_type: 32\n",
            "dataroot: ./results/nebbia3GAN/indoor/nebbia_low\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 500\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "model: pix2pixHD\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_local_enhancers: 1\n",
            "name: nebbia_low\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: True\n",
            "norm: instance\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "phase: test\n",
            "resize_or_crop: none\n",
            "results_dir: ./results/nebbia3GAN/indoor/nebbia_low/synth\n",
            "serial_batches: False\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "verbose: False\n",
            "which_epoch: 50\n",
            "-------------- End ----------------\n",
            "CustomDatasetDataLoader\n",
            "dataset [AlignedDataset] was created\n",
            "GlobalGenerator(\n",
            "  (model): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (11): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (14): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (17): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (18): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (19): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (20): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (21): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (22): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (23): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (24): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (25): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (26): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (29): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (30): ReLU(inplace=True)\n",
            "    (31): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (32): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (33): ReLU(inplace=True)\n",
            "    (34): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (35): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (38): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (39): Tanh()\n",
            "  )\n",
            ")\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1400_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1400_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1400_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1400_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1400_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1400_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1400_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1400_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1401_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1401_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1401_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1401_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1401_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1402_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1402_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1402_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1402_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1402_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1402_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1402_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1402_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1402_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1402_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1403_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1403_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1403_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1403_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1405_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1406_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1406_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1406_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1406_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1406_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1406_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1407_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1408_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1408_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1408_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1408_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1409_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1409_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1409_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1409_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1409_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1411_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1411_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1411_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1415_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1415_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1415_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1416_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1416_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1416_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1416_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1416_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1416_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1416_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1417_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1417_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1418_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1418_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1418_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1418_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1418_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1418_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1418_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1418_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1418_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1419_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1419_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1419_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1420_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1420_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1421_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1421_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1423_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1423_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1424_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1424_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1424_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1424_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1424_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1424_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1424_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1424_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1425_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1425_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1425_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1425_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1425_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1426_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1426_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1426_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1426_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1426_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1428_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1428_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1428_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1428_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1428_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1431_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1431_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1431_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1431_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1431_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1431_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1431_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1432_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1432_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1432_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1432_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1432_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1432_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1432_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1432_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1432_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1432_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1433_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1433_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1433_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1433_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1433_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1433_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1433_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1433_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1433_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1433_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1434_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1434_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1434_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1434_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1434_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1434_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1434_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1434_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1434_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1434_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1436_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1436_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1436_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1436_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1436_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1436_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1439_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1439_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1439_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1439_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1439_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1441_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1441_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1441_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1441_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1441_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1441_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1441_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1441_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1441_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1441_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1443_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1443_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1443_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1443_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1443_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1443_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1443_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1445_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1445_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1445_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1445_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1445_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1445_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1447_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1447_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1447_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1447_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1448_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1448_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1448_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1448_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1448_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1448_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1448_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1448_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1449_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1449_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1449_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1449_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_low/test_A/1449_5.png']\n",
            "\n",
            "nebbia_medium\n",
            "------------ Options -------------\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 1\n",
            "checkpoints_dir: ./checkpoints\n",
            "cluster_path: features_clustered_010.npy\n",
            "data_type: 32\n",
            "dataroot: ./results/nebbia3GAN/indoor/nebbia_medium\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 500\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "model: pix2pixHD\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_local_enhancers: 1\n",
            "name: nebbia_medium\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: True\n",
            "norm: instance\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "phase: test\n",
            "resize_or_crop: none\n",
            "results_dir: ./results/nebbia3GAN/indoor/nebbia_medium/synth\n",
            "serial_batches: False\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "verbose: False\n",
            "which_epoch: 50\n",
            "-------------- End ----------------\n",
            "CustomDatasetDataLoader\n",
            "dataset [AlignedDataset] was created\n",
            "GlobalGenerator(\n",
            "  (model): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (11): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (14): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (17): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (18): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (19): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (20): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (21): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (22): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (23): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (24): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (25): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (26): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (29): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (30): ReLU(inplace=True)\n",
            "    (31): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (32): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (33): ReLU(inplace=True)\n",
            "    (34): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (35): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (38): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (39): Tanh()\n",
            "  )\n",
            ")\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1400_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1400_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1401_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1401_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1401_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1401_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1401_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1403_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1403_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1403_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1403_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1403_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1403_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1405_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1405_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1405_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1405_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1411_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1411_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1411_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1411_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1411_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1412_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1412_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1412_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1412_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1412_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1412_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1413_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1413_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1415_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1415_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1415_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1415_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1415_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1415_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1417_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1417_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1417_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1417_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1418_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1420_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1420_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1420_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1420_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1420_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1420_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1421_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1421_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1421_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1421_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1421_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1421_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1422_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1422_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1422_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1422_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1422_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1422_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1422_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1422_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1422_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1422_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1423_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1423_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1423_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1423_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1423_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1423_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1423_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1423_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1424_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1424_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1425_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1425_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1425_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1425_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1425_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1426_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1426_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1426_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1426_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1426_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1428_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1428_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1428_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1429_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1429_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1429_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1429_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1429_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1431_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1431_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1431_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1435_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1435_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1435_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1435_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1435_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1435_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1435_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1435_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1435_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1436_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1436_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1436_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1436_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1437_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1439_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1439_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1439_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1439_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1439_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1440_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1442_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1442_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1442_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1442_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1442_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1442_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1442_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1442_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1442_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1442_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1444_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1444_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1444_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1444_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1444_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1444_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1444_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1444_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1444_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1444_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1446_1.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1446_2.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1446_3.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1446_4.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1446_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1446_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1446_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1447_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1447_5.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1447_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1447_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1447_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1447_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1448_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1448_9.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1449_10.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1449_6.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1449_7.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1449_8.png']\n",
            "process image... ['./results/nebbia3GAN/indoor/nebbia_medium/test_A/1449_9.png']\n",
            "\n",
            "no_nebbia\n",
            "------------ Options -------------\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 1\n",
            "checkpoints_dir: ./checkpoints\n",
            "cluster_path: features_clustered_010.npy\n",
            "data_type: 32\n",
            "dataroot: ./results/nebbia3GAN/indoor/no_nebbia\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 500\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "model: pix2pixHD\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_local_enhancers: 1\n",
            "name: no_nebbia\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: True\n",
            "norm: instance\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "phase: test\n",
            "resize_or_crop: none\n",
            "results_dir: ./results/nebbia3GAN/indoor/no_nebbia/synth\n",
            "serial_batches: False\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "verbose: False\n",
            "which_epoch: 50\n",
            "-------------- End ----------------\n",
            "CustomDatasetDataLoader\n",
            "dataset [AlignedDataset] was created\n",
            "GlobalGenerator(\n",
            "  (model): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (11): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (14): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (17): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (18): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (19): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (20): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (21): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (22): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (23): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (24): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (25): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (26): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (29): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (30): ReLU(inplace=True)\n",
            "    (31): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (32): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (33): ReLU(inplace=True)\n",
            "    (34): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (35): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (38): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (39): Tanh()\n",
            "  )\n",
            ")\n",
            "./checkpoints/no_nebbia/50_net_G.pth not exists yet!\n",
            "\n",
            "nebbia_high\n",
            "------------ Options -------------\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 1\n",
            "checkpoints_dir: ./checkpoints\n",
            "cluster_path: features_clustered_010.npy\n",
            "data_type: 32\n",
            "dataroot: ./results/nebbia3GAN/outdoor/nebbia_high\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 500\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "model: pix2pixHD\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_local_enhancers: 1\n",
            "name: nebbia_high\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: True\n",
            "norm: instance\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "phase: test\n",
            "resize_or_crop: none\n",
            "results_dir: ./results/nebbia3GAN/outdoor/nebbia_high/synth\n",
            "serial_batches: False\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "verbose: False\n",
            "which_epoch: 50\n",
            "-------------- End ----------------\n",
            "CustomDatasetDataLoader\n",
            "dataset [AlignedDataset] was created\n",
            "GlobalGenerator(\n",
            "  (model): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (11): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (14): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (17): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (18): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (19): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (20): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (21): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (22): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (23): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (24): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (25): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (26): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (29): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (30): ReLU(inplace=True)\n",
            "    (31): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (32): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (33): ReLU(inplace=True)\n",
            "    (34): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (35): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (38): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (39): Tanh()\n",
            "  )\n",
            ")\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_high/test_A/0048_0.9_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_high/test_A/0108_1_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_high/test_A/0133_1_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_high/test_A/0152_0.8_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_high/test_A/0153_0.8_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_high/test_A/0160_0.9_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_high/test_A/0189_0.85_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_high/test_A/0238_0.8_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_high/test_A/0270_0.85_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_high/test_A/0294_1_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_high/test_A/0300_1_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_high/test_A/0305_0.9_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_high/test_A/0361_0.85_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_high/test_A/0388_0.95_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_high/test_A/0406_1_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_high/test_A/1006_1_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_high/test_A/1020_0.95_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_high/test_A/1038_1_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_high/test_A/1040_1_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_high/test_A/1044_0.85_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_high/test_A/1915_1_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_high/test_A/1944_0.9_0.16.jpg']\n",
            "\n",
            "nebbia_low\n",
            "------------ Options -------------\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 1\n",
            "checkpoints_dir: ./checkpoints\n",
            "cluster_path: features_clustered_010.npy\n",
            "data_type: 32\n",
            "dataroot: ./results/nebbia3GAN/outdoor/nebbia_low\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 500\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "model: pix2pixHD\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_local_enhancers: 1\n",
            "name: nebbia_low\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: True\n",
            "norm: instance\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "phase: test\n",
            "resize_or_crop: none\n",
            "results_dir: ./results/nebbia3GAN/outdoor/nebbia_low/synth\n",
            "serial_batches: False\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "verbose: False\n",
            "which_epoch: 50\n",
            "-------------- End ----------------\n",
            "CustomDatasetDataLoader\n",
            "dataset [AlignedDataset] was created\n",
            "GlobalGenerator(\n",
            "  (model): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (11): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (14): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (17): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (18): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (19): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (20): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (21): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (22): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (23): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (24): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (25): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (26): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (29): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (30): ReLU(inplace=True)\n",
            "    (31): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (32): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (33): ReLU(inplace=True)\n",
            "    (34): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (35): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (38): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (39): Tanh()\n",
            "  )\n",
            ")\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0002_0.8_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0003_0.8_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0004_0.9_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0007_0.9_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0009_0.8_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0010_0.95_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0011_0.95_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0016_0.8_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0022_0.8_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0036_1_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0047_0.9_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0049_0.85_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0051_0.95_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0052_0.9_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0054_0.85_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0057_0.8_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0066_1_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0070_0.9_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0071_0.8_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0074_0.8_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0084_0.95_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0085_0.95_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0087_0.9_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0089_0.9_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0093_0.8_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0102_0.85_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0107_0.9_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0110_0.8_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0111_0.8_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0113_0.9_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0120_0.85_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0121_0.85_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0127_0.8_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0131_0.95_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0132_1_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0137_0.8_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0143_1_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0146_0.8_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0151_0.8_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0154_0.8_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0161_0.85_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0166_0.8_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0167_0.8_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0168_0.9_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0174_0.95_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0175_0.85_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0187_0.9_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0194_1_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0199_1_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0208_0.8_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0210_0.85_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0213_1_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0218_0.9_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0219_0.85_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0220_0.85_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0223_0.95_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0225_0.8_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0228_1_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0243_0.8_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0253_0.8_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0253_1_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0256_0.95_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0259_0.9_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0277_1_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0279_0.8_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0280_0.9_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0282_0.85_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0285_0.85_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0286_0.8_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0304_0.9_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0309_1_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0312_0.8_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0314_0.9_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0326_0.9_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0333_0.95_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0348_0.8_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0351_0.95_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0355_0.85_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0357_0.95_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0382_0.9_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0393_1_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0397_0.85_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0400_0.9_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0407_0.95_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0409_1_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/0413_0.95_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1001_0.8_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1005_0.8_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1008_0.9_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1016_0.9_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1027_0.8_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1030_0.95_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1059_0.95_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1063_0.9_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1709_0.95_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1712_0.8_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1714_1_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1731_0.85_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1747_0.8_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1756_0.9_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1824_0.95_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1834_1_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1837_0.9_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1843_0.8_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1849_1_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1852_0.85_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1857_0.8_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1859_0.85_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1873_0.85_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1878_0.9_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1880_0.9_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1887_0.95_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1889_0.85_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1919_1_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1921_0.95_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1923_0.9_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1924_0.85_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1930_0.8_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1940_0.9_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1947_0.8_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1954_1_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1962_0.9_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1966_0.9_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1971_1_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_low/test_A/1982_1_0.08.jpg']\n",
            "\n",
            "nebbia_medium\n",
            "------------ Options -------------\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 1\n",
            "checkpoints_dir: ./checkpoints\n",
            "cluster_path: features_clustered_010.npy\n",
            "data_type: 32\n",
            "dataroot: ./results/nebbia3GAN/outdoor/nebbia_medium\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 500\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "model: pix2pixHD\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_local_enhancers: 1\n",
            "name: nebbia_medium\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: True\n",
            "norm: instance\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "phase: test\n",
            "resize_or_crop: none\n",
            "results_dir: ./results/nebbia3GAN/outdoor/nebbia_medium/synth\n",
            "serial_batches: False\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "verbose: False\n",
            "which_epoch: 50\n",
            "-------------- End ----------------\n",
            "CustomDatasetDataLoader\n",
            "dataset [AlignedDataset] was created\n",
            "GlobalGenerator(\n",
            "  (model): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (11): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (14): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (17): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (18): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (19): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (20): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (21): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (22): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (23): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (24): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (25): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (26): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (29): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (30): ReLU(inplace=True)\n",
            "    (31): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (32): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (33): ReLU(inplace=True)\n",
            "    (34): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (35): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (38): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (39): Tanh()\n",
            "  )\n",
            ")\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0001_0.8_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0017_0.9_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0019_0.8_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0021_0.8_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0023_0.85_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0051_0.8_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0056_0.8_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0061_0.8_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0063_0.8_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0069_0.9_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0072_0.9_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0077_0.8_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0088_0.9_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0094_0.8_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0098_0.85_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0105_0.95_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0106_0.9_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0112_0.8_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0116_0.9_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0117_0.9_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0118_0.9_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0119_0.85_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0135_0.95_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0150_0.8_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0158_0.8_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0162_0.95_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0170_0.8_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0185_1_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0204_0.8_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0212_0.9_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0217_1_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0226_0.8_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0230_0.9_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0245_1_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0246_0.85_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0249_1_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0260_0.9_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0262_0.95_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0269_0.95_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0273_0.85_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0274_0.95_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0275_1_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0281_0.9_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0287_0.8_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0288_0.95_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0291_0.95_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0292_1_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0302_0.9_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0306_0.8_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0308_1_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0318_0.85_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0324_0.8_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0325_0.9_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0335_1_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0337_0.8_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0338_0.9_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0359_0.85_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0369_0.85_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0380_0.85_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0383_0.9_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0395_0.95_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0404_0.8_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/0411_0.95_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/1002_1_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/1007_0.95_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/1010_0.85_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/1018_0.85_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/1022_0.85_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/1037_0.8_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/1051_1_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/1722_0.95_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/1757_0.85_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/1784_0.8_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/1861_0.85_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/1877_0.9_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/1900_0.8_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/1926_0.9_0.16.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/1927_0.9_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/1949_0.8_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/1960_0.85_0.2.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/1973_0.95_0.08.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/1975_0.85_0.12.jpg']\n",
            "process image... ['./results/nebbia3GAN/outdoor/nebbia_medium/test_A/1984_0.85_0.08.jpg']\n",
            "\n",
            "no_nebbia\n",
            "------------ Options -------------\n",
            "aspect_ratio: 1.0\n",
            "batchSize: 1\n",
            "checkpoints_dir: ./checkpoints\n",
            "cluster_path: features_clustered_010.npy\n",
            "data_type: 32\n",
            "dataroot: ./results/nebbia3GAN/outdoor/no_nebbia\n",
            "display_winsize: 512\n",
            "engine: None\n",
            "export_onnx: None\n",
            "feat_num: 3\n",
            "fineSize: 512\n",
            "fp16: False\n",
            "gpu_ids: [0]\n",
            "how_many: 500\n",
            "input_nc: 3\n",
            "instance_feat: False\n",
            "isTrain: False\n",
            "label_feat: False\n",
            "label_nc: 0\n",
            "loadSize: 1024\n",
            "load_features: False\n",
            "local_rank: 0\n",
            "max_dataset_size: inf\n",
            "model: pix2pixHD\n",
            "nThreads: 2\n",
            "n_blocks_global: 9\n",
            "n_blocks_local: 3\n",
            "n_clusters: 10\n",
            "n_downsample_E: 4\n",
            "n_downsample_global: 4\n",
            "n_local_enhancers: 1\n",
            "name: no_nebbia\n",
            "nef: 16\n",
            "netG: global\n",
            "ngf: 64\n",
            "niter_fix_global: 0\n",
            "no_flip: False\n",
            "no_instance: True\n",
            "norm: instance\n",
            "ntest: inf\n",
            "onnx: None\n",
            "output_nc: 3\n",
            "phase: test\n",
            "resize_or_crop: none\n",
            "results_dir: ./results/nebbia3GAN/outdoor/no_nebbia/synth\n",
            "serial_batches: False\n",
            "tf_log: False\n",
            "use_dropout: False\n",
            "use_encoded_image: False\n",
            "verbose: False\n",
            "which_epoch: 50\n",
            "-------------- End ----------------\n",
            "CustomDatasetDataLoader\n",
            "dataset [AlignedDataset] was created\n",
            "GlobalGenerator(\n",
            "  (model): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (11): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (14): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (17): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (18): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (19): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (20): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (21): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (22): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (23): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (24): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (25): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (26): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (29): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (30): ReLU(inplace=True)\n",
            "    (31): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (32): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (33): ReLU(inplace=True)\n",
            "    (34): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (35): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (38): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (39): Tanh()\n",
            "  )\n",
            ")\n",
            "./checkpoints/no_nebbia/50_net_G.pth not exists yet!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "\n",
        "#se non  stato eseguito il download\n",
        "if os.getcwd() != \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD\":\n",
        "  os.chdir(\"pix2pixHD\")\n",
        "\n",
        "class_labels = ['nebbia_high', 'nebbia_low', 'nebbia_medium', 'no_nebbia']\n",
        "context = [\"indoor\",\"outdoor\"]\n",
        "base_path = \"./results/nebbia3GAN\"\n",
        "checkpoints_dir = \"./checkpoints\"\n",
        "\n",
        "for scene in context:\n",
        "  for label in class_labels:\n",
        "    dataset_path = os.path.join(base_path, os.path.join(scene, label))\n",
        "    result_path = os.path.join(base_path, os.path.join(scene, os.path.join(label, \"synth\")))\n",
        "    # Definisci il comando da eseguire\n",
        "    command = [\n",
        "        'python', 'test.py',\n",
        "        '--dataroot', dataset_path,\n",
        "        '--checkpoints_dir', checkpoints_dir,\n",
        "        '--name', label,\n",
        "        '--resize_or_crop', 'none',\n",
        "        '--label_nc', '0',\n",
        "        '--no_instance',\n",
        "        '--which_epoch', '50',\n",
        "        '--results_dir', result_path,\n",
        "        '--how_many', '500'\n",
        "    ]\n",
        "\n",
        "    # Esegui il comando utilizzando subprocess\n",
        "    completed_process = subprocess.run(command, stdout=subprocess.PIPE, text=True)\n",
        "\n",
        "    # Ottieni l'output dall'oggetto CompletedProcess\n",
        "    output = completed_process.stdout\n",
        "\n",
        "    # Stampa l'output\n",
        "    print(label)\n",
        "    print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwiE3e5WpQpG"
      },
      "source": [
        "### Evaluate images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqQ_Qq0SpbzN",
        "outputId": "eb587b4a-7eae-4d7d-a2f1-3652fbd87066"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spostamento completato.\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "class_labels = ['nebbia_high', 'nebbia_low', 'nebbia_medium', 'no_nebbia']\n",
        "context = [\"indoor\",\"outdoor\"]\n",
        "base_path = \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/results/nebbia3GAN/\"\n",
        "for scene in context:\n",
        "  for label in class_labels:\n",
        "    if label=='no_nebbia':\n",
        "      source = os.path.join(base_path, os.path.join(scene, os.path.join(label, \"test_A\")))\n",
        "    else:\n",
        "      source = os.path.join(base_path, os.path.join(scene, os.path.join(label, os.path.join(\"synth\", os.path.join(label, os.path.join(\"test_50\", \"images\"))))))\n",
        "    dest = os.path.join(base_path, os.path.join(scene, \"synth\"))\n",
        "\n",
        "    # Ottieni la lista dei file nella cartella di origine\n",
        "    elenco_file = os.listdir(source)\n",
        "\n",
        "    if not os.path.exists(dest):\n",
        "      os.makedirs(dest)\n",
        "\n",
        "    # Loop attraverso tutti i file nella cartella di origine e spostali nella cartella di destinazione\n",
        "    for file in elenco_file:\n",
        "        percorso_file_origine = os.path.join(source, file)\n",
        "        percorso_file_destinazione = os.path.join(dest, file)\n",
        "\n",
        "        # Sposta il file\n",
        "        shutil.move(percorso_file_origine, percorso_file_destinazione)\n",
        "\n",
        "print(\"Spostamento completato.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4lopGzjnv9u"
      },
      "outputs": [],
      "source": [
        "# Definisci i percorsi delle cartelle contenenti le immagini\n",
        "indoor_synth_folder = \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/results/nebbia3GAN/indoor/synth\"  # Cartella con le immagini generate\n",
        "outdoor_synth_folder = \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/results/nebbia3GAN/outdoor/synth\"  # Cartella con le immagini generate\n",
        "indoor_original_folder = \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/datasets/indoor/gt\"        # Cartella con le immagini originali\n",
        "outdoor_original_folder = \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/datasets/outdoor/gt\"       # Cartella con le immagini originali\n",
        "result_folder = \"/content/drive/MyDrive/Haze-Fog-suppression/pix2pixHD/results\"\n",
        "\n",
        "\n",
        "test_indoor_outdoor(indoor_synth_folder, indoor_original_folder, outdoor_synth_folder, outdoor_original_folder,os.path.join(result_folder,\"3GAN\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}